[["index.html", "Marketing Analytics Notebook Acknowledgement", " Marketing Analytics Notebook DEA 2024-10-23 Acknowledgement body {text-align: justify} This is a collection of notes from Coursera Marketing Analytics Certificate Program by META and some other sources. Marketing Analytics Foundation from META "],["marketing-analytics-foundation.html", "Chapter 1 Marketing Analytics Foundation 1.1 Definitions 1.2 Introduction to Marketing Analytics 1.3 Marketing Data Sources 1.4 Marketing Analytics 1.5 Data Analytics", " Chapter 1 Marketing Analytics Foundation body {text-align: justify} 1.1 Definitions Retail Media Retail media refers to advertising and promotional activities that take place within retail environments, both online and offline. It involves brands and advertisers collaborating with retailers to reach their target audience directly through various advertising channels within the retail space. The goal is to influence consumer behavior, drive sales, and enhance brand visibility at the point of purchase. In the context of e-commerce, retail media often involves advertising on the websites or platforms of online retailers. Brands may pay for sponsored product listings, display ads, or other promotional placements on these platforms to increase their products’ visibility to potential customers. In physical retail settings, retail media can include in-store displays, product placements, and other advertising methods within brick-and-mortar stores. This form of advertising is designed to capture the attention of shoppers while they are in the process of making purchasing decisions. Overall, retail media aims to leverage the retail environment to deliver targeted and relevant advertising messages to consumers, ultimately driving sales and creating a mutually beneficial relationship between brands and retailers. 1.2 Introduction to Marketing Analytics 1.2.1 Some Marketing terms 1.2.1.1 A brick-and-mortar store It refers to a physical retail location where business is conducted in person with customers. The term “brick-and-mortar” is used to distinguish these traditional stores from online or e-commerce businesses. In a brick-and-mortar store, customers can visit the physical location, browse products on shelves or displays, make purchases in person, and interact with store staff. The term “brick-and-mortar” comes from the materials used to build physical structures—bricks and mortar. This contrasts with online or virtual stores, which operate on the internet without a physical presence. Brick-and-mortar stores have been a common and traditional way of conducting retail business for many years, but the rise of e-commerce has led to increased competition and changes in the retail landscape. Some businesses also use a combination of both brick-and-mortar and online channels, known as omnichannel retailing, to reach a broader customer base. 1.2.1.2 Retail Media “Retail media” refers to the use of media channels, often within a retail environment, to promote and advertise products or services. It involves advertising and marketing efforts directly within the retail space, whether in physical stores or online platforms. In a retail media strategy, businesses leverage various channels such as in-store displays, digital signage, sponsored product listings on e-commerce websites, and other promotional methods to reach their target audience. This approach allows retailers to monetize their own media properties and engage with customers in a more targeted and contextually relevant manner. The concept of retail media has become increasingly important as e-commerce and digital marketing have grown in prominence. It provides retailers with an additional revenue stream and allows brands to connect with consumers at key points in the purchasing process. For example, a retail media strategy in an online marketplace might involve brands paying to have their products featured prominently in search results or on category pages, increasing visibility and potentially influencing purchasing decisions. 1.2.2 Role of marketer If you spend some time online, you’ve probably noticed that quite a few of the ads you see are for products you’re genuinely interested in and some of these ads may have prompted you to buy. Well, that’s no coincidence. You likely saw these ads because some underlying data and marketing analysis made the advertiser understand that you might be interested in the product advertised. That’s just one of the many ways in which marketing analytics powers marketing. In fact, it’s fair to say that all marketing benefits from data and analytics. Marketing is responsible for promoting and selling the products that a company makes. And that usually involves the following steps: First, the marketers identify the right customers for the product. They think about and research who might be interested in buying the product. They may interview people and use questionnaires to understand their needs better and whether these needs might be met by the product they sell. They will also try to form a better picture of the lives of the people that may want their product. All this is referred to as market or consumer research and it’s an important part of marketing. Marketing analytics is essential in this phase to help analyze the data from the research. Based on this research, marketers will create a message and a story about the products they sell. They will also decide where that message should go so it can reach the customers who may be interested. This may mean creating a website, a Facebook page, or an Instagram account. And in some cases, creating ads that could be put in magazines, on TV, on the web, and so on. This is the creative part of the marketer’s job. Many companies will rely on advertising or creative agencies to help them. Coming up with the right message and the right imagery to complement that message is a real art. But marketing analytics is used in this phase as well. Often marketers will test their messages out and gather data about the ads or promotions they run to try and understand what works best for their audience. To get marketing messages out, marketers need a plan. Marketers will carefully select the different places where they talk about their product. And if they plan to advertise, they will work on strategies that help them to most effectively spend their advertising budgets. Marketing analysts have an important role to play here. By using data and analytics to create their plan, marketers can save time and money. Once campaigns and promotions start to run, marketers will watch them carefully and focus on evaluating the results they see, like clicks on ads from campaigns, sales resulting from ads, and so on. Based on that information, marketers will adapt their advertising and their marketing plans. Given that a large share of marketing budget is spent online these days, real-time updates are possible and good marketers will make use of the opportunity by optimizing in real-time as well. But to do it effectively, they need marketing analytics. After an advertising campaign runs its course, marketers will want to evaluate whether their money was well spent. And they will have to report back to other people in the business on the success of their efforts, so they perform more analysis. And while reporting is essential, this analysis will also help the marketer get better and optimize their message and strategy for their next campaign.The better you are at marketing analytics, the better you’ll be able to optimize and get your message out to the right people in a more efficient way. Analytics plays a crucial role in marketing. A marketer equipped with good data and analytics, will be a better marketer. Online actions generate loads of data that can be a goldmine for marketers if used well. As a result, marketing analytics skills are in high demand, and all great marketers today rely on analytics to make decisions. 1.2.3 What is marketing analytics? It is the practice of measuring and analyzing data to inform, evaluate, and improve the performance of your marketing initiatives. Marketing analytics is all about gathering and analyzing data to make your marketing better. 5 Main Uses of Marketing Analytics Identifying the target audience Planning and forecasting Evaluate marketing effectiveness Marketing optimization Optimizing the sales funnel Now let’s take a look at where the role of the marketing analyst comes in, or how marketing analytics can support and improve marketing. 1. Identifying the target audience: Marketers have limited budgets, so they want to make sure that their marketing message reaches a receptive audience. Or in other words, they want to talk to people that may have an interest in buying their product. In marketing, they refer to that as your target audience. So how do marketers find that audience? Well, they use research. Imagine a marketer for a mattress company. They could use surveys to get a better understanding of when people buy mattresses, what they find important when buying a mattress, how much they would spend on a mattress, and so on. They might also use some databases that exist about mattress sales, and the demographics of the people who buy them. All of this will help describe who the best target audience is for the mattresses. What are their characteristics? Where do they live? What phase of their life are they in, and so on? All the information the marketer gathers comes in the form of data. And marketing analytics will help to make sense of that data and paint the detailed picture of the target audience the marketer needs to create the marketing message and get in front of the interested people. 2. Planning and forecasting: Marketing and advertising can be expensive. So before marketers spend their budgets, they evaluate where and when they should put their marketing message. They will carefully think about how much of their time and how much of their budgets should be spent on social media, ads on TV, radio, search engines, and so on. Often, marketers will take a look back at their previous marketing efforts, and on the basis of the success they have had with campaigns in all of these different places, they may decide to spend more or less money in some of them this time around. The mattress company may use data from the previous year to determine the mix of advertising for the coming year. They may have learned, for instance, that advertising on TV and social media really worked for them, but that there was little payoff from the ads on the radio. Often, this exercise comes with a detailed forecast of the sales they can expect based on the budget they plan to spend. This is where marketing analytics comes in. The more a marketer can rely on data and analysis in this phase, the better the results of their marketing will be. After marketing campaign is over, marketers will take a look back and ask themselves whether their campaign was effective. It helps them to learn more about what worked and what didn’t work. But they’re also doing it to report back to other people in the company. 3. Evaluate marketing effectiveness: They’re given a budget, and management typically expects a report on how the budget was spent and how successful the marketing was. For our mattress marketer, there may be a quarterly management meeting in which the marketer reports the sales that resulted from the marketing campaign. The marketer may also use this opportunity to show data on the ads that worked best, the placement of these ads that generated the largest audience and sales, and so on. Showing that the marketing was effective is crucial for most marketers, as it will help them to get the budget they need for success in the future. 4. Marketing optimization: Even after very careful planning and forecasting, things can always be improved. This is true with marketing too. Once a marketing campaign is up and running and you collect or gather data on how it is performing, there is an opportunity to optimize. And the more data you have, and the more you know about analytics, the better you’ll be able to fine-tune and optimize your marketing. As soon as you get some information on how your ads are performing, you can use that information to adjust your marketing. Say for our mattress company, if you learn from the initial data that certain search engine ads are delivering more sales than others, you could decide to spend a bit more money on the ads that perform well, and less on the ads that don’t. If you can take these kinds of actions, you optimize how your money is spent. Data and analytics are really powerful that way, and can save you quite a bit of money. 5. Optimizing the sales funnel: Finally, there’s a specific task of making sure that people who want to purchase a product or have shown an interest can easily do so. Marketers will refer to that as optimizing the sales funnel. That is because they think of the sales process in a few steps. For instance, you could think of the sales process in four steps. Awareness – Interest – Decision – Action Awareness; or when a person first hears about a product. Then Interest; which is when a person is interested in the product and may try to learn a bit more about it. Then there is the Decision step when a person decides that they want to get your product. And then there is the Action step, when they buy your product. Marketers described this process as a funnel, because as people go through this process, some people drop-off and don’t take the next step. So when you draw the group of people that go through the four steps, the groups get gradually smaller. And when you put these groups together, it looks like a funnel. When marketers talk about optimizing the funnel, they really talk about reducing the number of people that drop out. Say for our mattress marketer, it’s important that as many people as possible who are aware of the mattress become interested. And of the people who are interested, you want as many as possible to decide that they want your mattress. And then you want them to take action and buy your mattress. Since the marketer spends money on getting people to consider the mattress, they want as many people as possible to take all four steps and check out. Data and analytics will help inform marketers about how healthy their sales funnel is, how many people drop out and don’t take the next step, and why that may be. 1.2.4 The Future of Marketing is Data The future of marketing will be defined by analytics. Marketers must use data to more accurately understand who their customer is and predict what their future behavior will be. Marketing is all about personal connection. It's about filling a need or desire a customer has with a product or service you offer, and providing value to that customer while doing so. Marketing connects people with a problem they want solved to the business that can solve it. But too often, companies are simply guessing at who may need their product or service, and may advertise the features of their products without articulating any of the benefits to their customer. Or, they may just assume that everyone will want their product and never put the effort into identifying a target audience of those who will not only benefit from the product or service they offer, but who can become brand ambassadors in the future. Additionally, consumers today expect personalized experiences with the brands they interact with, from unique online and brick-and-mortar experiences, to customized product offerings, to a personable voice on social media. Just as a blanket advertising approach doesn’t work for organizations, a one-size-fits-all experience doesn’t work for customers. But marketers don’t just need better awareness about making personal connections with their audience, they need tools to do it as well. There’s a shift in looking at how well each product performs to how valuable each customer is, and marketers can only get to know their customer and create that personal connection with data. With data, marketers can learn: - what products each customer has bought in the past - what social media content is resulting in the most purchases - what keywords customers are searching for - age, gender, and location - what their interests are - how to market to those customer in the future This is why the future of marketing will be defined by analytics, or using data in order to more accurately understand who the customer is, what their past behavior has been, and what their future behavior will be. The future of business growth and success will belong to organizations who will use data in smart, insightful, applicable ways. 1.2.5 Marketing Trends for a Data-Driven Future As we see an increase in data-driven customer connections, here are some trends we’ll see in the future of marketing. Smarter use of data Marketing teams will increase their use of data in order to learn more about their customers, which will create better targeting, personalization, and connection. More personalized marketing means more returns, as 80% of consumers say they’d be more likely to purchase from a brand that offers personalized experiences, and 72% say they only engage with marketing messages that are specific to their interests. Growth of AI There will be an increase in use of AI, machine learning, and algorithms in marketing, as it can predict patterns and make recommendations based on the insights it sees. Already, algorithms choose 70% of what viewers watch on YouTube and 75% of what viewers watch on Netflix, and recommendation algorithms drive 35% of sales on Amazon. Additionally, automation will increase as well, with Gartner predicting that “By 2023, autonomous marketing systems will issue 55% of multichannel marketing messages based on marketer criteria and real-time consumer behavior, resulting in a 25% increase in response rates.” Shift to first-party data As Google is phasing out its use of cookies, organizations will shift from third-party data to first- and second-party data, which will help them understand their customer more precisely. Giving customers transparency into how data is collected will be a priority as well. According to Kevin Cochrane, the CMO of SAP Customer Experience, “To initiate a more trustworthy relationship, organizations must start by eliminating internal processes of acquiring third-party data. They must use only data that they have earned through explicit customer consent. … Moving forward, consumers should (and will) have full visibility into how extensively their personal data is being monetized.” More online data As the COVID-19 pandemic shifted life online, organizations suddenly saw an increase in new data they could collect about their customers, and the trend will only increase. “In the absence of the face-to-face, we had to lean in on digital, and that allowed us to have the information, the data, to then better serve our customers,” notes Kevin Warren, CMO of UPS. “This year really has revealed that strategic importance of analytics that maybe wasn’t quite there pre-COVID.” Better budget optimization As marketing teams are able to better target their customers, they’ll be able to better optimize their budgets. In wanting to optimize its marketing budget, DoorDash first looked at which ads brought in new customers, drew channel-level cost curves based on the data, and created better ways to deliver. “Accurate, timely, and fine-grained attribution data is the key to understanding and optimizing our marketing,” they explain. 1.2.6 An Application We are going to refer to an imaginary company, DCB Cleaning Services. They are a company that provides office cleaning services in the San Francisco Bay Area. James manages marketing for the company. Recently he presented an idea for a new product to his management, Snackwall. It’s a service where the company installs a snack wall in an office. Customers subscribe to the service and select their snacks and refills through an app. Management was very excited about his idea and developed the product. James was given a marketing budget to launch the new service. We’ll follow James and look at some of the decisions he needs to make. 1.2.6.1 Audience James at DCB Cleaning is excited to bring Snackwall to market and he’s gearing up to launch. With a quickly approaching launch date and limited budget, James knows that it is essential to get the message about Snackwall in front of the right audience; people who may be interested in the service. Given his limited budget, he wants to make sure not to waste any of his money on people in offices where Snackwall would likely not be a good fit. James needs to define his target audience. James believes that it will be best to promote Snackwall among the existing DCB Cleaning clients. But he does not think all the clients will be interested. To get a better understanding of who may have an interest, James decides to create a survey. He divides his survey in three parts. In the 1st part, he asks questions about the office space. - How many people work in the office? - Is most of the work desk work? - Where’s the office located? - How far is the office from the convenience stores? - Does the office provide lunch, etc.? In the 2nd part, James asks about the employees and the work they do. - What is the average age of the employees at the location? - What’s the education level? - What industry is the company in? In the final part of the questionnaire, James describes Snackwall and asks the level of interest in the product, from not at all interested to very interested. James’ survey goes out to all 300 clients of DCB Cleaning. It’s an online survey and 200 clients fill it out. Now that James has the answers to his questions, he goes to his marketing analyst, Alia, who had suggested to survey in the first place and who will help James analyze the results. Alia sorts all the responses in a spreadsheet. Then, she runs the segmentation analysis on the data. Segmentation is a technique we will learn more about later in this program. It’s a way to sort people in groups based on characteristics they have in common. In this case, Alia uses segmentation to get a better understanding of the characteristics that people who are interested in Snackwall have in common. After Alia runs her analysis, she finds that there are two distinct groups that have a very high interest in Snackwall. She presents her results to James. The 1st group she named “Focused Tech”. This group includes companies that have over 30 employees, provide lunch on-site, are active in the tech industry, and are primarily employing engineers and have a young workforce. The 2nd group Alia refers to as “Isolated Office”. This group includes companies with between 30 and 50 employees located outside of the urban areas with little access to food. They don’t provide lunch for their workers. They are in various industries and their workforce is young. Alia also tells James that the Focused Tech segment is quite a bit larger than the Isolated Office group. This information is super helpful for James. Using the information provided in the survey responses, James does a bit more work on describing these two audience groups. He plans to target his first advertising campaign to the Focused Tech audience. He will advertise to his current clients, but he will also use this information to find more companies that are similar to the audience in the Focused Tech segment. The segmentation that James’ marketing analyst Alia did for him helped James define his target audience. He knows that narrowing his advertising to this target audience will help him spend his budget wisely since it will increase the chance that his ads will be seen by people who are interested in his product. For any marketer who’s trying to define their target audience, marketing analytics is crucial. Segmentation helps to group the people interested in Snackwall and describe their common characteristics 1.2.6.2 Planning and Forecasting A second crucial task where marketing analytics supports marketing is in the planning and forecasting phase. James has a budget that he can use to market Snackwall. He has identified a target audience, but now he needs to come up with a marketing plan. He needs to make sure that he makes the best possible use of his budget. On top of that, his management would like to get a sense of the expected sales. There are a few things James needs to consider in his plan. First, he needs to select the platforms he will use to advertise. James believes that social media would be great, but he needs to decide which platforms to include. Alia, who runs marketing analytics for DCB cleaning and the Snack Wall product, has access to comScore data, a database with information about the different online media people use, people’s browsing behavior and demographics. Alia shows James how the age group of the focused text segment he is targeting uses Facebook and LinkedIn a lot, more so than Instagram, for instance. James agrees that these would be good platforms for his ads. Now he needs to decide how much of his money should be spent in each platform, should it be 50-50? Alia advises against that. She shows James how based on the company’s advertising experience, they found that Facebook tends to be cheaper if you target your ads well, or in other words, if you put the right message in front of the right people. But she has also found that LinkedIn helps to generate awareness among professionals. Even if they see less sales coming from the ads directly, they tend to create good leads. Based on this historical information, Alia has created a formula that she can use to help James divide up his budget. James ends up putting 70 percent of his ad budget in Facebook and 30 percent in LinkedIn. Now, James has one more step to take. He needs to present his plan to his management and his boss expects to see a forecast of the sales. Alia suggests that James rely on the historical data they have about the results of the campaigns the company ran for its cleaning services. They both know that this product is different, but since the product is new, this is the best data they have. Alia shows James how she can use the data to predict the number of people that will click on his ads in Facebook, and how many of those people will then go on to subscribe to the service. She can do the same for LinkedIn. This sounds simple enough, but in fact, the model Alia uses to forecast is a bit more complex. It also involves factors like the types of ads James is planning to use, how many video ads, single image ads, etc. The time of year when the campaign will run to people, James will target and so on. All of this information helps Alia build a better model to help James forecast the sales for Snack Wall. As you can see from this example, data and analytics play an important role into planning and forecasting phase. Of course, James could decide how to spend his budget without using analytics, but the more data and information James uses to plan, the better his strategy will be. Alia used what a company learned from the past, and that helps James to build his marketing approach and forecast sales. If you don’t have data from the past that can help guide you, marketing analytics will often use data they can purchase, like the comScore data about browsing behavior we referred to. In any case, using marketing analytics will make your strategy and forecasts better. Historical data for similar events in the past can help predict events in the future and can thus guide the planning process 1.2.6.3 Evaluate Advertising Effectiveness Marketing analysts play an important role in helping to evaluate marketing effectiveness. Or another way to think about this is whether or not the marketing budget was spent well. And an important part of that is evaluating the effectiveness of advertising. Marketing analysts will try to answer the question: did the advertising campaign payoff? A good starting point to answer that question is by looking at return on Ad spent or ROAS. ROAS is simply a way to find out how much revenue you made on your advertising versus what you spent on it. The calculation for ROAS is revenue made from the ads divided by advertising costs of those ads. For example, if you spent $1 on advertising and made $10 off of that advertising, your ROAS as is 10. Or can be expressed as 10 to 1 or 10x. So this advertising made 10 times what we spent on it, which would be pretty good. Marketing analysts will use ROAS to compare how ads on different platforms perform. Or they may use it to compare campaigns they ran in the past with new campaigns and so on. All of this will help them evaluate whether they are getting the most for the advertising dollars they’re spending. Or whether there is room for improvement. Let’s go back again to James and his campaigns for SnackWall. After is campaign ran for two weeks, he finds that ROAS on his facebook ads is 12. This means that for every dollar he spends on advertising on Facebook, he sees 12 dollars in revenue for the Snack Wall product. That doesn’t sound too bad. But James knows that the advertising campaigns he ran on facebook in the past for the cleaning service had a ROAS of 23. So now James is a bit worried, he doesn’t think that the product is less attractive, but he thinks he could optimize his campaign. He decides to create new ads with more images and a clearer explanation of the service. Two weeks later, James sees that ROAS for his ads is up to 19. James feels a lot better about that. He thinks there’s still some room for improvement, but this is definitely going in the right direction. Marketing analysts will use different data and tools to calculate ROAS. Most advertising platforms provide detailed reports to calculate and track the effectiveness of ads. Of course, the example we walked through here is a bit simpler than what analysts encounter in real life, as there are a few more considerations that go into evaluating the effectiveness of ads. In this program, we will cover several techniques that you can use to evaluate whether your campaigns paid off. As you’ll find throughout these courses, ad effectiveness evaluation is a crucial task for marketing analysts 1.2.6.4 Optimize your Marketing Strategy We discussed that a lot of planning goes into marketing from identifying the right audience, to creating the right message, to selecting the right channels for that message. But once you actually start your marketing, you get a lot more data that provides you with helpful information that you can use to adjust your plan and further optimize. Actually I find that that’s the beauty of digital marketing in particular, as soon as you start running campaigns online, you get data. And you can use that data to change course and adjust in real time. That’s super powerful especially if you know marketing analytics. Here are some of the things marketing analytics can help with when it comes to optimizing your marketing campaigns. First, if you’re running ads in different channels like Facebook, YouTube, Twitter, Google, and so on, you may find that as the initial data on the effectiveness of your ads come back that some of the ads work better than others. Some channels may be more effective for your message and for your target audience than others. That insight can help you adjust your marketing mix. You may decide to shift some of your remaining budget to the channels that perform best. Second, you may see that within a channel your ads aren’t exactly delivering the results you were expecting. That may prompt you to change your advertising a bit or in other words, optimize within a channel. You could change your message or the ad creative you’re using or you may adjust who you’re targeting your ads to, in other words, the audience that will get to see your ad. And third, while you make these changes in your ad strategy, you may decide to test your new ads or the new audience that you will target. You can do that by running your new ads as well as the initial ads and test them against one another. That way, you can see whether your new ad does indeed work better than the old ad. Testing is a powerful way to make your decision and adapt your marketing based on data rather than intuition. Let’s go back to James. Remember how Alia had suggested, based on historical data, that he put 70% of his budget in Facebook ads and 30% in LinkedIn. Well, after the ads ran for two weeks, James noticed that he got better results from LinkedIn than he and Alia expected. So, he decided to put a little bit of the Facebook budget into LinkedIn instead. And when James saw that the ads in Facebook did deliver less results than he had hoped for in the first three weeks, he decided to change the ads to include a clearer message and more images. However, instead of just stopping the first campaign altogether and switching to these new ads, James decided to run both ads and see which one delivered the best results. Based on the data, he learned that the new ad with a clearer message and more images was the better one. So he decided to put all his Facebook budget towards this new ad and stop the old version from running. This type of fine tuning your marketing strategy based on data can have huge payoffs. It helps you to get the most results for your budget. And that can mean big savings and a big difference in the payoff from your marketing. Because a larger share of the marketing budgets these days is spent on digital marketing, and because digital marketing makes this type of optimization possible, marketing analytics has become increasingly important over the past decade. Businesses have learned that if you let the data speak, you get a lot more out of the marketing budget. 1.2.6.5 Optimize the Sales Funnel We discussed how marketers will pay close attention to the sales funnel and how they might split the purchase process in four different steps; awareness, interest, decision, and action. As you can imagine, getting people to the awareness stage usually involves quite a bit of time and effort and often budget. If you are introducing a new product, for instance, you need to get a word out to an audience that may have an interest in your product. Often that involves developing an ad, buying advertising space, and so on. It’s no wonder then that marketers want to closely study what happens next. That’s where marketing analytics comes in to help them understand if and how people make it through the sales funnel. Specifically, they want to identify points of friction or points where people stop moving or leave the funnel altogether. Friction can happen at different points of the funnel. For instance, people may be aware of your product, but it may be hard to get them to become interested. That could happen if you just don’t get your message across or don’t explain the benefits of your product very well. That may mean you have to change your advertising message. You may also find that people who have become interested don’t bite the bullet and decide to buy your product. That could be because a competitor may have a more attractive offer, or they may have a better message and people may decide to buy their product instead. In some cases, you may see people who’ve decided to get your product, but they failed to take action, and that could be because there’s friction in the checkout process for instance, like on a website that’s hard to navigate or that does not work well on a mobile phone. By studying the data on the number of people that make it from one stage to the next, or by evaluating the flow of how people navigate your website, these points of friction come to light and that’s what shows a marketer where they should focus their efforts and adjust their marketing strategy, or in some cases, parts of the product or the sales process. Indeed, anything that hampers the online checkout process or leaves the user with questions during the process can cause friction. When James was evaluating the sales funnel for SnackWall, he saw that there was a substantial drop-off from the decision to the action phase. Of the people that made it to the SnackWall website, only 11 percent ended up enrolling and thus purchasing the product. While James figures that some drop-off is natural, he and Aaliyah did a little bit more digging. In fact, they turned to Google Analytics and evaluated how people flow through the different pages in the online checkout process. This is the type of report they were studying. We will learn more about these reports and Google Analytics later in this program. They saw that people who landed on the website did click on the “Enroll Now” button, but they did not submit their information when they landed on the next page. This puzzled James and Aaliyah and they decided to interview a few target customers. They interviewed five people and had them go through the checkout process with them. As they were going through the website, all five of them told James and Aaliyah that they did not feel comfortable providing their name and company information without a clear idea about what a SnackWall subscription would cost them. As a result, James and Aaliyah created a quick cost calculator. Instead of the “Enroll Now” button, they now have a “Learn More” button. That leads people to a page where they are asked how many employees they have and they get a quick calculation of the estimated costs of the SnackWall subscription. Then there is an “Enroll Now” button. After making this change to the website, James saw the enrollment percentage go up to 20 percent. As I’m sure you can imagine, James was glad he did some digging into the sales funnel data. Analyzing the sales funnel can highlight weak links in your sales and marketing process and give you clues as to what part of the process may warrant more research and where there may be opportunities for optimization. 1.2.6.6 Discussion: Friction in the purchase funnel While browsing online or on social media have you noticed an ad campaign that caused too much friction and resulted in you abandoning the sales funnel. Was it an aspect of the campaign that caused you to lose interest? If so, describe what caused you to lose interest. Did a competitor have a better offer or perhaps a better message? Who and why? Was their website difficult to navigate? If so, describe what made it difficult. 1.3 Marketing Data Sources 1.3.1 What Data do Marketers use Marketing analytics can help you plan your marketing efforts, evaluate your effectiveness, and optimize your marketing and your purchase funnel, but none of that can be done without data. Data can come from different sources, can be of varying quality and can be helpful or unhelpful to you depending on what it is, but without data and the ability to understand and analyze it, marketing efforts can only go so far. As you know, all our online interactions generate data, but depending on the device you use to go online, the way data is collected differs. You may have heard of cookies and pixels used to track online behavior for instance. It’s important to understand the mechanics of how this works as it will help you understand the nature of the digital data you’re working with and the limitations. Then, we’ll walk through an example of how a marketing team collects digital data and uses it for their campaigns. 1.3.1.1 Data Related to Offline Behavior Where does the data marketers use come from? Since we’re such a digital world, you may think collecting data only happens online, and we’ll talk about online data in our next video. But there’s plenty of useful customer data that can be found offline too which can help give you a complete picture of who your customers are and how they behave. While the customer journey is shifting more and more online, there’s still a significant part of that journey that happens in a physical location, whether it be a store purchase or engaging in a service. In fact, according to Statista, only 14.1% of retail sales in 2019 were made online, which means that 86% of customer purchases are happening in a physical location. Additionally, a report by Google shows that very few people do their purchasing wholly online or wholly offline, but use a mix of both. They either do research online and buy offline, or do research offline and buy online. This is why it’s crucial to engage with both offline data and online data to truly understand customer behavior and use those insights to influence your marketing approach. What do we mean when we say offline data? It’s simply data you gather about a customer that isn’t through an online channel. This could be information collected through a physical contact form, signing up for a loyalty program, filling out a survey, or giving customer feedback. Offline data can also be tracked through point of sale information, when your customers make a purchase. You learn what product they bought, the date, any amount they spent. Point of sales data is often referred to as POS. Offline data can also include call center tracking or focus group participation as well. You can also track in-store visits and behavior through Wi-Fi logins, app usage in the store, and Beacons, which are little devices placed in the store that communicate with smartphones through Bluetooth signals. Let’s look at an example of a bookstore. On a Wednesday afternoon, a customer stops by, browses around and comes to the counter with two bestsellers they want to purchase. The bookseller asks if they want to sign up for a frequent buyer card and the customer gives their name and address to the bookseller who enters them into their POS database. They also give their email address to sign up for the newsletter. The customer pays for their books and is on their way. This is the type of transaction that happens all the time. But now, the bookstore has all of this new data to help them better understand who’s shopping at their store, not just a name but where their customer lives, their shopping habits, and sometimes age and gender. Offline data is typically rich with demographic information about customers, and it’s often information that you may not be able to collect online. Offline data can also show how much each customer purchased, which can help determine their lifetime value, what they purchased, and when. The bookstore can now better understand its customer demographic, which will help with marketing efforts. The bookstore can also understand what times of the week are busiest, which will help them at staffing. It will also help them understand what inventory to keep in stock in order to increase sales. Now, because they have a name and email address attached to the purchase, they can target customers with book recommendations. And since they’ve collected this information directly from their customer, they can ensure that it’s accurate and represents their current customer base. Since it was given directly to them, it mitigates any privacy concerns as well. All of the insights you can gather from this offline data can help you tailor your marketing strategy, better target your customer base, and see the context of your customers journey. But collecting offline data at point of sale isn’t the only place where you can obtain it. Businesses can purchase third party data from companies who collect offline insights. This could include demographic information, purchasing behavior, and even information on offline media consumption that can help businesses gain further insights into their customers’ behaviors. You’ve probably heard of the Nielsen TV ratings or heard of someone who has a Nielsen box. Nielsen is a company that monitors media consumption across a variety of devices, including TVs and smartphones. Comscore is a similar company that also tracks media consumption across devices. This is another type of offline behavior. Businesses can then purchase their data to better understand customer behavior around media engagement, including when they watch and what they watch. The better you can understand your customer, the better you can target them with advertising for your product or service. There are many other third party data sets you can buy. There are data from supermarket loyalty cards and credit card transactions, for instance, that provide information on the purchases of different products and brands. There are industry specific data like data for the pharmaceutical sector or data on car sales, etcetera. While most brands have access to their own sales data, these third party datasets help them with competitive analysis as they give them some insights into the sales for other brands as well. 1.3.1.2 Data Related to Online Behavior With society today becoming more and more digital, marketers have a vast number of tools they can use that will help them gain insights from customers’ online behavior. Those insights can better inform marketing efforts, make advertising more personalized, and engagement more meaningful. Here are some of the ways that marketers can track customers as they move through their journey to a purchase. Brand engagement may begin by interacting with a brand’s content or posts on social media for instance. Platforms like Facebook, Instagram, and Twitter have insights or analytics dashboards that can reveal a lot about an account’s followers, including the number of followers, where they’re from, what their age is, their gender breakdown, when they’re most frequently online, and what languages they speak. This can help a business understand who their audience is on social media, and if the audience they’re targeting is indeed the one following them. Social media insights can also provide information on which pieces of content are being interacted with the most, which is also helpful knowledge about your audience. User engagement may also begin when someone sees an ad on social media for a product or service you offer. This is different from the kind of organic engagement a business would build with original content in the way of posts and videos. Instead, the business would create ads targeted to a specific audience with specific characteristics and demographics. When someone clicks on the ad, the business can track the interaction and further interactions with business. Businesses who created ad campaigns through a platform like Facebook Ads Manager, can see when people interact with their ad and what consumers do as a result of seeing the ad. Do they visit a website or app, sign up on the email list or buy a product or service? This data, so knowing whether an ad campaign results in a full purchase or just a website visit, is incredibly valuable to have in order to better understand the impact of your marketing efforts. Website insights produced by dashboards like Google Analytics or Adobe Analytics, are also able to give you a lot of rich audience data that you can use to inform your marketing strategies. Similar to social media insights, website analytics will tell you how many people are visiting your site, where they’re from, what language they speak, their age, and their gender breakdown. It will also tell you where they’re entering or leaving your site, how long they’re staying on your site, and which pages they’re drawn to the most. You can use website data to see how well you’re doing on website engagement, content areas to fix, and if your efforts to drive your audience to your site are working. Keep in mind that these insights from social media dashboards and Google Analytics are going to be anonymous to you. You’ll know, for example, that 1,000 people between the ages of 30 and 40 living in New York City, clicked on your ad, but you won’t know who they are. If you sell products online, you can track not only purchases, but names and information of your customers, like the point of sales data collection we saw in the last video. Here’s an overview dashboard from Shopify, a popular e-commerce software tool. Purchasing information will give you a lot of demographic data, product preference data, and customer purchasing behavior insights to use for your future strategies. You could also, more actively, collect customer information through something as simple as a sign-up form for a newsletter, a free e-book, or a rewards or loyalty program. Or you can also gather customer information through feedback questionnaires and surveys that can give you insights on how a customer feels about your brand, uses your products, or how likely they would be to recommend you to others. So far we’ve talked about data that can be gathered online for a specific website, app, or online business. However, there are instances where marketers want to collect information about the competition as well. They may want to know what audience a competitor attracts, or they may want to get more insights into how they stack up versus the competition. Marketers can leverage third-party databases to gather data about competitors. These third-party databases provide data collected and reported by someone else, namely a third party. In most cases, marketers will have to pay for that data. As with offline data, there are many third-party databases available related to online behavior. Marketers use tools that provide data on online browsing behavior, as well as data gathered from social media posts. Comscore and Nielsen are two prominent providers of data on online behavior. Both report on which websites and apps people use, how much time they spend on them, the demographics of the people who use them, and so on. Together with their data on offline media usage, they provide marketers with a good picture of how users spend their media time. Another type of data tools that can be useful to marketers are social listening tools. They can help marketers understand what people outside their audience are saying about their brand online. They monitor how often different brands are mentioned in social media posts and they provide insights on whether these mentions are mostly positive or negative. As with any type of data you collect, the impact on your marketing strategy and overall revenue generation and brand awareness doesn’t come from simply collecting the data. It comes from analyzing it, gaining insights in what it’s saying and using those insights to inform your future strategy. 1.3.1.3 Sampled or non-Sampled Data Learn what types of data are going to be useful to your business, what your best methods are for tracking data, how to interpret data points to provide you with insights and how to interpret raw data. One more item to be aware of is understanding if you want to use sampled or unsampled data. Sampled data is exactly what it sounds like, a sample or selection of the larger data set that represents the whole of the data set. Why would you use sampled data? If you want to get insights about your customers, you’d ideally want to ask all of them, but often that’s not possible. So, you may take a sample of your customer base knowing that their insights and feedback will represent the whole. For example, a movie theater launches a new self service kiosk for tickets and 1000 people use it on the first day. The manager wants to get a sense of how the experience went, but it’s too big of a job to talk to all 1000 people who used the Kiosk. What the manager would do is talk to a few users, or a sample, to get their feedback. The movie theater would get the data and insights they want from the sample without needing to ask every single person. From the sample, the movie theater is able to make inferences on how to leverage and promote the new self service kiosk. Here’s another example: do you remember the media consumption data from Nielsen we refer to in an earlier video? This is a good example of a data set that uses sampling. To monitor people’s tv viewing habits, Nielsen recruits households whose tv viewing behavior it will monitor. These people agree to be monitored and they also fill out a questionnaire that provides Nielsen with demographic and interest data. Nielsen then uses the information they gather from those households to build a data set that represents the total population. You may also use sampling when your data set is too large to handle, which would slow down generating any insights. Using a sample of the data would give you a more manageable data set with faster analysis time. And since the sample represents the whole, it should give you the same insights. For example, a marketer collects customer data but finds that they have thousands and thousands of entries to analyze. Working with that many pieces of data will take a lot of time and effort yet pulling out a sample of that data, only 1000 entries or a few 100 for instance, would give the same insights, just at a smaller scale, and would be much easier to work with. Marketers use this tool to monitor people’s browsing behavior on their website or app. If you use Google Analytics on a very large website that is visited by many people, then Google Analytics will use sampling, so it can give you access to your data and reports faster. What is non sampled data? Well, it’s simply the whole population or data set in its raw state and there are certainly times when you use the entire population for your analysis purposes. For instance, if you’re looking for events that don’t occur frequently, a sample may not be a good way to go as you may not catch the event you were looking for, if you only look at a small selection of data. You probably noticed when I talk about sampled data that I refer to the sample as a data selection that represents the total data set. It means that we assume that the characteristics of the sample are the same as the characteristics of my total data set. And thus it’s okay to look at the sample and draw conclusions about the total data set. There are a few different methods you can use to get a representative sample. We will take a closer look at them later in this program when we dive into statistics. For now, I will just mention the most common method: random sampling, which simply involves picking members or entries at random. This can be done using a random number generator and gives everyone a fair chance of being chosen. Selecting a representative sample is important. Let’s go back to our movie theater example and their self service kiosk. If I want to know what people think of the self service kiosk experience and I plan to take a sample of 20 people, it’s not a great idea to select the first 20 people in line. By doing that, I may, for instance, pick only families with kids who are catching the morning show of a Disney movie. The self service experience may be different for them than for the crowd that shows up later at night to see a romantic comedy. By randomly selecting 20 people throughout the entire day, I have a better chance of selecting a group that represents the full spectrum of theater visitors. 1.3.1.4 First party - Second Party - Third party Data The different types and quality of data you may use as a marketer or analyst, as determined by how you collect it. If you ever had to write a report for school that involved research, you know that using primary sources like journals or firsthand accounts were always the best sources to use, because they got you the closest to what actually happened. Secondary or tertiary sources were fine, but weren’t as factual, or helpful as primary sources. The same is true when you’re working with first-party, second-party, and third-party data. Not all data is equally as useful or helpful. So it’s important to know the difference between the three, how you obtained each, and when you would use each one to help in your marketing efforts. We’ll start with first-party data, since that type of data is going to be the most valuable and relevant to you. First-party data is simply data you’ve collected about your customers directly from your customers. Rewards sign up Unique visitors Newsletter interests Ad click Purchase data This can be through the offline and online sources we mentioned in previous videos, like tracking site visits, social media follows, or via sign up in store. Examples of first-party data could be the name and address of a customer who signs up for a rewards card at a store location. The amount of unique visitors your homepage received last year, the information a customer fills in about their interests when they fill out a newsletter sign-up form. The average age of Facebook users who clicked on one of your ads, or the customers who purchased a specific item last month. Because first-party data directly reflects your audience or customer base, it will show you customers’ behavior and actions, purchase history, and how your audience engages with your brand. This kind of information can help you plan campaigns and new strategies, and continue deepening the relationship with your current audience. Additionally, because first-party data is data directly collected from your customers, you know that it’s going to be accurate, and provide a lot of rich insights. But one of the drawbacks is that it’s only limited to your audience, so you aren’t necessarily getting insights from potential audiences, or able to engage with new customers. Still, first-party data is going to be the most useful to you, and the most accurate representation of your audience. Second-party data is essentially second hand data, or data you did not collect yourself. Think of it as another businesses’ first-party data that they’re sharing with you. Or, if you share your first-party data with another business, that would be their second-party data. Why would businesses willingly share data with one another? If two businesses cater to a similar demographic or audience, they may partner in sharing their data, which may give insights into potential new audiences or trends. For example, there’s a coffee shop on one block, and a bakery on the next block, and the owners are friends. The coffee shop only focuses on coffee, no baked goods. But sometimes, people come in with bags from the bakery. Similarly, the bakery just focuses on baked goods, and doesn’t want to branch into coffee. But they often see customers come in with cups from the coffee shop. Even though there is some overlap, there are still bakery customers that may not yet have tried the coffee shop, but may enjoy it. And there are coffee shop customers that may not yet have tried the bakery. The businesses then share their first-party data with each other, so that each business can now target more people who may be interested in their products, and bringing more new customers. Businesses may also choose to purchase second-party data they believe could help them in their marketing efforts. This approach is certainly easier, but unless you’re able to preview the data first, you may not be getting a hold of useful data for your business. You may also run into privacy issues, based on how the data was originally collected. Finally, third-party data is collected not by you or another business you partnered with, but by a third party not directly linked to the end customer. That data is then sold to businesses who can use it to expand their targeting efforts. Third-party data is collected using similar approaches to first-party data, like through customer surveys, feedback, or tracking of online behavior. But the data is typically collected through random sampling. In other words, it won’t be your particular audience, but across the general population. For example, a new restaurant opens in a neighborhood, and they want to target an audience within a specific zip code. They may buy data about everyone within that particular area. They, of course, wouldn’t know if the population on the list would even like their restaurant, or be in their target audience. But they can use the data to do an all encompassing campaign, or add the data to their current customer data to increase their reach. When you buy third-party data, you may not have as much insight into how the data was collected. And the data may be incomplete, or of lower quality than first-party data. Additionally, any organization can purchase the data, so it wouldn’t be uniquely yours. There may also be further privacy risk around how third-party data was collected as well. While third-party data may not be the primary data set a marketer uses, third-party data can be useful to round out first or second-party data, or for comparison. So acquiring third-party data may be worth it. What data will be best for you? You will probably find reasons to use all three in your marketing efforts and planning. But it’s going to be best to emphasize first-party data, since that will give you the most accurate reflection of who your customers are, and provide you the most accurate insight into their behaviors. 1.3.2 Sources of Digital Data Marketing Data Sets There are different types of data marketers and marketing analysts work with, and how these days, a lot of data is related to the use of digital media. We get data about different websites people visit, the way they navigate on websites, the products they purchase online, apps they download, ads they see, and so on. In order to get the most out of the data that’s available to you as a marketer, it’s important to understand how this data is collected. First, we’ll go over how online interactions generate data. Then, we’ll take a look at data collection on websites using cookies. We will also look at the use of tags or pixels. Then, we’ll take a closer look at the use of software developer kits or SDKs for data collection for mobile apps. We’ll also discuss the use of Platform APIs to help connect data that a company may already have to the advertising platforms they may want to use. Finally, we will look at the use of UIDs. 1.3.2.1 How Online Interactions Generate Data To understand how data fuels digital marketing and how data and advertising are connected, it’s important to have a closer look at where the data comes from. How does that come about when you visit content online? Let’s look at how interactions happen online. As an example, let’s look at what happens when someone interacts with the publisher’s website. Every publisher’s website starts as a blank canvas made of code and stored on a web server. Think of your favorite news site, for instance. In your mind, strip away all of the content. The shell that’s left is the blank canvas the website started with. To fill this blank canvas with content, the publisher uses a tool known as a content management system, or short: CMS. Publishers use their CMS to store, create and manage content on their websites. So, imagine your favorite news site, they use such a CMS. It’s typically a system that makes it possible for many people to easily create and manage the content without needing to know how to code. Or in other words, it’s an easy system to write a news article that you will see appear on the new site. The publisher will leave some space on the website for advertising. A separate server will place the ads. This server is referred to as the ad server. So note that two different systems handle the content and the ads. The ads come from advertisers. To get the right ad in front of the right people, the publisher sends a signal to connect with the advertiser’s ad server and retrieve the creative for the ad that needs to be displayed. Again, when we think about our favorite news website, the people who are writing the articles that you see aren’t deciding on the ads that you see on the site. The ads you get to see are coming in from the Ad server. To publish, this website will connect with the Ad server and the Ad server fills the advertising spaces. Now let’s look at what happens when someone accesses a website. As soon as the person’s browser requests a web page from the publisher, some data about a person is sent to the publisher. That information is used to bring the right content to the person, but it’s also sent to the Ad server to make sure a relevant Ad is displayed. So, data is exchanged between the person and both the publisher and the advertisers’ servers. The publisher and the advertiser both store data. Every interaction like accessing a page, clicking on a link, clicking on an ad or making a purchase leaves a record. The publisher and the advertiser categorize and store some of that information to personalize the content and adapt the ads people see. So we now know that a lot of data is generated as people interact with online content. But what do we really mean when we talk about data? As you probably know, every website is made of code. That code is stored on a publisher server. Every time you interact with the website, you tell its server which piece of the code to display. Every request you make for a piece of code or elements of the website, leaves a record in the server. That record is referred to as the web server log. A web server log consists of strings of code like this one. This code may look foreign to us but it’s not too difficult to understand its components. First, you see a series of numbers. That’s the person’s IP address. It tells the server where to send the data. Next is a unique identifier. This is how the server recognizes who is asking for the information. This identifier is typically pulled from the person’s browser and is usually a sequence of characters. Note, that this is not personally identifiable information also referred to as PII. So, no names or physical addresses are stored here. Next, if the website requires the person to log in, there may be a user name here. Next, there’s a date and a time stamp of when the information was requested from the server. After that is the string of code that identifies what information the person is requesting. This is how the server finds the right piece of data to return. This string of code is embedded in the links on websites so that you can click on a link and give an instruction to the server at the same time. Next, you’ll see a number that tells us whether the information was successfully provided to the person. 200 means successfully delivered, while 404 means error. Finally, another number reflects the size of the content filed a person received. While every interaction leaves a trace in the publisher and advertiser servers, the servers often also send some information back to the user and store it in their browser as a cookie. 1.3.2.2 Use of Browser Cookies Above, we saw how those interactions leave a trace in the publishers’ and the advertisers’ servers in the form of web server logs. But the interactions you have with websites and ads can also leave a trace in your browser in the form of cookies. I bet you’ve heard about them before, so let’s explore what they are and how marketers use them. Web and ad servers can store some information about your interaction in a special storage area in your browser. When you interact with content from the same publisher or advertiser later, the publisher can call up the information it’s stored in your browser to help it remember a few things about you and your previous interactions. So you can think of cookies as the browser memory, and publishers and advertisers can ask it to be reminded of relevant things. A cookie is a formatted piece of text that gets stored in a person’s browser. Cookies contain information on when the person accessed a website, saw an ad and where they clicked. Sometimes, login information is stored as well. This information makes it possible for websites to remember a person’s log in info for instance, remember what someone had put in a shopping cart or what content a user seemed interested in. Cookies allow a server to connect multiple interactions from the same person. Here’s how they work. The person requests a page through the browser. To the server, it looks like a browser requesting a page. When the server gets this request, it sends the page the person asked for back. But alongside the page it also sends a tiny text file that’s placed inside the person’s browsers. The next time the person requests a page from the same server, the request will come with a cookie attached. So now the server has a little bit of information about a browser that’s asking for the page. Following is made possible through the use of cookies: Give you locally relevant content Keep you signed in on a website Adjust the content you see on a site based on your preferences In the previous lesson, we distinguished between 1st, 2nd and 3rd party data. Actually, that distinction is also very relevant when we talk about cookies, Especially 1st and 3rd party cookies. First party cookies are the text files stored in your browser by the sites that you’re actually visiting. For instance when you visit your favorite news site, they will store a text file in your browser that helps this new site to remember some of your preferences. When you come back to that news site, your experience may be personalized on the basis of the information the site has stored in your browser. By visiting your favorite news site, you have an implicit or explicit agreement that the site can store these cookies in your browser. You’ve probably had to accept the use of cookies for many sites you visit. When you accept, you give the site you are on permission to add cookies to your browser. Third party cookies are text files stored in your browser by a third party with whom you don’t have a direct relationship. In the case of your favorite news site, there may be an advertiser who stores some information in your browser while you visit a news site. The advertisers can do that because it has an ad showing on the news site you are visiting. For that ad to load, your browser interacts with the ad server, and the ad server can send a cookie to your browser in that interaction. But, you did not intentionally seek out a relationship with that advertiser. Hence, the cookie they store is considered a third party cookie. Third party cookies are used for tracking and advertising targeting purposes. Advertisers can use this third party cookie to build a user profile on you, tracking the different websites you visit and which ads you click. Thus getting a better understanding of your interests. That understanding will help them tailor ads to you. Since users have less control over 3rd party cookies and how they’re used, they have raised privacy concerns. Users and browsers increasingly block these cookies from being stored. Later, we’ll take a closer look at data and privacy and we will cover this in more detail. But for now it’s good to keep in mind that third party cookies are harder to rely on as they’re slowly phased out as a result of these concerns. While cookies in general can be a great way to connect a person’s interaction with the server and pass some information back and forth, they have some challenges. Ideally, the cookie would function as the memory of the interactions between a website and a person. With that memory intact, navigation would be smoother for the person. The website would know what actions they took or it might remember settings they like or pages and ads they saw, but people don’t use just one browser for all their interactions with the website. They may use different computers, different browsers and mobile devices. Cookies don’t work across devices and memory trace is lost. People can also erase cookies from their browsers, which erases the memory from the publisher and the advertiser. Users can also change the privacy settings in their browsers and prevent cookies from being stored. You should also keep in mind that many browsers today don’t allow the use of 3rd party cookies by default. One of the major complications with cookies is that they don’t work on mobile apps. As a result, it’s hard for a publisher to link behavior from a person on its website to behavior on its app. But even with those limitations, cookies play an important role in how data is stored and used online. If the advertiser network puts a cookie in the browser of the visitor of the website, that is considered a third-party cookie since you, as the user, don’t have a direct relationship with the advertiser network. Mobile app cookies 1.3.2.3 Cookies A “cookie” refers to a small piece of data that is stored on a user’s device by a web browser. Cookies are used to track and store information about a user’s online behavior and preferences. They play a significant role in digital marketing by providing insights into user interactions with websites and helping marketers deliver personalized and targeted content. Here are key points to understand about cookies in marketing: User Tracking: Cookies are commonly used to track user activities on websites. They store information such as pages visited, time spent on a site, and specific actions taken by the user. This data is valuable for marketers to analyze user behavior and make data-driven decisions. Personalization: Cookies enable marketers to personalize the user experience. By tracking a user’s preferences and history, websites can offer personalized content, recommendations, and advertisements. This personalization enhances user engagement and increases the likelihood of conversion. Ad Targeting: Third-party cookies, in particular, are often used for online advertising purposes. Advertisers and ad networks use these cookies to track users across different websites and display targeted advertisements based on their interests and online behavior. This practice is known as behavioral targeting. Analytics and Measurement: Cookies are essential for web analytics tools to gather data on website traffic, user demographics, and user interactions. Marketers use this data to measure the performance of their campaigns, understand their audience, and optimize their strategies. Session Management: Cookies are also used for session management, helping websites recognize users as they navigate through different pages during a single session. This is essential for maintaining user login status, shopping cart contents, and other session-specific information. Consent and Privacy Concerns: With growing concerns about online privacy, regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) require websites to obtain user consent before storing or accessing cookies. Marketers need to be mindful of these regulations and ensure compliance with privacy laws. 1.3.2.4 Tags and Pixels The publisher of a website can add a pixel by adding a few lines of code provided by the third party to whom the publisher wants to send data. There are different ways in which data is generated when people interact with content online. So far we looked at web server logs and cookies. Now, we’re going to take a look at pixels which are sometimes also referred to as tags. Pixels and tags are used for tracking, measurement and advertising. Let’s take a look. When you have a website, you will often work with different companies to help you manage and monetize your site as well as understanding how people navigate your site. You may work with a company that helps you track user behavior on your site for instance, or companies that help you advertise your products. In order for these companies to help you, you need to pass some information or data to them about what’s happening on your site. You, as a publisher, can see all the information in your server logs but since these other companies that help you don’t have access to your servers, you need another way to give them information. That’s where pixels or tags come in. That sounds a bit like cookies…how is this different? Remember that cookies are added to the user’s browser after an interaction has been established. So, if I go to my favorite news site, I create a connection with them. Their servers send me some information and in the process of sending me that info they store some information in my browser via cookie. Advertisers that show ads on that news site can follow a similar process since their ad server will send me the ad so an interaction between my browser and the ad server is established. But if my favorite news site uses Google Analytics to help them track and measure behavior on the site, there isn’t really any interaction that’s automatically established between my browser and Google Analytics. Google Analytics is not sending the content or the ads, so there isn’t anything I need from its servers to browse around on my favorite news site. If the news site wants to send information about my browsing, it needs to add some extra code to its site that sends data to google analytics. That extra code that will be integrated in the site is referred to as a pixel or a tag. A pixel or tag is a small piece of code, often Javascript, that instructs the website to send some information to an identified 3rd party. As you know, a website is made up of lines of code; pixels and tags are integrated inside that code. Here is what a pixel may look like. This example is the pixel from Facebook. From the user point, this code doesn’t really do anything. You don’t see the pixel, in fact, it literally is a super tiny transparent square, hence it’s called a pixel. When you visit a website, all the website code loads and when this piece of code loads, the transparent pixel is displayed, and the pixel is loaded. It will collect some information about the page you are on and the actions you take and send that information back to the server of the party identified in the pixel. In our example, that party would be Facebook. The information will then be used to help the website owner. In the case of the Facebook pixel, the information is used to help connect advertising on Facebook with actions taken on the site. The website owner can then check how effective advertising on Facebook was to encourage certain behaviors like purchasing or subscribing, for instance. Code in a pixel can also be used to store a cookie in the browser of the user. Pixels and tags are primarily used for tracking, measurement, and advertising purposes. Some very common examples are the Google Analytics tag, which tracks user behavior on the website and uses the data to provide publishers with insightful reports of the number of visitors, the content that’s most popular, the actions taken on the site, and so on. The Facebook pixel we just referred to is another popular example. Websites that advertise on Facebook will use it to evaluate whether they’re advertising results in the desired actions. They also use it to create custom target audiences: groups of people that have engaged with the website and that the publisher would like to target with very specific advertising messages. The Google Ads re-marketing tag is another example. It functions similarly to the Facebook pixel and is used by advertisers to advertise to people who previously interacted with their site. If you are the website owner, you can integrate these pixels or tags on your webpages. The code is provided to you by the company whose pixel you are installing, so you can get a code for the Facebook pixel from Facebook. Similarly, other companies, like Google, for instance, will provide anyone who wants to install their pixels or tags with a code to do so. Usually, you can find that code in their help documentation or other help tools for developers. As a marketing analyst, you may not be the person who will be adding the pixel called to a web page, but it really helps to understand how pixels and tags work. That way you can ask the developers of the website for some help when you have data needs that require pixels or tags. 1.3.2.5 Software Developer Kit (SDK)s for mobile Apps So far, we’ve learned about several ways in which marketers can access data related to online behavior. We talked about web server logs, cookies, pixels, and tags. Everything we described so far has been related to data collected from interactions with websites. As you know, a lot of the online user behavior happens on mobile devices, and a large portion of mobile activity is on apps. Apps are different from websites, and tools like cookies, pixels, and tags don’t work in the same way on apps. Of course, we can still get data related to app usage, but we need to use different tools to collect the data. That’s where SDKs come in. In this video, you’ll learn what that’s all about. SDK stands for Software Developer Kit. You can think of it as a toolbox for software developers. The toolbox contains code developers can install to help create applications. In some ways, you can think of it as a library of ready-made code that makes the life of the developer easier. Instead of having to manually code every piece of an app, for instance, they can plug in pieces of ready-made code from an SDK to achieve certain functions. Here’s an example: I’m sure you’ve downloaded apps on your phone where you were asked to log in with your Google or Facebook account. That makes it easier on you as you don’t need to create a new login. The developer of that app would have used an SDK to make that work. Instead of manually programming a way for you to log in, developers would use the Facebook SDK, which has code they can implement in their app to let you log in with your Facebook credentials. It’s a bit like copying and pasting code. The code inside the Facebook SDK is especially written to make it easy for outside developers to integrate their applications with the Facebook functionality. Many platforms like Facebook provide an SDK for a number of different functions. You could use an SDK, for instance, to allow people to use certain filters in their images, or to create a smooth check-out when buying a product, and so on. SDKs exist for all kinds of software development, not just for mobile apps, but they are definitely heavily used by mobile app developers. But what does this have to do with data about user behavior? Well, when you use an SDK from an advertising platform like Facebook or Google for instance, then you’ll have the option to connect data from your advertising to actions that happen in your mobile app. Imagine you have a gaming app. You may decide to use the Facebook SDK so your users can log in with their Facebook credentials. By having your users log in with their Facebook ID using the SDK, some data is sent back to Facebook. This makes it possible for you to see things like whether people who saw an ad on Facebook for your gaming app, download your app. And, you could even see whether these people are more likely to make in-app purchases, like purchasing extra powers inside your game, for instance. The code in an SDK could instruct your app to send certain information over to the platform that created the SDK. That data can then be connected to other actions marketers take using the platform, like advertising, for instance. As a marketing analyst, it’s good to know that SDKs are the way to go when you need to connect marketing platforms to your app. Most likely you won’t need to install any of this code yourself. But, it helps to know that you can ask your developers to build in some code that can help you track the connection between your advertising and the actions people take on your app. 1.3.2.6 Connecting Data Through APIs You probably gathered from the previous videos that often, the data gathering we go through as marketing analysts has to do with connecting systems. That’s because we want to measure the effectiveness of advertising along the customer journey and across platforms. Marketers want to influence behavior, but the data related to the marketing and the data related to the behavior aren’t always easily connected. The marketing takes place using one system, like advertising using Google for instance. But behavior we want to influence takes place on other, a purchase on a website, an app download, a purchase in a store, and so on. Many of the systems we talked about so far will help marketers to make connections. But these systems often have dependencies that are a bit out of our control. We already saw how users can delete or block cookies, for instance. Or how browsers may prevent certain data collection. That’s why we’ll often rely on making more direct connections through the use of APIs. Let’s explore what those are. An API or an Application Programming Interface is a tool that establishes a connection between two pieces of software. An API allows two applications to talk to each other. The API is a little bit like a courier who transports information, requests and so on from one system to another. Think of something as simple as sharing a news article on your Twitter feed. You are on the news article and you would like to share it on Twitter. An API will ensure that your request to share goes to Twitter, who will then in turn make sure the article appears on your Twitter feed. APIs really fuel our online experience today. Loads of connections are being made constantly between different websites and different systems online. How exactly does the API play a role when it comes to data? Well, APIs make it possible to share data directly with certain marketing or advertising platforms. For instance, I can use the Facebook API to directly provide Facebook with data about what happened on my website, on my app, in my stores, and so on. Why does that matter? Well, I can send data to Facebook about purchases for instance. Facebook can then help me figure out whether the ads I ran on their platform led to those purchases. I can use the API to pass on information about website purchases, but I can also pass on information from in-store purchases. Through an API, I can establish a connection and send the data that’s relevant over that connection. Later in this program, we will dig deeper to see how APIs are relevant for marketers. To use an API, you would usually involve a developer who can help make the connection between your software and the software of the platform or tool you would like to connect with. Platforms like Facebook, Google, Twitter, and so on, will provide a developer with all the information and code needed to integrate the API. APIs are an excellent tool for marketers to connect information from different platforms. They are especially powerful because they establish a direct connection between the publisher of a site or app, and the platform it wants to connect to without depending on other tools like browsers or operating systems. As a marketing analyst, using APIs to connect information from different platforms will give you more reliable information and prevent broken data connections. 1.3.2.7 Use of UIDs UID stands for Unique User ID. It is a unique text or number string that identifies a person and it is created when the user logs in. So there are Facebook UIDs, Google UIDs and many others. There are also device IDs associating a unique person with a device like a phone, for instance. When you create an account on an online platform like Facebook, Google, Amazon and so on. You provide them with some information and you create a log in, a user ID, and a password. Let’s say you create an account with Google for example. Google will create a text or number string to associate with your unique account and link that string to the information you provided. This text or number string is your unique ID, in this case your Google ID and it will help the company associate data with your account. Now, no matter through which browser or device you access Google, all your behavior can be associated with that ID as long as you’re logged in. That’s super helpful as it enables the platform, in this case Google, to connect what you do on your computer with your usage on mobile for instance. So anywhere you use your Google log in, your behavior can be stored and linked to your Google ID. For publishers or platforms that use UIDs, it helps them to overcome some of the challenges they face when they use cookies. Remember that cookies are stored in the browser but sometimes people use different browsers or they access a site on a computer and later again on a mobile phone, for instance. The UID makes it possible for publishers to link behavior from a person on different browsers and on apps so that it’s possible to get a clearer and more complete picture of the users across platforms. With a UID, interests, behaviors, demographics and other information can be stored. Anytime a person logs in, behaviors can be associated with them. In the introduction to this video, I also refer to device IDs. These are also important for marketers. In both iOS and android, an ID is stored in the settings of the device and that ID can be accessed by advertisers if the user allows it. When users interact with advertising in an app and they have opted in to share their device ID with advertisers, it makes it possible for the advertisers to advertise to you across different apps. That way, they can show ads and track behavior on one app, like Instagram for instance, and then use that information to advertise to you while you’re using a different app. This type of tracking used to be a default setting in most phones. Nowadays, apps on Apple devices have to prompt their users to ask for permission to track their behavior and use that data across apps. You may have seen this message pop up on your phone when you are opening an app. It specifically asks you whether you are okay with this app tracking you and sharing your data with advertisers. This is a recent effort by Apple to protect users’ privacy. It’s important to note that UIDs use a number or text file, but they don’t store personally identifiable information. Personally identifiable information is any information that would help someone to identify a person, like your name for instance. You will hear marketers also refer to this as PII. Actually these days, most companies go through a lot of efforts to protect your personal data. Companies that work with online data will often use data hashing for that. In data hashing, the original data item gets translated into a hashed data item by applying an algorithm. As a result, what’s stored is unrecognizable unless you have the hashing key, another algorithm that lets you reverse the data back to its original form. This is an extra safety measure to help keep people’s privacy intact. Now you know the main ways in which behavioral data is collected online. We looked at web server logs, cookies, pixels or tags, SDKs and APIs. And now you also understand what UIDs are. That was a lot to cover, and these concepts can be a bit confusing at times. Don’t worry. We’ll repeat them again in other parts of the program and gradually their different applications will become increasingly clear. In the next lesson, we’ll go through an example of how a company might use all of these different ways to collect data. It’s a good opportunity to further practice these concepts. I’ll see you there. 1.3.3 Collecting Data for Marketing: Application 1.3.3.1 Intro We have looked at web server logs, cookies, tags or pixels, SDKs, APIs and we have also talked about UIDs. Each of these methods can help you achieve slightly different things and I think they can be quite confusing. To do that, we’re going to take a look at another fictitious company, Calla &amp; Ivy. Calla &amp; Ivy is a flower shop in Amsterdam; Imra is the owner of the store. She always loved fresh flowers, but she is particularly known for her handbound bouquets. A few years ago Imra started selling these bouquets online and her business has expanded quite a bit as a result. She now employs a few people who help her focus on the website and they also help her with her marketing. Recently, Imra introduced a flower subscription service. Subscribers can schedule monthly deliveries of bouquets to their home. In the next video, we’ll explore how Imra and her team collect and use data to help them market their products. 1.3.3.2 Collecting Data There are different ways in which data is collected online. Different methods serve different purposes. And in this video we’ll walk through an example of how these different methods can be used in a real life scenario. For the scenario, I’ll refer to our florist in Amsterdam, Calla &amp; Ivy. Imra, the owner of Calla &amp; Ivy, is introducing a new product, a flower subscription. People can subscribe on the website or on the Calla &amp; Ivy app to receive a flower delivery every month. It’s a way for people to get the fresh flower bouquets Imra is known for delivered on a regular basis and add some seasonal color to their homes. As the first step in making the product available, Imra and her team created a landing page on the Calla &amp; Ivy website where they explain what is included in the subscription and where people can enroll. When people click to enroll, they provide all their details for shipping and payment. It’s important to Imra and her team to track the appeal of this new product. She wants to know how many people check out the landing page and how many people subscribe. In theory, she could get this information from her web server logs. Remember, the web server logs keep track of all the interactions between people and the website. But in practice accessing and going through those logs it’s not easy or practical. Instead, the team at Calla &amp; Ivy tracks website traffic and website behavior using Google Analytics. For Imra and her team to use Google Analytics to see the interaction of people on their website, they first need to add the Google Analytics tag to the website. This tag or pixel is a piece of code that gets added to every page of the Calla &amp; Ivy website, which sends information over to Google Analytics. The information sent by the tag includes things like how many times the landing page for the subscription service was viewed, how many people clicked on the subscription button, how many people filled out the subscription information and so on. Google Analytics sorts all this information in neat reports that help Imra to understand whether the new product is a success and whether its popularity is growing. From studying the Google Analytics reports, Imra learns that many people visit a landing page but far fewer subscribe. After discussing this with her team, they decide that it may be a good idea to present people who hesitate with a coupon on their next visit, making their first bouquet free when they subscribe. To make this work, Imra decides to use a cookie. Now, when people access the Calla &amp; Ivy website, a cookie or a piece of formatted text, is added to their browser. It stores information about a user’s visit to the site and it stores whether people accessed the page that describes the subscription. Now, when people leave the site and come back at a later point, the cookie will help recall that this person had already been to the site and had shown an interest in the subscription. If that is the case, a large overlay with the coupon comes up on the page the user is visiting, encouraging them to subscribe and get the free bouquet. Calla and Ivy also has an app that makes it easy for people to order flowers or subscribe, monitor and manage their subscription. Of course, Imra wants to understand the behavior of people that use the app as well. So, her team installed the Google Analytics SDK. Remember that an SDK or software developer kit is a library of different pieces of code that you can integrate in your app to make certain functions possible. By installing the Google Analytics SDK, the interactions of people with the app can be sent to Google Analytics so Imra can get a full picture of all the online usage, whether on the app or on the website. On the website, she can use the Google Analytics tag, but on the app that doesn’t work, hence the SDK. For those people who live in Amsterdam, there’s a good chance that they dropped by Imra’s physical store to buy flowers. In some cases, people may learn about some of the new seasonal bouquets from ads the marketing team is running on Instagram. Instead of clicking on the ads to buy online, they decide to buy the flowers in person. Imra’s marketing team is eager to connect the dots here. They would really like to know how effective their ads on Instagram are and they want to count all the resulting purchases, not just the purchases that happened online. That’s where the marketing team relies on an API, or a system that lets them connect two pieces of software. In this case, they connect their in-store customer management software to the Facebook API. That way, every time a purchase is made in-store, data can be sent to Facebook. Based on some information that may be known about the purchaser, like the email address for instance, it may be possible to link the purchaser to a known Facebook user Id. Imra’s team can then assess whether the purchaser saw an Instagram ad and may thus have been influenced by that ad to make a purchase. This information is important to the marketing team to have access to, so they are able to better understand their ads’ effectiveness. This is just a brief view into what may go on in a company and its marketing department on a daily basis. And as you can see, data plays a crucial role in many tasks that get executed on a regular basis. Marketers rely on different methods to get to the data they need. 1.3.3.3 Implementing the Facebook Pixel, SDK and API Implementing Data Collection Tools In previous lessons, we’ve learned about the many different types of data that can be collected, from the different websites people visit to the ads they see along the way. Just like there are many different data points, there are various ways to collect data, each with their own features and purposes. Although much of the information these tools collect and organize for you can be found on the web server logs for your site, that’s not always easy or practical. In this reading, we’ll take a look at three tools that will help you collect data. Facebook Pixel Pixels, also referred to as tags, are used for tracking, measurement and advertising. As mentioned in the introduction section above, it’s not always easy or practical to look at data from your web server logs or even cookies. Luckily you can work with companies to help you track user behavior or advertise products. A pixel is a small piece of code that you can add to your website that instructs it to send some information to an identified third party, in other words, these companies looking to help you utilize your data. The Facebook pixel is one example. Here, the information is used to help connect advertising on Facebook with actions taken on the site, allowing you to check how effective your advertising on Facebook was. SDKs An SDK, or software development kit, is a library of pieces of code that you can integrate into your app to add certain functions. Where on a website you can use a pixel or tag, you would use an SDK for your app. The SDK sends the information about people’s interaction with the app to, for example, Google Analytics where both website and app information can be aggregated. A great example of an SDK that you might see every day is an app that asks you to sign in with your Google or Facebook account. For your website, you might use an SDK to create a smooth checkout experience for customers, as well as, of course, tracking various data points of your browsers’ activity. If users have signed into your app using their Facebook account, for instance, you can also see whether an ad they saw on Facebook inspired them to download your app and make in-app purchases. APIs An API, or an application programming interface, is a tool that establishes a connection between two pieces of software. Remember the example of sharing a news article on Twitter from the previous lesson? In the same way APIs make it possible to share your article, they make it possible to share data directly with certain marketing or advertising platforms. This is useful because you can then use these connections to learn more about the results of your marketing activities. For example, you can send purchase data to Facebook, which can then help you figure out whether the ads you placed on their platform lead to the purchases. Implementing the tools How to do it Using these tools is often as easy as integrating them into your website’s already existing code. Most of these tools, for example the Facebook pixel and the Google Ads Remarketing, have the code readily available in the help documentation or other information for web developers. This allows you or your content developers to install the code easily so you can start tracking. Why they’re useful Implementing tools such as these can allow you to encourage browsers of your website and app to purchase, subscribe and more. The Facebook pixel, for example, can also create custom target audiences consisting of people who have engaged with the website and who you would like to target with more specific advertising messages. These tools also allow you to integrate your website experience with that of your app. For example, you can use an SDK to instruct your app to send certain information over to the platform that created the SDK, and that data can then be connected to other actions marketers take using the platform, like advertising. 1.3.3.4 Review First, you learned about different sources of data marketers use. You now know that marketers use both offline and online data. And you also understand that in some cases, it isn’t realistic to work with all the data for a particular event, in which case you can turn to sampling. You also learned what marketers mean when they talk about first, second, and third party data. And you know which tools marketing analysts use to collect data about online user behavior. You learned about browser cookies used to collect web browsing behavior data, pixels or tags to collect event data on specific websites, SDKs for data on app usage, and you learned how APIs are used to connect data from different sources to online platforms. And finally, you saw how Imra at Calla &amp; Ivy uses all these tools to collect the data she needs for her marketing. Now, you know which data sources you can tap into for different data needs, and you know which tools to use to collect online data for different use cases. Given how many different data sources there are, knowing when different data collection tools apply is incredibly helpful. Now, you’re ready to start looking into the tools you can use to categorize and analyze all that data. That’s what’s next. See you there! 1.3.4 Analyzing and Visualizing Data Now that you know about the importance of marketing analytics and the many sources of data collection, it’s time to learn about the tools of the trade. These are the software applications and techniques used by marketing analysts all over the world every day. In our first lesson, we’ll look at some common tools that are used to analyze and visualize data. We’ll talk about spreadsheets and some popular visualization tools. Then in Lesson 2, we’ll take a closer look at specific tools analysts use to evaluate online data, like Google Analytics for instance. Finally, in Lesson 3, we will look at common ways in which marketing analysts evaluate the success of their marketing campaigns. We’ll look at specific reports that are provided by big marketing platforms like Facebook Ads Manager or Google Ads for instance. At the end of this week, you’ll have a good idea of the tools that marketing analysts use every day. Later in the program, we’ll cover them in lot more detail. But it’s always good to start with the big picture. Marketing analysts have a suite of very powerful tools at their disposal, and I hope some of them will pique your interest. Let’s get started. 1.3.4.1 Spreadsheets Spreadsheets are a staple for marketing analysts everywhere. They are the most basic way to access, sort, categorize, report results and even run analyses. We will dive deeper into spreadsheets later in this course, but for now we will introduce you to the basic concepts. Today we’ll cover labelling, sorting and filtering, calculated cells, and visualizations. Before we start, there are several different software programs that allow you to access and manipulate spreadsheets, but the two main programs are Microsoft Excel and Google Sheets. Both programs work well and are similar enough that if you can use one, you can use both. Microsoft Excel has more features, but Google Sheets is a free program. No matter which you choose, the basic format is the same. 1.3.5 Tools to Evaluate Digital Data 1.3.5.1 Website Data Your website is one of the biggest assets your business will have. New customers will learn about you through your website and old customers return because they’re engaged with your brand. Your marketing efforts, both organic and paid, are going to funnel to your website. Even if you have a brick and mortar store, you’re probably also generating sales on your website. But many businesses today are online only and do all of their business through their website. This means that you need to thoroughly understand how users interact with your website. This allows you to optimize your site content to not only provide the best value and experience for your visitors, but to also maximize your conversions from signing up for a newsletter to a sale. Who is your audience? How do they get to the website? what content do they engage with? Are they staying or leaving? This is why analyzing data associated with your website can help you with your marketing efforts. Marketers need to know where to find website data and analytics, how to read them, and how to glean insights from them, so they can make data-backed decisions on whether to change marketing efforts going forward, or whether what they’re doing now is paying off. Google Analytics Google will provide you with some tracking codes to add to your website, also known as the Google Analytics global site tag, to collect data from your website. Then you can simply log into the Google Analytics dashboard to view metrics. Once the code is embedded in your site, anytime someone visits, Google Analytics attaches a unique identifier to the user, usually in the form of a cookie and tracks their movement throughout the site. Each uniquely identified visitor is called a user and each time they visit your site is called a session. Adobe Analytics 1.3.5.2 Terminology A/B Testing: A method of testing two different versions of a web page or mobile app to determine which version performs better with users. Abandon/Abandonment: When a user or customer leaves an action on a web page uncompleted and doesn’t return in the session, like a contact form or a purchase. Acknowledgement/Thank You/Receipt Page or Pop-Up: A page or pop-up that displays after a user has completed an action, like completing a form or submitting a purchase. This signals the end of a conversion event that may be tracked. Acquisition: The different ways in which customers find a website, whether it be by entering a URL directly, through a social media link, through an email link, through another website referral, or other methods. Ad Click: The act of clicking on an ad on a webpage. Ad View: The act of viewing an ad on a webpage. Audience: The visitors that come to a website, and their demographics, interests, location, behavior, and more. Banner Ad: An ad that is embedded on a webpage. It can present as full width, within the sidebar, or as other sizes on the page. Behavior: The way in which a visitor moves through a website. Benchmark: A standard measurement for a metric — for example, the average number of monthly visitors — against which to measure other measurements of the same metric. Can be within a site or across an industry. Bounce Rate: The measurement of the percentage of visitors to a website that leave the website after viewing only one page, and don’t navigate to other pages within the site. Cascading Style Sheets (CSS): A style sheet language for websites that dictates the site-wide styles and presentation. Click Through/Click Through Rate (CTR): The act of clicking on an ad to access a website or landing page. The rate is determined by dividing the number of clicks an ad received by the number of times the ad was shown. Content Management System (CMS): Software that manages the contents and back-end of a website. Conversion/Conversion Rate: When a customer completes an action, like makes a purchase, subscribes to a newsletter, or other actions. The conversion rate is the percentage of visitors to a website that complete a conversion. Cookie: A piece of data used to track a visitor’s behavior throughout a website. Cookies are used to track and store information about a user’s online behavior and preferences. They play a significant role in digital marketing by providing insights into user interactions with websites and helping marketers deliver personalized and targeted content. Cost Per Click (CPC): How much a business pays for one click on their ad. Cost Per Mille (CPM): How much a business pays for their ad to be seen by 1000 (mille) people. Crawl/Crawler: A method by which search engines “crawl” the internet, and read pages for indexing. Creative: The contents and design of an ad. Demographics: The age, gender, location, and other individual identifiers of a website’s visitors in general, or target audiences in particular. Direct Referral: One of the ways a visitor accesses a website, by typing in the URL directly into their web browser or accessing the URL via a bookmark. Domain: The web address of a website, specified by the name in the URL. eCommerce: Selling products or services online only, as opposed to in a brick-and-mortar store. Entry Page: The first page a visitor sees when they get to a website (i.e., the entry point). Exit Page: The page from which a visitor exits the website after navigating through the site. Hit: Anytime any image or files is accessed from the web server. Not to be confused with a page visit (i.e., there could be multiple hits per one page view). Home Page: The main or starting page of a website, typically located at the root URL. Hypertext Transfer Protocol (HTTP): A protocol for the way data and hypermedia is transferred between a web server and a web browser. Hypertext Markup Language (HTML): A programming language that communicates text formatting and hyperlinks on a web page. Impression: One view of a piece of content, whether it be an ad, a social media post, or some other post or call to action. Inbound Links/Back Link: Links from other websites into a website, which are evaluated by search engines when ranking. Internet Protocol (IP) Address: A unique address that identifies a computer or other device connected to the internet. Keyword: A word or phrase that not only describes the contents of a particular website, but that search engine users can search that will result in that website appearing in the results. Landing Page: A single webpage used to detail a product or offering (typically different from a home page). Link Referral: A way by which visitors find a website through links from other websites. Load Time: The time it takes for a web page to load in the browser. Meta Tags: Text that can be added to a page via hidden HTML to help with search engine ranking. Navigation: The way in which visitors move throughout a website, via a menu or navigation bar. New Visitor: A visitor who is accessing a website for the first time, and has no previous sessions. Organic Traffic: A way in which visitors find a website via organic means, like through a search engine, organic posts on social media, or via non-paid links. Outbound Links: Links going out to other websites from a website. Page Duration: The time spent by a visitor browsing one page. Page View/Page Views Per Visit: One point-in-time access of a webpage by a visitor, or one rendering or request of a web page. Page Views Per Visit is how many pages were accessed by one visitor during a period of time. Page: A static page or full HTML document on a website. Paid Referrals: A way to access a website by a paid referral via an ad, sponsored content, or other paid call to action. Path: The way a visitor travels through a website. Reach: The number of people reached by a specific ad, social media post, or website; typically a size of an audience. Redirect: Sending a visitor from one URL to another to find the page they’re looking for; too many redirects can reflect negatively on a website’s rankings. Return on Ad Spend (ROAS): Evaluating how successful an ad campaign is by seeing how cost effective it was. Return Visitor: A visitor who returns multiple times to a website, identified either through cookies or through a log-in authentication. Sampling: A selection of an audience that represents the whole, to use for data analysis. Search Engine Optimization (SEO): An approach by which a website can better optimize itself for higher rankings and search returns by using keywords, header tags, links, and more. Search Engine: A service that allows users to search the web for keywords and phrases, and returns both paid and organic website listings from their indexing that matches the search. Session: The time in which one visitor browses through a website. Site Content: A list of all content, including pages or other assets, that are contained within a website. Site Performance: The overall success of a website in terms of conversions, page visits, content views, and more. Site Search: The search within a website (not a search engine). Site Traffic: The number of visitors that access a website over a given time period. Social Referrals: A way in which visitors find a website via social media links. Stickiness: The ability of a website to keep visitors from leaving, and to continue to navigate within the site instead of exiting. Traffic: Visitors to a website. Uniform Resource Locator (URL): A specific, named address with which to identify and access a website. Unique Visitor: One specific visitor to a website, identified by a cookie, authentication, or IP address. Visits: An individual visit to a website or a web page; may not be a unique visitor, but the number of visits (of which a unique visitor may be counted multiple times). Web Analytics: The measure of visitors on a website, which pages they visit, how they accessed the website, and more, in order to give insight into site success or improvements. Web Analytics Dashboard: An online dashboard (via Google Analytics or a native web platform) that displays all visitor and usage metrics for a website. 1.3.6 Data and Privacy Access to data is important for marketers. It makes it possible to deliver the advertising messages to the right audience, optimize marketing campaigns, and measure the outcome of marketing action. But we shouldn’t forget that all that data is related to user behavior and while users may be okay with sharing some data, there are limits. 1.3.6.1 Consumer Perspective Our online experience heavily relies on advertising, with 86 percent of the media consumed in the US being supported by advertisements. Many of these ads are customized to individual preferences using data provided by users like you and me. This data is instrumental in making inexpensive and free content available online. However, it’s important to recognize that not all data is equal in this context. Advertising serves as the cornerstone of the majority of our online interactions and typically either partially or fully funds our digital experiences. This business model is not new; it has long been prevalent in various forms of media such as newspapers, magazines, TV, and radio. While users may pay for access to these platforms, advertising remains the primary source of revenue supporting content creation. While some of us might wish for an ad-free experience, the reality is that without advertising, accessing content would likely come at a cost or be less freely available. Many individuals have come to accept ads as an integral part of their online experience. As you browse the web, you’ve probably encountered ads that felt tailored to your interests and others that seemed irrelevant. The spectrum of online advertisements ranges from captivating to irritating. Often, the ads that resonate most with us are those customized to our specific interests. Surprisingly, these personalized ads also tend to be the most effective. However, for some individuals, even these tailored ads can evoke a sense of intrusion. As we’ve come to understand, personalized ads tailor their content to our individual interests by leveraging data collected from our online activities and privacy settings. A clear differentiation can be made between data consciously provided by consumers—such as when filling out interests or demographic details during the sign-up process for social media platforms—and data derived from individuals’ browsing habits, which is often collected unintentionally. It is this latter type of data that consumers are typically most concerned about when considering their online privacy. Based on a survey conducted by the Pew Research Center, 72% of Americans express a sense of being constantly monitored by advertisers, technology firms, or other companies while engaging in online activities or using their cell phones. Additionally, a significant 81% of Americans believe that the potential downsides of data collection by companies concerning their personal information outweigh any benefits. Seventy-nine percent of adults express concern, to varying degrees, about how companies utilize the data they gather about them. A study published in the Harvard Business Review, discovered that consumers exhibit less apprehension when companies utilize information directly provided by them, in contrast to conclusions drawn from their browsing activity. The distinction between engaging, personalized advertisements and intrusive ones is exceedingly delicate. As we embark on our journey as a marketing analyst, it’s crucial to prioritize consumer privacy concerns. While access to data in advertising is undoubtedly advantageous and enhances marketing effectiveness, it’s equally essential to maintain a balance between data utilization and consumer trust. Consumers are increasingly aware that their online activities are being tracked, yet they often feel uneasy about the sharing and utilization of their browsing behavior data for advertising purposes. This discomfort may prompt some consumers to take action in response to these concerns. As a marketing analyst, being aware of how consumers can assert control over their own data and content is essential, as it provides insight into the limitations of the data available for analysis. Consumers have access to several tools that enable them to restrict the information they share online and control how it is utilized. Three of the most prevalent and easily accessible tools include ad blockers, cookie blockers, and VPNs (Virtual Private Networks). These tools empower consumers to manage their online privacy effectively. Ad blockers are software designed to prevent advertisements from displaying on webpages. Typically, these tools are browser plugins that users can install to block ads while browsing. For instance, two popular ad blockers are Adblock Plus and uBlock Origin, both of which can be easily added to commonly used web browsers. While consumers enjoy the ad-free browsing experience these tools offer, it’s important to note that a significant portion of content publishers and creators rely on ads to fund their work. Both Adblock Plus and uBlock Origin offer the option for users to whitelist specific sites, allowing ads to be displayed on those sites while still blocking ads on others. Some publishers and websites are transparent about this process and directly request users to disable their ad blocker or whitelist their site to support ad revenue. Another tool consumers can utilize to control the data they share online are cookie blockers. Similar to ad blockers, cookie blockers are browser plugins that prevent data from being stored through cookies. Unlike ad blockers, which primarily focus on blocking ads, cookie blockers limit or entirely prevent the collection of data about users’ browsing behavior. This reduces the amount of information advertisers receive about users and their online habits, even though users may still see ads tailored to their interests. Two popular cookie blockers are Privacy Badger and Ghostery, both of which are browser plugins that users can add to enhance their online privacy. As mentioned earlier, the landscape of cookies and their utility is evolving alongside changes in browser settings and user acceptance. Consequently, the perceived value of cookies to advertisers is shifting, and over time, consumers may find less necessity in blocking them. Another privacy tool consumers can utilize is a VPN, or virtual private network. A VPN anonymizes all internet traffic leaving a user’s device by routing it through an intermediary server. This effectively conceals the user’s IP address, location, and personal information. However, it’s important to note that VPNs may still allow for tracking based on browsing habits and patterns. There are numerous VPN options available, including both free and paid services. Some VPNs are integrated directly into devices and browsers. Despite the variety of options, the fundamental functionality of all VPNs remains the same. Next, let’s delve into an overview of some settings consumers can adjust on their devices to enhance their privacy. If you’ve ever explored the settings on your phone, you’re likely aware of the numerous specific settings and privacy preferences available on all major devices. For our discussion, we’ll focus on three overarching concepts: location, tracking, and permissions. Consider the multitude of modern devices capable of tracking a consumer’s location, including cell phones, tablets, laptops, and smart-watches. On each of these devices, users have the ability to control how, when, and to whom their location data is accessible. Typically, these settings can be found within the location services menu. Another setting consumers have some control over is how and by whom they are tracked online. While these settings may vary across platforms, in Apple’s iOS, for example, users can access a tracking menu under the Privacy settings. This menu enables users to specify which apps are permitted to track their activity. Permissions, as an umbrella term on most devices, allow users to fine-tune what information or functions apps and websites can access. For example, you may want your favorite photo-sharing app to access your camera, but you might not want to grant the same permission to a grocery shopping app. Similarly, various online platforms offer a range of privacy controls. On social media, users have control over their content, communication, and interactions. They can typically delete posts, disable incoming messages, and customize the personal information visible to the public. These specific controls complement the platform’s privacy policy, offering users greater autonomy over their online presence. Websites and apps that collect data about users are required to have a privacy policy, typically accessible alongside the terms of service. Social media platforms recognize the importance of consumer privacy and often provide tools to facilitate user control. For instance, Facebook offers a privacy checkup tool within its app, making it convenient for users to manage their settings. Despite advertising being a significant component of social media platforms, users can still determine the extent to which their data is used for advertising purposes. These controls are usually found in personal settings. As consumers online, individuals have considerable control over the information they share. You might wonder why a course on marketing analytics would emphasize ways to block or control data sharing. While marketers generally prefer access to more data, they also recognize the importance of maintaining user trust. Understanding the limitations and gaps in the data available for analysis is crucial for a marketing analyst. Recognizing these limitations resulting from consumer controls provides insights into the boundaries of data accessibility and helps maintain transparency and trust in marketing practices. 1.3.6.2 Advertisers Perspective Now, let’s shift our focus to the advertiser’s perspective and examine what it means to be a responsible advertiser when working with consumer data. First, we’ll delve into the concept of responsible advertising and the obligations advertisers have towards consumers when utilizing their data. Then, we’ll explore the advertising ecosystem, highlighting the various parties involved in handling user data and their shared responsibilities. Lastly, we’ll discuss the ownership and management of data, shedding light on who ultimately controls and oversees the data used in advertising practices. This shift in perspective will underscore the importance of data in advertising and elucidate the ethical responsibilities that advertisers bear when leveraging consumer data. Since the early 2000s, advertisers have made a significant shift in their approach. They’ve moved away from relying solely on contextual advertising, which involves placing ads on pages or in locations with relevant content. Instead, they’ve embraced data-based advertising, which targets consumers based on their individual interests and behaviors. To illustrate, imagine a contextual advertising scenario where an ad for running shoes appears on a website dedicated to running enthusiasts. However, with data-based advertising, the targeting becomes much more refined. For instance, an ad for running shoes could pop up on a news website, but it would be shown specifically to a consumer who has previously shown interest in running. In this model, the context of where the ad is displayed becomes less critical than ensuring it reaches the right audience. The effectiveness of data-based advertising relies heavily on the availability of data. Without access to information about consumers’ interests, habits, or needs, advertisers would be limited to using only contextual advertising strategies. Data-based advertising is highly effective, and advertisers are eager to utilize data to target their ads to the right audience. However, when advertisers handle and utilize data, they bear the responsibility of providing consumers with three key elements: value, transparency, and control. First and foremost, it’s crucial for consumers to perceive the value in allowing their personal data to be used for advertising purposes. This could manifest through access to inexpensive or free content, personalized experiences, or innovative marketplace offerings, all of which enhance the consumer’s overall experience. Secondly, advertisers must prioritize transparency regarding the origin and usage of data. For instance, if you’ve recently encountered a personalized ad, you might have noticed additional information indicating why you’re seeing that specific ad. An example of this is the ad choice flag, provided by the Digital Advertising Alliance (DAA), a consortium of advertisers striving to enhance transparency in data-based advertising. When users click on this icon, they gain insight into how and why they’re being targeted with that particular ad. This initiative by the DAA represents a genuine effort to make advertising practices more transparent and consumer-friendly. Finally, an advertiser has a responsibility to highlight consumer’s control over their data. Consumers might be fine with their personal data being used in one situation, but as we’ve covered in an earlier lesson, they worry about losing control over who else might have access to that data. Consumers own their personal data and reminding them of that control might actually be a win-win. Research shows that when consumers are reminded about the controls they have over their personal data, they’re actually more likely to engage with an ad. To summarize, advertisers are expected to provide value, transparency, and control to consumers when working with the data users provide them. In this lesson, we’re going to explore the four major components of the advertising ecosystem and how personal data and consumer privacy reef through it. The advertising ecosystem can be broken down into four sections: - consumers, - advertisers, - publishers and partners, - regulators and gatekeepers. These four groups all interact with each other in different ways and they create a complex web that’s at the core of data-based advertising. Let’s look at these four groups individually and how they influence the ads you see as a consumer. 1. consumers: First, the consumer is the person that’s most important to a business. We’ve already covered in previous lessons what a consumer is comfortable sharing and how an advertiser can responsibly use that shared information. advertisers: Next, on the other side of the advertising ecosystem web is the advertisers. We’ve broken down the many ways that data can be useful to advertisers to make ads more relevant. publishers and their partners: After an advertiser has crafted the ad and identified its target audience, it is then sent to publishers and their partners. Publishers refer to websites and apps that produce and distribute digital content, often partially funded by advertisements. These ads are optimized using data provided by consumers to these platforms. When publishers effectively connect brands with individuals likely to be interested in them, advertisers are more inclined to invest in their platforms or sites. This connection is facilitated by data. Publishers serve as the most direct link to consumers and are well-attuned to the needs and feedback of their audience. Publishers must carefully balance the interests of their consumers, their own brand, financial considerations, and technical requirements with each ad displayed alongside their content. Thus, making informed decisions is crucial. Publishers frequently collaborate with partner companies such as ad exchanges and measurement providers. Ad exchanges act as systems and intermediaries that facilitate automated buying and selling of advertising inventory between advertisers and publishers. These systems rely on data gathered from publishers, advertisers, and various ad inventory platforms. Measurement providers encompass third-party entities and ad providers offering solutions for evaluating the effectiveness of advertising. This enables publishers and advertisers to assess the performance of ads and refine their strategies accordingly. gatekeepers and regulators: The final stakeholders in the advertising ecosystem are the gatekeepers and regulators. This encompasses a broad array of entities, including companies, industry groups, and government agencies, all of which play a role in determining how private data can be utilized in advertising. We’ll specifically examine three types of gatekeepers: browsers and device platforms, governments, and industry organizations. In the digital realm, any advertisements encountered by consumers ultimately appear on a device or browser. Therefore, these browsers and devices hold significant importance within the advertising ecosystem. Rules or restrictions implemented by browsers and devices can profoundly impact their user base as well as advertisers aiming to engage with them. Governments increasingly play a regulatory role in overseeing the collection and usage of personal data in advertising. Legislation such as GDPR, CCPA, and COPPA places limitations on the extent of personal data that can be collected and dictates how such data may be utilized. We’ll delve deeper into these regulations later on. Additionally, industry organizations contribute to shaping data and privacy regulations. These groups comprise members from various sectors of the advertising ecosystem and work towards fostering a better understanding of privacy issues and encouraging their adoption within the advertising industry. The digital advertising ecosystem can be intricate, so let’s illustrate it with an example. Previously in this course, we discussed DDC Cleaning and their launch of SnackWall, a subscription snack service for businesses. James, representing DDC Cleaning, aims to advertise SnackWall to reach his target audience. James takes on the role of the advertiser, while the target audience represents the consumers. Recognizing Facebook as an ideal platform for his ads, James selects it as the publisher he plans to collaborate with. Facebook will leverage its user data and insights to ensure James’s ads reach the intended audience. However, James acknowledges that not all potential consumers may be active on Facebook. To broaden his reach, James seeks advice from an advertising agency, which recommends utilizing an advertising exchange to place ads across a wide range of websites. This allows James to tap into the browsing behavior data of numerous consumers to effectively target his ads. James’s agency partners with OpenX, an example of an advertising exchange, which assists publishers in monetizing their content by placing ads alongside it. While James’s ads won’t reach every individual in his target audience, they will be delivered through browsers and devices, subject to certain data collection limitations imposed by publishers and their partners. Compliance with regional laws and regulations regarding data usage is also essential for the publishers and partners James collaborates with. 1.3.6.3 who owns data Let’s take another look at data-ownership in light of data privacy depending on who collects and manages the data. There are different restrictions and regulations of course, as a consumer, you are always the owner of your data, but you can engage in a relationship with a publisher or an advertiser where you allow them to use your data. As we saw earlier in this course, the parties that you allow to collect and store your data fall into three different groups depending on how direct your relationship is with them, first party, second party or third party. First party data is the data a company receives from the people it’s interacting with directly. These people could be customers, visitors to the website or followers on social media. For example, if you’re using a social media platform and you click on an ad for Pizza, the platform may infer that you are interested in Pizza, that information is considered first party data that the social media platform is now managing about you. With first party data, there is an implicit or explicit agreement between the consumer and the data receiving company that it can use your data. Of course, with certain restrictions, as we saw earlier. Second party data consists of the same type of data is the first party data, but in this case the data has been passed on to a second party, often a trusted partner of the first party. Continuing the metaphor, if the social media platform you signed up for earlier gives information to a partner, that partner company also knows that you like Pizza then both managed that data about you. In this scenario, ideally the partner is trustworthy and responsible with the data that was passed on from the first party social media platform and it’s the responsibility of the first party to ensure that the second party won’t misuse your data. If not, the repercussions would involve both parties first and the second party. The final bucket that personal data can fall into his third party data. Third party data is collected by a company or entity that doesn’t have a clear relationship with the company a person is interacting with or the first party. Third parties may track a person’s behavior across sites, for instance, using browser cookies, which we call third party cookies. Information gathered this week can be bundled together to create a profile about a person that can then be sold to advertisers. Using our metaphor one more time, if a third party tracks your behavior across the web, they might learn about your interest in Pizza, even if you didn’t specifically give that information to them. This type of information gathered is the kind that makes consumers most uncomfortable, since people don’t have an explicit agreement with these third parties that allows them to collect and store this information. Third party data tracking often raises privacy concerns. As a result, several browsers block third party cookies to help limit this kind of data collection. It’s important that all parts of the advertising ecosystem, first, second or third parties set and maintain high privacy standards. That’s the only way that a consumer can trust and have confidence that their information is being handled appropriately. 1.3.6.4 Regulations Around the globe, governments are taking on a role in regulating how personal data is gathered and used. It’s important for marketing analysts to know about these laws as they regulate how user data can be used, and of course, as a consumer, it’s also good to know what your rights are. All three of these regulations affect how much and what type of data an advertiser can use for data-based advertising. GDPR: GDPR stands for the General Data Protection Regulation. It’s a law that protects data and online privacy in the European Union. GDPR is a very detailed and pretty complex law. At a high level, we can group some of its key requirements in two buckets: European citizen data rights and data protection obligations for companies who collected the data. Right to access: The law specifies that people have the right to access the personal information received about them, Right to correct: they have the right to correct that information Right to erase: the right to have all the information that was collected and saved about them erased Right to data portability: they have the right to data portability In other words, they have the rights to get a file of their personal information and pass it on to another party. As for the data protection obligations, the law specifies how companies must protect the information they receive. It also specifies that companies must alert people within 72 hours if their personal data was leaked, and companies must designate people whose job it will be to protect the data they received. The law also says that companies should limit their data collection and that certain data categories are prohibited, for instance, ethnicity and sexual orientation. Before receiving any data, companies should ask for permission. This is the right to prior consent. GDPR was developed and is managed by the European Union. Any company that works with the personal data of EU residents must comply no matter where the business is based. In practice, this means that most digital businesses have to comply with this law. The different EU countries each have their own supervisory authorities that monitor compliance. Fines related to GDPR can be substantial, up to four percent of the annual revenue of a company. In October 2020, clothing retailer H&amp;M was issued of $41 million GDPR fine after several hundred employees were found to be illegally under surveillance. The company kept extensive profiles of employees, families, illnesses, and religious beliefs. The Data Protection Authority of Hamburg, Germany found that this case showed a disregard for GDPR data protection rules. Laws like this and fines of this magnitude have reinforced how seriously the European Union is taking personal data privacy. CCPA: In 2019, the Governor of California signed into law the California Consumer Privacy Act. The strictest of any consumer privacy laws in the US, this law aims to give residents of California more privacy and protection. This law is not dissimilar from the GDPR, the law wants to give consumers more insight into what data is collected about them and say whether or not they want their data collected. There are five distinct rights the CCPA gives to consumers. The right to know what information is collected about them, the right to know whether they’re data is sold and to whom, and the right to opt out of that sale, the right to access to personal information that was collected about them, the right to require the business to delete their personal information, and finally, the right to not be discriminated against for exercising their rights under the act. The CCPA falls under the responsibility of the California State Attorney General’s office. Any business that collects and controls the personal information of California residents should comply with the CCPA. The California Attorney General and residents of California can initiate lawsuits. Fines under the CCPA can be up to $7500 for intentional violations and $2500 for unintentional violations. The law went into effect in January 2020. It’s still a bit too early for any high-profile lawsuits under this law. COPPA: COPPA or the Children’s Online Privacy Protection Act. This US law took effect in 2000, and limits the collection and use of personal information of people under the age of 13. COPPA was specifically designed to protect children. It requires that notice be given and parental consent is obtained before any personal information is collected from children. It also requires that companies have a clear and comprehensive privacy policy, and companies that collect data from minors need to keep that data confidential and secure. COPPA is managed by the US Federal Trade Commission or the FTC. All companies that interact with children under the age of 13 in the US must comply with COPPA. The FTC relies on people to alert them to violations of COPPA and those complaints can prompt an investigation. Fines related to COPPA can be fairly substantial, up to $40,000 per violation. Here’s one example of a high profile case that violated COPPA. In 2019, Google was find $170 million for collecting and saving personal information from children and using it for advertising on YouTube. Needless to say, violations can be costly, not only in terms of the fines, but also in terms of the consumer trust that is lost. This was just a high-level overview of the most prominent laws governments have established to regulate the collection and use of personal data. There may be other local regulations, so depending on the region you work in, it’s worth checking which laws are in place. 1.4 Marketing Analytics Here are three types of marketing analytics: Predictive Analytics: Predictive analytics enables you to forecast the potential outcomes of marketing campaigns and estimate the likelihood of future events. This type of analysis provides insights into future trends and behaviors, allowing you to anticipate how the market is likely to respond to your advertising efforts. For example, it can predict customer responses, sales increases, or changes in market share based on past data and statistical models. Descriptive Analytics: Descriptive analytics focuses on understanding past and present data to identify patterns and trends. It provides a comprehensive view of what has happened in your business, such as customer behaviors, sales performance, and market conditions. By analyzing historical survey data from customers, you can gain valuable insights into their preferences and past behaviors, although this analysis doesn’t guide you on future actions. Prescriptive Analytics: Prescriptive analytics goes beyond predicting future outcomes by recommending specific actions to achieve desired results. It analyzes data to suggest the best courses of action to take. For instance, if your company needs to address customer concerns about high salt content in products, prescriptive analytics can provide actionable strategies to mitigate these concerns and improve customer satisfaction. It helps you understand the optimal decisions to make in order to achieve your business objectives. 1.4.0.1 AIRBNB EXAMPLE Strategic challenge: how do we improve rental prospects for our hosts and identify better rental options for our guests? Mental Model: Profit per Property Gross Margin (%) Profit per Property &lt;- Price, # of rentals, minimum stay What is the value of brands? Brand is not just a name, color, shape or logo. It is a complex entity. Brand personality is part of larger concept of brand architecture. Analytics help us identify how marketing affects brand architecture. Marketers use data to tweak features and benefits to create a stronger connection between customers and the brand Marketers analyze data around marketing campaigns and their impact on all the components of brand architectures. Product attributes: features of the product. What a brand means to a consumer. Customers buy benefits, not features. When building up brand architecture, knowing the benefits helps with consistent messaging to consumers. Brand personality contributes to the strength of a brand, but isn’t used to determine brand strength. The architecture of a brand is not part of calculating brand value, but it is important to understand what the brand means to consumers. 1.4.0.2 Measuring Brand Value 1.5 Data Analytics We can define data analytics as the process of collecting, cleaning, organizing, analyzing, and interpreting data to uncover insights and make informed decisions. 1.5.1 Data Analytics vs. Data Science As you continue to learn about data, you will come across tons of data-related terminology. Among these are two often-confused terms: data analysts and data scientists. These two roles are similar in the sense that they both work with data to gather insights, but how they work with data is what sets them apart. In this reading, you will learn the differences between these two disciplines by reviewing their roles, responsibilities, skills, and backgrounds. Data Analysts Data analysts work with structured data to identify patterns, build visualizations, and extract meaningful insights that help organizations make informed decisions. Responsibilities Data analysts are typically responsible for maintaining databases, interpreting data sets, and creating reports that effectively present data trends, patterns, and predictions. Some common tasks include gathering data from various sources, cleaning and organizing data, and presenting findings in easy-to-understand visualizations. Skills and Tools Foundational mathematics and statistics Analytical thinking and data visualization Basic fluency in R, Python, and SQL SAS, Excel, and business intelligence software Background Data analysts are commonly experienced in mathematics and statistics. They might also have a degree in mathematics, statistics, computer science, or finance. Data Scientists Data scientists work with various data types, including structured and unstructured data. They use advanced data techniques, including machine learning and predictive modeling, to design processes, develop models, and extract insights from data. Responsibilities Data scientists are typically responsible for arranging undefined datasets, writing algorithms, building automation systems, and statistical models. Some of their common tasks include gathering and cleaning raw data, creating data visualization tools, dashboards, and reports, and developing code to automate data collection and processing. Skills and Tools Advanced statistics and predictive analytics Machine learning and data modeling High-level, object-oriented programming Hadoop, MySQL, TensorFlow, and Spark Background Data scientists are commonly experienced in computer science and are generally required to have a master’s or doctoral degree in data science, information technology, mathematics, or statistics. Although their titles are similar, data analysts and data scientists have distinct roles, requirements, and career paths. Now that you know the difference between the two, consider this as you continue your journey in data analysis. Conclusion Although these two disciplines are very similar and often go hand-in-hand in terms of skills and how they work with data, there are some subtle differences to keep in mind as you explore which focus you’d like to pursue in how you work with data. 1.5.2 OSEMN Framework Overview Obtain: Gather the data • Determine what data would be useful • Evaluate what data are available • Decide on how the data can be gathered Scrub: Clean the data to prepare it for analysis • Correct inconsistent formatting • Remove duplicate records • Handle missing values • Remove inaccurate information Explore: Search for interesting patterns and statistics that stand out • Examine variable distributions • Examine variable relationships • Perform statistical tests Model: Generate predictions and insights • Select a model type for your goals (often in cooperation with a partner) • Categories of models include: o Classification - Is this “A” or “B”? o Regression - How much or how many? o Clustering - What natural segments can we find in our data? iNterpret: Help others to understand the results of your analysis • Build visualizations • Construct stories • Create presentations of your findings 1.5.3 Obtaining Data 1.5.3.1 Sampled Data Sampled data is data from a subset of a larger population or a larger data set that’s used to represent the entire population or data. In other words, you are a smaller number of data, that’s a good representation of the total data set you would like to study. It’s a common practice in data analytics to sample data, because analyzing the entire population can be costly, time consuming, or even impossible. Sampling allows us to draw conclusions about the population while only analyzing a fraction of it. Let’s run through some situations where sampled data is necessary. First, the population might be too large. When dealing with large data sets or populations, analyzing the entire data set can be impractical or impossible. Imagine you are a market researcher and you work for a large auto manufacturer, the company wants to get a better understanding of their customer satisfaction. They would like to know how satisfied their car buyers are with the performance of the cars, as well as with the service they’re getting from the dealerships. You know, you can get all this information using a survey in which you ask customers questions about their experience and have them rate how satisfied they are. But because your company has hundreds of thousands of customers, it’s not practical to send a survey to each individual who owns one of your cars. Instead, you decide to send a survey to a sample of your customer base, a smaller group of customers that you will select as a representation of the larger customer population. Second, and related to the first point, you might have cost constraints, collecting data from an entire population can be expensive. Sampling can be more cost effective, allowing researchers to allocate resources to other important tasks. In our example, for the car company, surveying everyone would cost a lot of money just in getting the surveys out to everyone. But it would cost you even more to get responses from all these customers. You might need to use incentives to get customers to answer, which could cost a lot of money if you’re talking to hundreds of thousands of people. You could also face time constraints, collecting data from an entire population can also be time consuming. Sampling can save time and allow researchers to collect and analyze data quickly. For our car company, collecting responses from a very large group of people would take you quite a bit more time than focusing on a smaller number of customers who bought a car from your company. In some cases, it might not be possible to analyze the entire population because it would be destroyed in the process. Data analysts refer to this as destructive sampling. For example, testing every product manufactured in a candy factory would result in the destruction of the entire inventory and the destruction of your teeth, but that’s not really what’s referred to here. So for all of these reasons, you might be dealing with a subset of the data instead of the whole data set, or in other words, a sample. But when you work with sample data, there are a few things you should consider to help you evaluate the quality of your data. First, the sample size. Sample size is the number of observations in the sample. A larger sample size generally provides more accurate estimates of the population. If the sample size is small, it might not give you enough to work with, and the data might not accurately represent the population. A smaller sample will also limit the types of analyses you can perform on your data, because certain analyses require many observations to provide an accurate result. In other words, if you want a reliable analysis, larger samples are usually a must. The sample should also be representative of the population being studied. If the sample is biased, the conclusions drawn from the sample might not be valid for the entire population. Let’s say you are conducting a study on the average salary of employees in a certain company. The company has a total of 1000 employees, and you decide to survey 50 of them to collect data on their salaries. However, you only choose to survey employees who work in the finance department because you assume that their salaries will be representative of the entire company. In this scenario, the sample is not representative of the entire population of the company because it only includes employees from one department. The sample is biased towards finance employees and might not be accurate for the entire company. This can lead to incorrect conclusions being drawn from the data, such as assuming that the entire company has a higher average salary than it actually does. To ensure representativeness, it would be better to use a more random sampling method that includes employees from different departments and positions. Such a sample would better represent the entire company, and it will give you a more accurate read on the average salary. Another important thing to think about when using samples is the generalizability of your sample. The conclusions drawn from the sample might not be applicable to other populations. It’s important to be aware of the limitations of the sample and not over generalize the findings. Let’s say you are conducting a study on the eating habits of college students in a particular university. You decide to collect data by surveying 100 randomly selected students who attend to university. However, your study only includes students who attend that specific university, which means that the conclusions drawn from the study might not be generalizable to all college students or to the population at large. This is because the students attending that university might have different demographics, cultural backgrounds, and socioeconomic statuses compared to students at other universities. For example, the university in question might be located in an urban area and attract more students from low income households. This means that the study’s findings might not be applicable to students attending universities in suburban or rural areas or students from higher income households. Therefore, it’s important to consider the generalizability of the sample when conducting research to avoid drawing incorrect conclusions or making incorrect generalizations about a larger population patient. Conclusion: Sampled data is a useful tool in data analytics when dealing with large populations or data sets. However, it’s important to consider the sample size, representativeness, and generalizability when working with sampled data to ensure that the conclusions drawn are valid. 1.5.3.2 First-Party Data Definition: First-party data refers to information collected directly by a company or organization from its own audience, such as customers, website visitors, or app users. This data is considered highly valuable because it is unique to the company and typically involves direct interactions with the brand. How It Is Collected: Website and App Analytics: Data collected from user interactions on a company’s website or mobile app, such as page views, time spent on pages, click-through rates, and purchase history. Customer Relationship Management (CRM) Systems: Information gathered from customer interactions, including contact details, purchase history, and customer service interactions. Surveys and Feedback Forms: Direct input from customers through surveys, feedback forms, and user reviews. Email Marketing Campaigns: Data collected from email open rates, click-through rates, and responses to email campaigns. Loyalty Programs: Information from customer participation in loyalty and rewards programs. Who Collects It: - Businesses: Retailers, e-commerce platforms, service providers, and any organization with a direct relationship with customers. - Organizations: Non-profits, educational institutions, and government agencies collecting data from their members or service users. 1.5.3.3 Third-Party Data Definition: Third-party data refers to information collected by entities that do not have a direct relationship with the users from whom the data is derived. This data is aggregated from various sources and sold to other companies for marketing and analytical purposes. How It Is Collected: - Data Aggregators: Companies that specialize in collecting data from multiple sources, such as websites, apps, public records, and social media platforms. - Purchase and Usage Data: Information gathered from third-party apps and services that users interact with. - Cookies and Tracking Pixels: Data collected through cookies and tracking technologies placed on various websites to monitor user behavior across the web. - Public Records and Social Media: Information pulled from public databases and social media platforms where users share data publicly. - Surveys and Panels: Data collected from third-party surveys and consumer panels, where participants opt-in to share their information. Who Collects It: - Data Brokers: Companies like Acxiom, Experian, and Nielsen that gather, compile, and sell data to other businesses. - Advertising Networks: Ad networks like Google AdSense and Facebook Audience Network collect data to target advertisements more effectively. - Market Research Firms: Organizations that conduct market research and compile data from various sources to provide insights to businesses. 1.5.3.4 Key Differences Source of Data: First-Party: Directly from the company’s own customers or users. Third-Party: Indirectly from external sources without a direct relationship with the data subjects. Data Quality: First-Party: Typically more accurate and relevant, as it comes from direct interactions. Third-Party: Can be broad and extensive but might lack accuracy and specificity due to aggregation from various sources. Control and Privacy: First-Party: Companies have full control over data collection and usage, often leading to better compliance with privacy regulations. Third-Party: Companies must rely on the data provider’s compliance with privacy laws, which can introduce risks. Usage: First-Party: Primarily used for enhancing customer experience, personalization, and direct marketing. Third-Party: Used for broadening customer insights, expanding reach, and enhancing advertising targeting. 1.5.3.5 An Overview of Helpful Free Datasources Accessing data is simpler than ever, and there is a wide range of helpful data sources at your disposal. Here’s a list of free data sources to help you gather information and insights more effectively, along with links to those resources. Google Public Dataset Search Like Google Scholar, Google Dataset Search provides access to millions of datasets hosted on public websites, such as Kaggle and OGD Platform India, in thousands of locations on the internet. United States Census Bureau The United States Census Bureau provides access to quality and essential data about the United States’ population, economy, and geography. Pew Research Center The Pew Research Center provides insights and analysis on a wide range of social, political, and technological issues through surveys and research. Eurostat As the European Union’s statistical office, Eurostat provides comprehensive economic, social, and environmental data. The Organization for Economic Co-Operation and Development (OECD) The OECD is a reliable source for comparative data and analysis on global economic and social matters. Kaggle Datasets Kaggle hosts hundreds of thousands of high-quality public datasets from several industries to explore, analyze, and share. National Centers for Environmental Information (NCEI) NCEI is part of NOAA’s Office of Oceanic and Atmospheric Research and provides environmental data regarding climate change and global chemical measurements. World Bank Open Data This comprehensive dataset includes indicators such as population size and unemployment rates collected from hundreds of countries worldwide, offering insights into global economic, social, and environmental trends. 1.5.3.6 Summary: Validity of Data When obtaining data, it is important to check the validity of your dataset, or in other words, ensuring your data are of high quality so you can move on to the explore and analyze phase. Here is a checklist you can use to ensure the validity of your data Source credibility: ⏹ Authorship: Is the data provided by a reputable author or organization? What are the credentials of the author or organization? ⏹ Publication date: Is the data current and up-to-date? Methodology: ⏹ Sample size: Was the data collected from a large enough sample? ⏹ Sampling method: Was the sampling method unbiased and representative? ⏹ Data collection: Were the data collection methods clearly described and appropriate? Objectivity: ⏹ Bias: Are there any apparent biases in the data or its presentation? ⏹ Conflicts of interest: Are there any potential conflicts of interest that could influence the data? Accuracy: ⏹ Consistency: Are the data consistent with other reputable sources? ⏹ Error rate: Are there any obvious errors or inconsistencies in the data? Relevance: ⏹ Scope: Is the data relevant to the research question or topic? ⏹ Context: Is the data presented within a meaningful context? 1.5.4 Scrub the Data Clean your data to ensure that it is usable for the next phases where you will explore, model, and interpret your data. What does it mean to scrub your data and why is it so important? Scrubbing data is sometimes also referred to as cleaning data. The scrubbing face transforms raw, dirty data into clean data. The scrubbing process can be divided into four main tasks: Removing duplicates, Formatting records, Solving for missing values, Checking records for mistakes or wrong values. Dirty data is any data that contains duplicate records, is inconsistently formatted, has missing values, or contains inaccurate information. In contrast, clean data contains only unique records, has a consistent structure, has no missing values and contains reliable and accurate information. Ensuring your data is clean is an essential step before analyzing the data for further insights. Without the scrubbing stage, the errors in your data might affect your exploration and analysis, and they can lead you to drawing the wrong conclusions. Or in some cases, they can mess up any analysis you want to do on the data or make any model you apply to your data gets stuck, making it impossible to draw any conclusions at all. 1.5.4.1 Scrubbing Checklist The scrubbing stage is all about cleaning your data and getting your dataset ready for analysis. You can use this checklist to help you in the process. Removing Duplicates ⏹ Identifying duplicate records: inspect records for duplicates and verify that they are actually a duplicate record. ⏹ Remove duplicate records: remove the duplicate records from your dataset Formatting records** ⏹ Ensure consistency: check all data follow a consistent format and adjust the format if necessary Solving for missing values ⏹ Identify the missing values ⏹ Solve for the missing values: Replace the missing values with text (e.g. NA) or delete the entire record with the missing value Checking for wrong values ⏹ Identify wrong values ⏹ Solve for the wrong values: Replace the wrong values with the correct ones if you can or delete the entire record with the wrong values 1.5.5 Exploring Data 1.5.5.1 Visualize data Anscombe’s quarter: 4 sets of data with same mean and standard deviation but all has different distribution. It is important to visualize data to really understand the relationships. 1.5.5.2 Data Distributions Normal Distribution Log-normal Distribution Exponential Distribution 1.5.5.3 Data relationships Correlations ** Causations** 1.5.5.4 Summary: Exploring Data Explore Checklist What is your data telling you? ⏹ Inspect your data: If your dataset isn’t too large, read through your data to assess whether interesting information jumps out ⏹ Use summary statistics: Evaluate your data by summarizing it (categorize, use statistics like average, standard deviation, etc.) ⏹ Inspect a random sample of your data: if your dataset is too large, a random sample may give you some initial information Visualizing data ⏹ Visualize your data using bar charts, line charts or scatter plots to examine information hidden in your dataset. Bar charts Line charts Scatter plots Examine variable distributions ⏹ Inspect the distribution of your data Categorize the data Plot the categorized data Common data distributions: Normal Bimodal Log-normal Exponential Uniform Learn more about your data: ⏹ Evaluate the minimum ⏹ Evaluate the maximum ⏹ Evaluate the mode ⏹ Evaluate the standard deviation Examine variable relationships ⏹ Visualize variables to understand their correlation Common visualizations: Scatter plot Line chart ⏹ Calculate the correlation coefficient to understand the strength of the correlation 0 = no correlation 1 = perfect positive correlation -1 = perfect negative correlation Feature engineering ⏹ Evaluate whether we can create new features or modify existing ones to better understand our data 1.5.6 Modeling We’ve obtained the data we needed, scrubbed it, and explored it thoroughly. Now, we’re ready for stage 4 “Modeling”. This phase is about using our data to make predictions with mathematical models. These models can be anything from simple linear regressions to advanced machine learning algorithms depending on the project. Although there are many different models, they all work by discovering hidden patterns in data and using it to make predictions on any new data we give the model. For example, you might build a model to predict how many conversions you expect a campaign to deliver. You would do that by using data from the past to predict the future. Our discussion of modeling is going to be broken down into the following 3 sections: What are models, how the models work, and the types of models? All of the steps of the OSEMN process are important, but modeling is a central piece of data analysis. ’’ All models are wrong but some are useful’’ Statistician Box 1.5.6.1 Real world Example In previous videos, we followed Keira, a data analysts working with Carlos, the owner of Inu and Neko, a dog and cat care company. Carlos had approached Keira to help and launch a new subscription meal service for cats and dogs and wanted to select the 10 best products to offer as part of the subscription. Keira started by obtaining the necessary data from their e-commerce software. She downloaded last year’s sales data into Google Sheets to analyze which products were most popular and purchased repeatedly. She obtained the data properly by making sure it was credible, collected accurately, objective, accurate, and relevant to Carlos’ questions. Keira proceeded to scrub the dataset, checking for duplicates, inconsistent formatting in the zip codes, and missing values like phone numbers and sales totals. She standardized zip codes for consistency and remove the phone number column because it was not crucial for analysis. Keira filled in missing sales stores by calculating product price multiplied by quantity. Some records lacked customer IDs, preventing the assessment of repeat buyers. So Keira deemed them unhelpful and removed them from the dataset. Lastly, she identified inaccurate information such as negative sales amounts and unusually high prices, recognizing them as glitches in Inu+Neko’s system and excluded them from consideration to maintain data accuracy for future analysis. Now that Keira has completed scrubbing the data successfully while addressing duplicates, inconsistencies, proportionate gaps, and inaccuracies, she’s ready to dive into our next topic; explore and model. In the explore and model stages of the OSEMN Framework, Kiera is now tasked with uncovering patterns and trends within the data and creating a model to predict subscription bundle preferences for Inu and Neko’s customers. During the explorer stage, Keira will perform various exploratory data analysis techniques to gain insights. This might involve using charts and visualizations to identify correlations between different product categories or demographic segments. She’ll also dive deeper into customer behavior by analyzing purchase frequency, average basket sizes, and seasonal trends. Once Keira has explored the data thoroughly. She can move on to modeling. Modeling involves using algorithms to create a predictive model based on historical data. Keira will develop models to help Carlos meet his goal of hitting 500 subscriptions. In the upcoming videos, we’ll follow Keira through the explore and model stages of the OSEMN Framework! Let’s get started! 1.5.6.2 Exploring Data Kira now has a clean set of data that she considers relevant for the question she got from Carlos at Inu+Neko: Which products should he include in the new dog and cat food subscription product to help him reach 500 subscribers by the end of the year? Kira gets started with Step 3 of the OSEMN cycle, she starts to explore the data. She thinks that a good place to start is to see what types of data are in each column. She sees that she has both categorical and numerical data. There’s a date column and text columns like order numbers and customer IDs. She notices that the order number and customer ID columns are very long and take up a lot of screen space and are hard to type. So, she decides to map each unique value to a number in a process called encoding. Encoding is the process of turning a string of data into numerical data by mapping each unique string to a unique number. Encoding can be used to reduce the amount of memory needed to work with data, or to make large, complex strings easier to work with. Can also be used to turn text data into numbers when a model needs numerical inputs instead of text inputs. In this example, Kira’s using encoding to make the data easier to view and understand. She also notices that there are quite a few columns that contain redundant information. A column is redundant if you could look at one column and always guess what’s in the other column. In this case, the customer ID and name are redundant. They might not always be, but for this product she knows it’s safe to assume, so she hides customer name. She also notices that SKU and product name are redundant as well, so she hides the SKU. She also decides that it is unlikely that this project will look at data at the street address level, so she only keeps the state and zip code. Great, now she can see all of the useful columns at a glance. And not having a large text columns even helps her computer run more smoothly. Next, she decided to run some summary statistics for the remaining columns. She looks at things like the most common value, how many times it appears, and what percentage of the rows it shows up in. She also looks at the minimum, maximum, range, and mean of the numerical values. From this, she sees that the data spans 899 days from the spring of 2019 through the summer of 2021. She sees that Texas is the most popular state, which makes sense because it is quite populous. There are also some numerical columns that she thinks could come in handy, like price and quantity. Kira decides to add up the total sales for each product and use a bar chart to look at the distribution of these total sales. This gives her exactly what she was looking for, the top selling products. She can also see from this chart that cat products tend to sell more than dog products. She realizes that it’s great to know what top selling products are, but it might also be important to know what causes those products to sell more. To answer that question, she creates a few scatter plots to observe the relationships between the quantities sold and different variables. One relationship that stands out to her is quantity sold and price. She notices that if she looks at just cat or dog products in isolation, the quantity sold is low for low and high-priced items, but high for items in the middle. This means that the two variables have a positive correlation for low prices, and a negative correlation for high values. This is great information to pass on to Carlos. Maybe adding more medium-priced items will help him find additional products for his subscription service. Kira now knows the top selling products and a possible reason for why those products are the top sellers. Kira’s ready to move on to the next stage in her analysis, the model stage. 1.5.6.3 Type of data Ordinal Data Ordinal data refers to a type of data that involves order or rank. Unlike nominal data, which is purely categorical and lacks any inherent order, ordinal data has a meaningful order among its categories, but the intervals between the categories are not necessarily consistent or known. An example of ordinal data is a survey response scale for customer satisfaction: Very Unsatisfied Unsatisfied Neutral Satisfied Very Satisfied In this example, the responses have a clear order (from very unsatisfied to very satisfied), but the difference between “Very Unsatisfied” and “Unsatisfied” is not necessarily the same as the difference between “Neutral” and “Satisfied.” This makes it ordinal because while the ranking is meaningful, the exact differences between ranks are not quantified. 1.5.7 Interpreting the Results The interpret stage is where you interpret your analysis. It’s arguably the most important. Without it, all we would have is data and statistics. The interprets stage translates your analytical findings back to a business context. After successful modeling stage, you’ll have a new tool like a regression model that can be used to generate predictions. The answers generated from these sorts of models are very specific and usually aren’t immediately interpretable or understandable by non-technical team members. During the interprets stage, our goal is to close the loop of the OSEMN cycle by using the models and insights we generated during the exploration and modeling phases to try and answer the business question driving the entire project. In other words here you look back at your objective for your analysis. Your goal here is twofold. First and foremost you need to understand the results of your model and all the insights it can provide. These might be the actual predictions the model makes, like forecasting the results of sales from a campaign or they might be information contained within your model like an insight that shows that mailing lists sign-ups are strong predictors of people spending more money with your company. Second, you need to be able to explain your findings to a non-technical audience in a clear concise way. Simply understanding the implications of your model isn’t enough. You need to be able to make others understand it and trust your results. Remember, analytics projects are about generating actionable insights or information that can be used to make better decisions that help the company. What was the objective of this analysis? It’s important to go back to your starting point because that will remind you of the questions you set out to answer. It’s quite easy to get lost in the data during the model and explore stages and lose sight of your initial question. How does the data answer my questions? Maybe the data shows you that the business goal you set is currently unattainable, or maybe it gives you a plan that you could use to move forward. What other learnings do I have? In the process of answering one business question, you will often find new pieces of potentially useful information that help solve the problem at hand in a different way. Or maybe they open up new potential business objectives you can address in later analysis. How can I apply this to a business context? Gaining new knowledge is great, but it is important to focus on information that’s actionable and moves your business forward in meaningful ways. It will often be someone else that takes action based on your information, so think about how that will happen. How confident should I be in my results? If you see an improvement in a business metric, was it due to the changes you made or was it due to random chance? Many data analysts are overconfident in their results, and when they implement what they have learned, they quickly discover that something was wrong with their analysis. That brings us to the topic of, how do you know if you should be confident in the results of your model? Earlier, during the modeling stage, we briefly discussed using a separate set of test data to check your trained model against. The testing process is all about ensuring you have the right amount of confidence in your model. By running your test data through your model, you can answer questions like, how wrong is the model on average? If the model predicts something, how likely is it to be correct or incorrect? Are there particular scenarios that cause the model to be incorrect? Even the best models have limitations, so it’s important to know what they are. On top of those basic questions, you can also use a tool called statistical testing to quantify how confident you should be. Statistical tests are mathematical methods of ensuring that differences are not caused by random chance. Sometimes this is called the significance of the results. For example, you’re trying to improve an email campaign. Your model recommends a change that you implement, and you see a 5% increase in sales. Great, you just made the company 5% more money, right? Well, not so fast, it’s possible that the increase in sales was random or because of some other factor. How can you know? You might run a statistical test and see that you should be 80% confident that the change in revenue was due to your new improved emails. It’s then up to you or your organization to decide how confident you need to be to take action. Sometimes organizations want to be between 90 and 95% confident to take action, other times, they’re happy with greater than 50%. It often depends on how risky it is for your business to be wrong. This is why statistical tests are so useful to businesses. So how do statistical tests work? To be honest, there’s a lot of complicated math involved that we won’t get into here. But there are some things they generally measure, including the differences in the averages of the datasets. If the averages are very different, the difference is less likely to be caused by randomness, the size of the dataset. The more data you have, the more confident you should be that the difference in averages isn’t random, even if it’s small. And the distributions of the datasets, this is often measured using standard deviation. A high standard deviation indicates high variability or that data values on average fall far from the mean. And a low standard deviation would mean that data in general is closer to the mean. If your data sets have high standard deviations, even large differences in their averages can simply be due to randomness. It’s important to note here that none of these metrics in isolation provide a quantifiable measure of confidence. Only by combining them using statistical tests can you measure confidence. The interpret phase of the awesome framework is crucial because it’s where data driven insights are evaluated and communicated. You must revisit your initial analysis objectives, understand how the data answers your questions, and uncover any additional findings. Moreover, it’s vital to ensure these insights are actionable within your business context. Tools like statistical testing play a key role, helping quantify your confidence in the results. And ultimately, the goal of the interpret phase and data analysis overall is not just to gain insights, but to make informed decisions that propel your business forward. the interprets stage of the OSEMN process This is where all the data explorations and number crunching finally pay off. This is also where we explain our findings and generate concrete recommendations for our organizations. Now that we’ve explored the entire OSEMN process to understand our model, we want to make the hard numbers tell a story. It needs to be a story that anyone in our team, not just the data experts can understand and act upon. This is a crucial step because it’s not just about having insights, it’s about communicating them effectively. An essential aspect of effective data storytelling is choosing the right medium to communicate your findings, and there are many different mediums you could use. Some examples could be a slide presentation or an interactive notebook, or an in-depth report for an executive review. Each of these comes with its own strengths and challenges, and being able to adapt your story-telling approach to fit each medium is an important skill in data analytics. Slide presentations are universally relevant across industries and job roles and provide a structured, visual and engaging way to take your audience through your findings and recommendations. Your presentation should recap the original goal, review how you went through the steps of the OSEMN cycle, visualize critical data points, and importantly, explain your findings and recommendations. Key components of a slide presentation Original problem Start your presentation by taking your audience back to the original problem that initiated your analysis. Re-introduce the issue at hand. What were we trying to solve? Why did we consider it necessary to undertake this analysis? Highlight the potential implications of not addressing this issue, illustrating why it was significant enough to warrant such an in-depth investigation. The purpose of this segment is to establish the context, helping your audience comprehend the relevance of the forthcoming findings and recommendations. The Method Now that you’ve established the context, take the audience through the method you used. In this example you’re going to take the audience through the steps of the OSEMN process that was followed. You want to maintain high-level overview, provide enough context for each step so the audience can understand the methods that lead to the insights. Remember, the goal here isn’t to dive into highly technical details. You simply want to build a clear picture of the process leading up to your findings. If you’re presenting to a more technical audience though, you might want to include more of the technical details. Now, guide your audience through a visual tour of the data, using aesthetically appealing and easy to understand visuals such as graphs, charts, and tables. You should try to encapsulate the core data points that lead to your findings. Make sure these visuals are accessible to a broad audience and designed in a way that even non data analysts can comprehend. The role of visualizations it’s not just to display data, but to make the data speak for itself. Highlighting trends, anomalies, patterns, and correlations that underscore your findings. With visuals presented, it’s time to describe them for your audience. This is where you act as the translator, decoding the visuals and turning data into a narrative. Elaborate on the key observations drawn from the data, explaining what they signify in the context of the original problem. Try to link the patterns and trends into visuals to the story you’re trying to tell. Make sure your explanations are straightforward and relatable so that the audience can easily understand the story coming from the data. As you approach the end of your presentation, present your recommendations based on the findings, what actions should be taken to address the problem identified at the beginning of the presentation. If your data reveals a potential for improvement or modification in certain areas, outline those recommendations clearly. Discuss why you believe these steps would make a difference. Drawing connections between your findings and the recommended actions. Let’s imagine we’ve been analyzing a recent decline in web traffic for an e-commerce store. We start our presentation with a recap. We remind the audience about the initial problem; a significant drop in website traffic over the past three months, which we noticed during our routine metrics review. Next, reshare the OSEMN process. We obtained website analytics data, scrubbed it to ensure accuracy, then explore that to identify trends and anomalies. Our exploration led us to the modeling phase where we created a model that identifies potential costs. We then present a visualization, a graph illustrating the downward trend in website traffic alongside the increase in page load time, which we discovered was the primary cause for our model output. The clear inverse correlation visually substantiates our key finding. We can use the graph to explain what happens and when the problem started. As the page load time increased, the web traffic decreased significantly. We’re able to tell the story of how our users started leaving our website because of longer low tides causing the website traffic to decline. And finally, we conclude with our recommendation. Given the correlation between page load time and traffic, we suggest optimizing the website’s performance in an effort to reduce low time, which should help recover and possibly increase our website traffic. Thus, our data journey comes full circle, offering actionable insights that can be used to improve our business. Interpreting your findings and explaining them effectively to your audience is what turns data into action. It’s the crucial final step in the OSEMN cycle, one that bridges the gap between raw data and real-world decisions, and that’s the power of data analytics Explain, Enlighten and Engage After you’ve analyzed your data and drawing your conclusions, you will often need to present your findings. You’ll want to make sure that you can convey your findings well and persuade people to understand and believe that. In order to tell a persuasive story, we need to focus on the three Es; explain, enlighten, and engage. This can be achieved by a combination of data, narratives and visuals. Both the data and a narrative will serve to explain the situation. The narrative provides context for the data, specifically, where it comes from, why stakeholders should care about it and what was done with it. Data and visualization are part of enlightening your audience, as we’ve mentioned before, raw data are simply a bunch of values. It’s hard for most people to appreciate what the data I have to say in their raw form. By combining the data with good visuals, one can show clearly what the data are and what they mean to the overall big picture. You want to lead your audience to that aha moment to point where everything clicks. Engagement comes from the narrative and visualizations. If the visualizations are good and the narrative is clear and concise, people can internalize what’s being said. This internalization gets them invested in the story. As the Venn diagram shows all three parts together, the data visualizations and narrative can lead to audience understanding and persuasion as they’re brought together using the three Es of explain, enlighten, and engage. That’s frequently the goal of the story. Play video starting at :1:59 and follow transcript1:59 Suppose you’re presenting data on decreasing honeybee populations. You have data on the global decline in honeybee populations over the last decade gathered from various environmental research agencies. This data includes annual honeybee colony counts across several countries. You prepare a story around the importance of honeybees in the equal system, highlighting their role in pollinating a majority of the food crops we consume. You discuss the potential consequences of their declining numbers and why it matters to everyone, not just environmentalists. You create a line graph that vividly illustrates the decrease in honeybee populations over time across different countries. This visual representation allows for a clearer understanding of the magnitude of the problem. The numbers alone would illustrate. Now, how do these elements combine to explain, enlightened, and engage? You use the narrative to clarify the data’s origin and its significance. Stating disfigures derived from multiple environmental agencies showed the alarming rate of decline in honeybee populations over the past 10 years. The visual of the line graph is used to illustrate the data. You’d see this graph powerfully depicts the downward trend allowing us to visualize the severity of the issue at hand. Finally, you combine the narrative and visuals saying, imagine a future where many fruits and vegetables becomes scarce due to the lack of pollination. This graph isn’t just lines and dips. It represents potential problems to our food supplies that might need to be addressed. This makes the story memorable and drives home the urgency of the issue. In future videos, we’ll go deeper into data storytelling and how to tell an effective and compelling story. For now, remember that a good data story persuades your audience by transforming the data into stories that explain, enlighten, and engage. So far, we focused quite a bit on data and we also saw how to create compelling visuals. But how about a narrative? How can we build a good narrative to help people understand and be persuaded by the data and the visuals? Every compelling story, from novels to movies to data analysis, typically has four key parts. Setup, buildup, climax, and conclusion. To create an impact, your data story should incorporate these elements. Let’s look at them one by one. As with any good story, we should start our story with a hook. Something to get the audience interested in following along. Frequently, these hooks are questions derived from curiosity. Is there a sudden change? Are we missing an opportunity? What should we expect moving forward? What we want to convey in the setup is the theme of the story. It could be that there is an issue or concern that needs to be addressed, or an opportunity to be seized. For our example hook, suppose that we notice a sudden dip in Inu and Neku’s sales for the last couple of months. An obvious and compelling hook is why? What could be causing this downturn? After we’ve set up the story, we want to create a build up. Build up is where the story unfolds. It’s here that we describe the steps taken in investigating the hook from the setup. We also want to communicate the findings from our investigations. The actions taken that lead us to the key findings are particularly important. The key finding is the insight from our analysis that has the greatest explanatory power. In our example, after some data exploration, we realized that the sales figures are from multiple channels. They can be broken up into Internet, wholesale, and retail. It looks like the change in sales is stemming from our Internet sales. We then investigated the web data and found that while Internet sales numbers went down, the number of customers visiting the online store did not. Digging further, we discovered that for Internet customers, there was a high abandonment rate of shopping carts, meaning many customers never checked out even though they had items in their cart. This appears to have started at the same time as the downturn started. So that would be our key finding. Online shopping cart abandonment rates increased during the downturn. If this was a mystery story, the climax happens when the villain is unmasked. For us, it’s when we explain the hook’s root cause with our key finding. Ideally, this is where the audience’s light bulb goes off. If you engaged with the audience adequately, they should now understand the dynamic between the hook and the cause and want to act on your insight. In our story, it’s strange that 92% of customers abandoned their cards while in the process of making a purchase. This didn’t happen in prior months or years. It’s at this point that we uncover the fact that customers abandoned their cards due to our lack of inventory for the products that they want to buy. If we don’t have the product in stock, of course our customers can’t buy it. Consequently, we received no sales for those products. Now we finish the story. If there is action that needs to be taken to remedy the issue, it should be revealed at this point. We should also discuss the cause if we have an idea of what it is. Going back to our example with Inu and Neku, now that we’ve uncovered the cause for the decline in sales, how do we fix it? Well, if we work to increase our stock of in demand products, we should be able to reverse the downward sales trend. If the products were in stock, our sales would have likely looked much better and the decline wouldn’t have happened. Should be mentioned that you don’t always need to tell a nice and neat story when interpreting data. But the most impactful and meaningful discoveries tend to. When the insights are hard to understand or when the impact on your business is large, storytelling with data is essential. Expect an underlying story when data shows something unexpected, unpleasant, complex, costly, or especially surprising. These situations tend to point to a good data story waiting to be told. Summary Reading: iNterpreting Data &amp; Storytelling iNterpret Checklist Step 1: Understand the results of your analysis Ask the following questions: ⏹ What was the objective for this analysis? ⏹ How does the data answer my questions? ⏹ What other learnings do I have? ⏹ How can I apply this to a business context? ⏹ How confident should I be? How wrong is the model? How likely is the model to be correct? What scenarios cause the model to be incorrect? Step 2: Explain your findings Build a presentation with these key components: ⏹ Recap ⏹ Method ⏹ Visualization ⏹ Explanation ⏹ Recommendation "],["marketing-tactics.html", "Chapter 2 Marketing Tactics 2.1 Channels and Platforms 2.2 Other Channels and Demand-Side Platforms (DSPs) to Explore 2.3 Upper Funnel Marketing (Awareness Stage) 2.4 Mid-Upper Funnel Marketing (Consideration Stage) 2.5 Why Mid and Upper Funnel Are Critical for Insurance Marketing 2.6 Question", " Chapter 2 Marketing Tactics A marketing funnel is a model that represents the customer journey from initial awareness to eventual purchase. It is typically divided into three stages: Top of the Funnel (Awareness): This stage focuses on creating awareness of a brand or product. It targets a broad audience to introduce them to the business, aiming to capture attention and generate interest. Tactics: Display ads, social media marketing, blog posts, videos, PR campaigns. Metrics: Impressions, reach, website traffic, brand recall. Middle of the Funnel (Consideration): In this stage, the audience is already aware of the brand, and the goal is to nurture their interest and push them toward evaluating the product or service. This phase involves building trust, educating the potential customer, and addressing pain points. Tactics: Email marketing, retargeting ads, content marketing (webinars, whitepapers), comparison tools, case studies. Metrics: Engagement (clicks, time spent), leads, email signups, downloads. Bottom of the Funnel (Conversion): This is the final stage where the focus is on converting potential customers into paying customers. It typically involves more direct, action-oriented marketing tactics designed to drive purchase or sign-ups. Tactics: Personalized offers, discounts, demos, free trials. Metrics: Conversions, sales, ROI, customer acquisition cost (CAC). 2.1 Channels and Platforms These platforms play a pivotal role in mid and upper funnel marketing by allowing advertisers to reach broad audiences, optimize targeting, and measure effectiveness through data-driven strategies. 2.1.1 Google Display Network (GDN) What it is: GDN is one of the largest ad networks, allowing marketers to display ads (banner ads, responsive ads, etc.) across millions of websites, apps, and Google-owned platforms like YouTube and Gmail. Importance: Reach: GDN can reach over 90% of internet users globally, making it an ideal tool for upper funnel awareness campaigns. Targeting Options: With GDN, advertisers can target audiences based on demographics, interests, browsing behavior, and specific website placements. Brand Safety: It offers features to ensure that ads don’t appear on inappropriate or low-quality sites, ensuring brand safety. Formats: Supports a variety of formats (static, video, interactive) to engage users at different stages of the funnel. 2.1.2 Meta (Facebook/Instagram Ads) What it is: Meta’s advertising platform covers Facebook and Instagram, offering access to over 3 billion monthly active users. Importance: Granular Targeting: Meta allows for hyper-targeted campaigns using demographics, behaviors, interests, and custom audiences (including lookalike audiences). This is useful for both mid and upper funnel strategies. Ad Formats: It supports a wide range of ad formats, including image, video, carousel, and collection ads, enabling interactive and engaging campaigns. Retargeting: Powerful retargeting capabilities allow advertisers to follow up with users who have interacted with the brand, pushing them down the funnel from awareness to consideration. Cross-Channel Engagement: Since Facebook and Instagram are social networks, engagement metrics (likes, shares, comments) can be directly tied to how users interact with the brand. 2.1.3 DV360 (Google’s Display &amp; Video 360) What it is: DV360 is a programmatic ad platform designed for advanced media buyers. It allows advertisers to buy and manage display, video, audio, and native ad campaigns across a variety of platforms in real-time. Importance: Programmatic Efficiency: DV360 allows marketers to target audiences across multiple networks in real-time using programmatic bidding, optimizing for reach and efficiency. Cross-Channel Campaigns: DV360 integrates with YouTube, mobile apps, connected TV, and third-party exchanges, enabling cohesive cross-channel strategies. Audience Targeting &amp; Data Integration: It offers sophisticated audience targeting options, leveraging first-party data, Google’s proprietary data, and third-party data from integrated partners. Advanced Reporting: DV360’s robust reporting and analytics tools help marketers measure and optimize campaign performance with detailed insights. 2.2 Other Channels and Demand-Side Platforms (DSPs) to Explore 2.2.1 The Trade Desk: Overview: A powerful programmatic DSP that allows marketers to buy display, video, audio, and native ads across various platforms. Why It’s Important: Known for its transparency and advanced targeting options, The Trade Desk is widely used for mid and upper funnel marketing strategies. It integrates with multiple data providers, allowing for precise audience segmentation. 2.2.2 Amazon DSP: Overview: A DSP that offers programmatic access to display, video, and audio ads both on and off Amazon. Why It’s Important: Amazon DSP is particularly valuable for ecommerce and retail brands. It provides access to Amazon’s first-party shopping and behavioral data, which allows advertisers to target users based on past purchase intent and behaviors. 2.2.3 LinkedIn Ads: Overview: A platform specializing in B2B advertising, allowing businesses to target professionals based on job title, industry, company size, and more. Why It’s Important: For upper and mid-funnel marketing in the B2B space, LinkedIn is an essential tool. It provides unique access to decision-makers and professionals, making it ideal for high-value lead generation campaigns. 2.2.4 TikTok Ads: Overview: A fast-growing platform that offers video advertising options targeting a younger demographic. Why It’s Important: TikTok’s algorithm helps marketers reach highly engaged audiences. Its focus on short-form video content makes it ideal for upper funnel brand awareness, particularly for brands targeting Gen Z and Millennials. 2.2.5 Snapchat Ads: Overview: Snapchat’s ad platform is known for its focus on younger audiences and engaging, immersive ad formats. Why It’s Important: Similar to TikTok, Snapchat offers unique ad formats like augmented reality (AR) ads and vertical video ads. It’s useful for upper funnel awareness campaigns, especially for consumer products aimed at younger audiences. 2.2.6 Verizon Media DSP: Overview: Verizon Media’s DSP offers access to a wide range of ad formats across video, native, display, and search inventory. Why It’s Important: It offers extensive targeting options, combining first-party data with third-party insights. It’s also integrated across Verizon’s owned properties, including Yahoo, HuffPost, and AOL, giving advertisers access to large audiences. how data-driven approaches in DSPs, how designed targeted strategies, and iterated through A/B testing to optimize performance across these funnel stages. Data-Driven Marketing Strategies: Expect questions about how you’ve used data to inform and optimize marketing strategies, especially in the mid-upper funnel (awareness, consideration stages). Be prepared to discuss metrics like impressions, reach, engagement, and click-through rates (CTR). Customer Segmentation: You may be asked how you’ve segmented customers or audiences for targeting in upper funnel strategies. Expect to explain methodologies for identifying and targeting segments, such as lookalike modeling or propensity scoring. Attribution Challenges: While not focused on MMM, you might be asked about multi-touch attribution models or how you measure success across different channels, especially in brand awareness campaigns where conversions aren’t immediate. A/B Testing and Experimentation: Expect questions about running A/B or multivariate tests, especially for upper funnel campaigns. Be ready to discuss how you measure uplift or improvement in key metrics through experimentation. 2.2.7 2. Business Acumen Strategic Thinking: You’ll likely be asked how marketing data informs broader business decisions, such as optimizing media spend or aligning marketing efforts with business goals. Be ready to discuss your ability to connect marketing KPIs with business growth. Budgeting and ROI: Since the focus is on mid-upper funnel, expect to discuss how you manage marketing budgets, measure ROI for awareness or consideration-focused campaigns, and allocate resources effectively. Campaign Performance Analysis: Be prepared to talk about how you analyze the performance of marketing campaigns at various funnel stages, particularly in terms of engagement, brand lift, and conversion funnel progression. Collaboration with Other Teams: Upper funnel marketing often involves working closely with creative teams, product teams, and sales. You might be asked about cross-functional collaboration and how marketing insights inform business strategy. 2.2.8 3. General Marketing Knowledge Upper Funnel Tactics: Be ready to talk about common strategies and tools used in the awareness and consideration stages, such as programmatic display, video advertising, influencer marketing, and social media strategies. Performance Benchmarks: You might be asked how you evaluate the success of these upper funnel activities, given the lack of immediate conversions. Be ready to discuss metrics like engagement rates, brand recall, and view-through conversions. Campaign Optimization: Expect questions on how you optimize campaigns based on real-time data and performance indicators, especially in situations where attribution is not clear-cut. In short, be ready to demonstrate how you’ve leveraged quantitative skills to inform and optimize mid-upper funnel marketing efforts and connect those efforts to broader business outcomes. 2.3 Upper Funnel Marketing (Awareness Stage) The upper funnel focuses on introducing your brand to as many people as possible, primarily to build awareness. This stage is not about conversions but about visibility and attracting attention from a broad audience. Key Objectives: Make potential customers aware of your brand or product. Generate interest and build brand recognition. Reach a large and diverse audience to bring them into the consideration stage. Common Tactics: Display and Social Ads: Using platforms like Google Display Network, Meta (Facebook/Instagram), or DV360 to show ads to a wide audience. Video Marketing: Creating engaging video content for platforms like YouTube or social media to increase brand visibility. Content Amplification: Distributing branded content (blog posts, videos) through paid channels or influencer partnerships to increase reach. Programmatic Advertising: Automated, real-time ad buying to target potential customers based on demographics, interests, or online behaviors (via DSPs like The Trade Desk, DV360). Brand Partnerships and Sponsorships: Associating with other well-known brands or events to increase visibility. Metrics: - Impressions: The total number of times your ad is displayed. - Reach: The number of unique people who saw your content. - Brand Recall/Brand Lift: Measuring how many people remember your brand after being exposed to your marketing. - Engagement: Likes, shares, and comments on social or video content. 2.4 Mid-Upper Funnel Marketing (Consideration Stage) The mid funnel is crucial for turning awareness into genuine interest and engagement, often focusing on guiding customers as they start evaluating options. It’s about nurturing leads and educating potential customers to move them closer to a decision. Key Objectives: Develop a relationship with the customer. Build trust and demonstrate the value proposition. Provide content that answers questions and alleviates concerns. Common Tactics: Retargeting Ads: Serve ads to people who have already interacted with your brand (e.g., visited your website) but haven’t converted yet. Email Marketing: Personalized content sent to leads who have expressed interest but haven’t made a purchase. Content Marketing: Educating leads through blogs, webinars, whitepapers, and case studies that provide deeper insights into the product or service. Lookalike Audience Targeting: Identify and target users who are similar to your current leads or customers on platforms like Facebook or Google Ads. Metrics: Click-Through Rate (CTR) on ads and emails. Conversion rates from lead magnets (downloads, webinar registrations). Engagement metrics (time on site, return visits). Lead Quality and nurturing progress (e.g., leads moving from cold to warm). 2.5 Why Mid and Upper Funnel Are Critical for Insurance Marketing In industries like insurance, customers rarely make purchasing decisions right away. Mid and upper funnel strategies are crucial because: Insurance is a high-consideration product: It requires trust-building and multiple touchpoints before conversion. Awareness campaigns (upper funnel) aim to make your brand the first option they think of when a need arises. Education is key: Insurance buyers need to understand what differentiates your product. Mid-funnel strategies provide valuable information that helps guide customers toward making informed decisions. Long purchase cycles: Insurance purchase cycles are often lengthy, and staying top of mind during the decision-making process is crucial. By focusing on upper funnel tactics, you can attract and educate a broad audience, ensuring your brand is recognized. By leveraging mid-funnel strategies, you can nurture potential customers and move them closer to conversion with the right messaging, targeting, and content. Incrementality Measurement: Study techniques for measuring the incremental profit impact of marketing campaigns. This includes uplift modeling, calculating incremental lift, and designing experiments to separate causality from correlation. Data Science for Marketing: Rapid Prototyping and Production Pipelines: Learn about tools and methodologies for rapid prototyping of data science models (e.g., Jupyter, PySpark) and putting them into production efficiently. Understand CI/CD practices for machine learning pipelines and model deployment. ML Targeting Models: Review machine learning models commonly used for marketing (e.g., logistic regression, random forest, gradient boosting, and deep learning). Focus on how these are applied to customer segmentation, personalized recommendations, and ad targeting. Tracking and Evaluating Marketing Effectiveness: Study how marketing performance is tracked (e.g., impressions, CTR, conversion rates) and how you can use that data to build predictive models for future campaigns. Communicating Research Findings: Data Storytelling: Practice how to communicate complex data science findings to non-technical stakeholders clearly and concisely. Use tools like PowerPoint, dashboards (e.g., Tableau, PowerBI), and Jupyter notebooks to present data visually. End-to-End Ownership: Marketing Analytics Lifecycle: Learn the full lifecycle of marketing analytics—from identifying key objectives, designing strategies, running campaigns, measuring impact, and iterating to improve performance. 2.5.1 Suggested Resources: Books: Data Science for Marketing Analytics by Tommy Blanchard, Debasish Behera Marketing Analytics: A Practical Guide to Real Marketing Science by Mike Grigsby Trustworthy Online Controlled Experiments by Ron Kohavi (for A/B testing and incrementality measurement) Courses: Udacity - Marketing Analytics Nanodegree (covers A/B testing, funnel analytics, and campaign measurement) Coursera - Machine Learning for Marketing (builds machine learning models for marketing applications) Papers and Blogs: Read blog posts and case studies from platforms like The Trade Desk and Google Marketing Platform (DV360) to understand industry applications of DSPs and marketing strategies. 2.5.2 Mock Questions: Can you walk me through how you would design an A/B test to measure the impact of a new mid-funnel marketing campaign? How would you approach building a machine learning model for targeted advertising on a DSP like The Trade Desk or DV360? What metrics would you use to measure the effectiveness of an upper funnel marketing campaign? This preparation should align with the specific skills and knowledge you’ll need for your role at Root. Let me know if you’d like more details on any specific topics! 2.6 Question How did you use data to inform and optimize marketing strategies especially in the mid-upper funnel (awareness and consideration stages) Here’s a framework to guide your response: 2.6.1 Start with the Objective Explain the Business Goal: The goal here might have been building awareness, increasing engagement, or nurturing leads. For example: “The objective was to increase brand awareness and drive qualified traffic to the website in preparation for upcoming sales campaigns. We needed to optimize engagement in the consideration stage to nurture leads more effectively.” 2.6.2 Discuss the Data Sources You Used Highlight the Types of Data: Discuss the data sources you used to gather insights on the target audience. Upper Funnel (Awareness): Focus on broad-reaching data such as audience demographics, third-party data (e.g., interests, behaviors), and impressions/engagement metrics. Mid Funnel (Consideration): Discuss more refined data such as retargeting data, website interaction (bounce rates, session duration), and engagement rates (CTR, form completions). For example: “We collected signals from first-party CRM data, web content traffic data, demographics and interests from Transunion population data. This helped identify potential customers who fit our target demographics but hadn’t yet interacted with the brand.” 2.6.3 Describe How You Analyzed the Data Showcase Analytical Techniques: Talk about specific analyses you performed, such as audience segmentation, A/B testing, or performance comparisons across channels. Mention tools like SQL, Python, or Tableau. For example: “We performed segmentation based on demographic and behavioral data to identify high-value audiences for our retargeting efforts. By using clustering techniques, we identified which audience segments were more likely to engage with our content.” 2.6.4 Explain the Strategy and How Data Informed It Link Insights to Actions: Describe how you used the data to adjust or develop marketing strategies, including channel selection, targeting, and messaging. For upper funnel: “Based on audience interest data, we identified key personas and launched targeted display ads on Google Display Network and YouTube to increase awareness. We focused on video ads for brand recall and static banner ads for broader reach.” For mid funnel: “In the consideration stage, we deployed retargeting campaigns on Meta (Facebook/Instagram) and personalized email campaigns using engagement data to keep prospects engaged.” 2.6.5 Discuss How You Optimized the Campaigns Show Iteration and Testing: Highlight how you continuously monitored performance and ran A/B tests or other experiments to optimize results. For example: “We set up A/B tests on different ad creatives and CTAs to see which messages resonated more with our audience. By using tools like Google Ads and Facebook Ads Manager, we iterated on campaigns based on CTR and conversion data, optimizing bids and ad placement accordingly.” 2.6.6 Show the Outcome and Impact Quantify the Results: Whenever possible, quantify the impact of your data-driven optimization. For example: “As a result, we improved brand awareness by 25% and reduced bounce rates on our landing page by 15%. Engagement rates on retargeted ads increased by 30%, leading to a significant increase in the number of leads moving further down the funnel.” 2.6.7 Sample Answer “In my current role, I was responsible for optimizing mid-upper funnel marketing strategies to drive awareness and consideration. Our objective was to increase brand awareness while generating qualified leads for a new product launch. We leveraged a combination of first-party CRM data and third-party consumer purchase and web content consuming behavior data. We used this data to build out personas and refine our targeting. For example, we segmented audiences by interests and demographics, launching targeted display and video campaigns across Google Display Network and YouTube. We monitored performance in real-time, using metrics like impressions, engagement rates, and click-through rates (CTR) to assess which channels and creatives were most effective. In the consideration stage, we deployed retargeting campaigns using Facebook and Instagram ads to keep our brand top of mind. By analyzing audience engagement and running A/B tests on different messaging and creatives, we optimized our campaigns for higher engagement, which resulted in a 30% increase in click-through rates and a 20% increase in leads moving further down the funnel. This data-driven approach allowed us to efficiently allocate resources and improve ROI.” Use data to create audiences, customer segments launch campaign and monitor performance assess which channels and individuals are more effective and engaged deploy retargeting campaigns test different segments and creative messages and optimize campaigns "],["measurement-in-marketing.html", "Chapter 3 Measurement in Marketing 3.1 A/B Testing and Experimentation: 3.2 Incrementality", " Chapter 3 Measurement in Marketing body {text-align: justify} 3.1 A/B Testing and Experimentation: Designing Efficient A/B Tests: When it comes to A/B testing in marketing, the goal is to rigorously measure the impact of different strategies, whether it’s ad creative, targeting, or messaging. To ensure that the results are valid and actionable, several key principles come into play: 3.1.1 Sample Size Calculation: Proper sample size is crucial for detecting significant differences between variations. I ensure we calculate the sample size based on the expected effect size, confidence level (usually 95%), and power (commonly 80%). This helps avoid underpowered tests, which may miss meaningful differences, or oversized tests, which waste resources. Example: For a campaign involving display ads, I would calculate the necessary sample size to detect a lift in click-through rate (CTR) of a few percentage points, ensuring the test is sensitive enough to capture small but meaningful improvements in engagement. 3.1.2 Randomization: It’s critical to randomly assign participants to control and treatment groups to eliminate bias. This ensures that any observed differences between the groups are attributable to the variation being tested (e.g., different ad creatives) rather than external factors. Example: When testing different ad creatives on a platform like Google Display Network, I would randomize the exposure to the ads to avoid selection bias, ensuring that all types of users are equally likely to see any of the variations. 3.1.3 Handling Biases: A/B tests can be prone to various types of biases, such as selection bias (when participants in one group differ systematically from those in another) or novelty bias (where people may respond more positively to a new variant simply because it’s new). Mitigating these biases is essential to ensure reliable insights. Example: In retargeting campaigns, I account for recency bias by controlling for the time since the user’s last engagement with the brand, preventing this from skewing results. 3.1.4 Test Duration: Running an A/B test for the right amount of time is important. Ending a test too early may not capture the full effects, while running it too long could introduce external factors that cloud the results. A good practice is to run tests until enough data is collected to reach statistical significance based on the calculated sample size. Example: For a mid-funnel email campaign, I would run the test for at least two weeks, ensuring that we gather enough data across different days of the week to account for cyclical behavior, like higher email open rates on weekdays versus weekends. By adhering to these principles, I ensure the A/B tests we run provide actionable, reliable insights into which strategies deliver the best results. 3.2 Incrementality Understanding the incremental impact of marketing efforts is crucial in evaluating whether a campaign truly drives additional revenue or engagement, beyond what would have happened without the campaign. This concept is especially important in marketing for the mid- and upper-funnel because these campaigns target awareness and consideration, often before the user is close to conversion. Here are the key techniques used for measuring incrementality: 3.2.1 Incremental Lift Calculation Definition: Incremental lift refers to the difference in outcomes (e.g., conversions, sales, or profit) between a group exposed to a marketing treatment (e.g., ads) and a control group not exposed to the treatment. The goal is to quantify how much the marketing effort contributes above and beyond what would have occurred without it. How It’s Calculated: Incremental lift is typically calculated by comparing the conversion rate (or another key metric) between the treatment and control groups: \\[ \\text{Incremental Lift} = \\left( \\frac{\\text{Conv. Rate of Exposed Gr.} - \\text{Conv. Rate of Control Gr.}}{\\text{Conv. Rate of Control Gr.}} \\right) \\times 100 \\] Example: If the exposed group had a 5% conversion rate and the control group had a 3% conversion rate, the incremental lift would be \\(\\frac{5\\% - 3\\%}{3\\%} = 66.7\\%\\). This means the campaign resulted in a 66.7% increase in conversions compared to what would have been achieved without exposure to the campaign. Importance in the Funnel: In the upper funnel, where conversions are not immediate, incremental lift can measure shifts in awareness, brand consideration, or engagement. In the mid-funnel, where users may be considering a purchase, it helps determine how well your campaigns push prospects toward conversion. 3.2.1.1 2. Uplift Modeling (Incremental Response Models) Definition: Uplift modeling is a machine learning technique designed to predict the causal impact of marketing interventions on individual customers. Instead of just predicting whether a customer will convert, uplift models focus on identifying customers who are likely to convert because of a specific marketing action. How It Works: Uplift models typically divide customers into four categories: Persuadables: Customers who would convert only if exposed to the campaign. Sure Things: Customers who would convert regardless of whether they’re exposed. Lost Causes: Customers who won’t convert, even if exposed. Do Not Disturbs: Customers who would convert if not exposed but might be negatively impacted by the campaign (e.g., by seeing an ad too many times). Uplift modeling focuses on identifying the persuadables, who are the most likely to deliver incremental profit when targeted. Advantages: Uplift modeling can help target marketing campaigns more efficiently by focusing on customers most likely to be influenced by the campaign. This leads to better resource allocation (spending marketing dollars on the right people) and improved return on investment (ROI). Example: In a mid-funnel campaign for an insurance product, uplift modeling can predict which individuals are likely to move from consideration to purchase because of seeing a particular ad or email. Targeting these persuadable customers can help optimize the campaign’s impact. 3.2.1.2 3. Experiment Design for Causality Randomized Control Trials (RCTs): The most robust way to measure incrementality is through Randomized Control Trials (RCTs), where individuals are randomly assigned to treatment (exposed) and control (non-exposed) groups. This randomization ensures that the only systematic difference between the groups is the exposure to the marketing campaign, which helps isolate the causal effect of the campaign. Use in Mid-Upper Funnel: In the upper funnel, RCTs can measure the impact on brand awareness or intent to purchase. In the mid-funnel, they help quantify the impact on moving customers closer to conversion. Example: In a social media campaign, a group of users is shown targeted ads while a control group is not. By comparing the outcomes (e.g., website visits or form submissions) between the two groups, you can measure the incremental lift caused by the ads. Pre/Post Analysis: Another common experimental method is pre/post analysis, where you compare key metrics (e.g., sales, site traffic) before and after the campaign. While this approach can show changes, it doesn’t account for other variables that may have influenced the outcome, which is why RCTs are generally preferred. Quasi-Experimental Designs: When running fully randomized experiments isn’t feasible (e.g., due to ethical or operational reasons), quasi-experimental designs like matched pairs or difference-in-differences can help approximate the causal impact by comparing similar individuals in treatment and control groups, but without full randomization. 3.2.1.3 4. Difference Between Incrementality and Correlation Causality vs. Correlation: It’s important to distinguish between a correlational relationship (where two variables move together but may not be causally related) and a causal relationship (where one variable directly affects the other). Incrementality measurement, through experiments like A/B tests or uplift models, helps separate causality from correlation. Example: Suppose a marketing campaign for an insurance product targets users who are already researching insurance options. These users may have converted on their own without the campaign, so observing a correlation between exposure and conversion might not indicate a causal effect. Incrementality measures whether the conversions are actually driven by the campaign. Biases to Watch For: Be mindful of biases such as selection bias (e.g., when exposed and non-exposed groups differ systematically) or time effects (e.g., seasonal trends) that can obscure the true incremental impact of the campaign. Randomized experiments and uplift modeling can help mitigate these issues. 3.2.2 Importance in Marketing Funnel Context Upper Funnel (Awareness): In the awareness stage, the focus is on increasing brand recall, engagement, or intent, rather than immediate conversions. Incrementality in this stage can be measured through metrics like ad recall lift or brand consideration scores. Uplift modeling might focus on identifying audiences who are more likely to remember the brand after exposure. Mid-Funnel (Consideration): In the mid-funnel, incrementality measurement often targets intent to purchase or website engagement, as prospects move closer to conversion. A/B testing and uplift models can help identify whether specific marketing interventions are driving users to engage more deeply with the brand (e.g., visiting product pages, signing up for newsletters). Real-World Application: For example, in an email campaign, incrementality might be measured by comparing the open and click-through rates of an exposed group versus a control group to determine how much of the engagement is driven by the email versus organic behavior. For household-level or Designated Market Area (DMA)-level targeting and incrementality measurement, the methodologies shift slightly to account for the broader aggregation of data. In these cases, the focus is not on individuals but on groups, so certain individual-level techniques may not directly apply. Here’s a breakdown of methods tailored for household or DMA-level targeting and incrementality measurement: 3.2.3 Methods for Household-Level or DMA-Level Incrementality Measurement: 3.2.3.1 1. Geo-Experimentation (Geographical Split Testing) Definition: Geo-experimentation involves splitting regions (e.g., households, zip codes, or DMAs) into test and control groups. One region (or group of households) receives the marketing treatment, while the other does not. This approach is frequently used when individual-level targeting isn’t feasible or available. How It Works: Randomly select geographic areas (households, zip codes, DMAs) for the treatment group, which receives the marketing exposure (e.g., ads, promotions). Use other similar areas as a control group that doesn’t receive the exposure. Measure the performance in both groups over time, looking at metrics like sales lift, engagement, or store visits. Advantages: Scalability: It works well for larger campaigns where individual-level data is either unavailable or too costly to manage. Minimal Bias: Randomizing geographical units helps minimize selection bias, ensuring a more reliable comparison. Example: A household-level geo-experiment could measure the impact of a TV advertising campaign in specific regions by comparing the sales performance of households in treated DMAs against those in non-exposed areas. 3.2.3.2 2. Difference-in-Differences (DiD) Definition: This quasi-experimental technique is commonly used to estimate causal effects at an aggregated level. It compares the changes in outcomes over time between a treatment group (e.g., a DMA or household exposed to a campaign) and a control group that was not exposed. How It Works: First, establish baseline measurements for both treatment and control groups. Introduce the marketing campaign to the treatment group. After the campaign period, measure the change in key outcomes (e.g., sales, brand recall, visits) for both groups. The difference in performance between the groups over time is attributed to the marketing intervention. Advantages: Controls for Time-Based Trends: This method controls for external factors (like seasonality or economic changes) that might affect both groups simultaneously. Simplicity: It’s relatively easy to implement using pre- and post-campaign data at the household or DMA level. Example: A retail store could apply DiD to measure the impact of a display ad campaign targeted to households in one DMA, compared to households in a similar DMA that did not receive the ad exposure. By tracking sales data before and after the campaign, the incremental lift can be isolated. 3.2.3.3 3. Regression-Based Uplift Modeling (Aggregate-Level) Definition: While uplift modeling is typically used at the individual level, it can be adapted for household or DMA-level targeting by aggregating data. Regression techniques, such as linear or logistic regression, can estimate the relationship between exposure (e.g., whether a household or DMA was exposed to a campaign) and the outcome (e.g., sales, engagement). How It Works: Aggregate relevant data at the household or DMA level (e.g., total sales, ad impressions, demographic factors). Use regression models to estimate the effect of exposure to the campaign on the desired outcome, controlling for other confounding variables (e.g., household income, past purchasing behavior, or location-specific factors). You can include interaction terms to model the differential effects of exposure on different regions or household groups. Advantages: Flexible: Can be adapted for a wide range of marketing channels and aggregated datasets. Allows for Control Variables: By including covariates like household demographics or DMA characteristics, you can better control for other factors influencing outcomes. Example: A furniture retailer might use regression to assess the lift in sales for DMAs exposed to a marketing campaign while controlling for household income and previous purchase patterns in each DMA. 3.2.3.4 4. Synthetic Control Method Definition: This method is particularly useful for DMA-level targeting and incrementality measurement when there’s only a single treatment region and no well-defined control group. The idea is to create a “synthetic” control group by combining other DMAs or households that weren’t exposed to the marketing campaign, simulating what would have happened without the campaign. How It Works: Identify the treated DMA that received the campaign. Build a synthetic control group by combining data from other DMAs that closely resemble the treated region before the campaign (in terms of key metrics like sales, demographics, and engagement). Compare the post-campaign performance of the treated DMA against the synthetic control group to estimate the incremental impact. Advantages: Effective for Small-Scale Interventions: It’s especially useful when there aren’t many control regions available for comparison. Rigorous Control: It accounts for time trends and allows for the construction of a custom control group, improving the validity of the analysis. Example: If a marketing campaign was launched in only one DMA due to budget constraints, a synthetic control method could be used to create a weighted average of similar DMAs to estimate what the treated DMA’s sales would have been without the campaign. 3.2.3.5 5. Propensity Score Matching (Aggregate) Definition: Similar to individual-level propensity score matching (PSM), this technique can be applied at the household or DMA level to create comparable treatment and control groups. It helps control for pre-existing differences between groups before estimating the incremental effect of the campaign. How It Works: Use household or DMA-level attributes (e.g., demographics, past purchasing behavior, geography) to calculate propensity scores, which indicate the likelihood of being exposed to the campaign. Match households or DMAs in the treatment group (those exposed to the campaign) to similar households or DMAs in the control group (unexposed) based on these propensity scores. Compare outcomes between the matched groups to estimate the incremental lift caused by the campaign. Advantages: Addresses Selection Bias: By matching treatment and control groups based on similar characteristics, PSM helps account for differences that could confound the results. Aggregate-Level Adaptability: Can be used for aggregated datasets, making it useful for household or DMA-level campaigns. Example: For a national marketing campaign, you could use PSM to match households in exposed DMAs to similar households in unexposed DMAs, ensuring the groups are comparable before measuring the sales impact of the campaign. 3.2.4 Real-World Application in Mid-Upper Funnel In mid- and upper-funnel campaigns, these methods help quantify the impact on awareness, consideration, or engagement at a larger scale. For example, DMA-level geo-experiments could measure the brand lift or site traffic increase from a digital video campaign or display ads across households in various regions. In these broader contexts, the goal is often to assess whether awareness-building campaigns are effectively pushing users down the funnel towards intent and conversion, and these techniques allow for reliable measurement at aggregated levels. By applying these techniques, you can show how you’re capable of measuring the incremental impact of campaigns at the household or DMA level, which is critical for large-scale marketing strategies, especially when individual-level targeting isn’t feasible. "],["marketing-analysis.html", "Chapter 4 Marketing Analysis 4.1 Market Basket Analysis (MBA)", " Chapter 4 Marketing Analysis 4.1 Market Basket Analysis (MBA) MBA is commonly used in retail and e-commerce to analyze purchasing patterns, making it highly relevant for marketing roles. Below are the key points to cover: 4.1.1 Introduction to Market Basket Analysis Definition: Market Basket Analysis is a data mining technique used to uncover relationships between items purchased together. It helps identify associations and co-occurrences of products in transactional datasets. Application: Typically used in retail, e-commerce, and recommendation systems to understand customer behavior, cross-sell opportunities, and inform promotional strategies. 4.1.2 Key Concepts Itemsets: Groups or sets of items purchased together. Association Rules: Rules that express the likelihood of purchasing one item when another is purchased. These rules take the form: “If a customer buys X, they are likely to buy Y.” Support: The proportion of transactions that contain a specific item or itemset. It helps to filter out infrequent itemsets. Formula: Support(X) = (Transactions containing X) / (Total transactions) Confidence: The likelihood that a customer buys item Y given that they’ve bought item X. It measures the strength of the rule. Formula: Confidence(X → Y) = Support(X and Y) / Support(X) Lift: A measure of how much more likely item Y is to be purchased when item X is purchased, compared to random chance. Formula: Lift(X → Y) = Confidence(X → Y) / Support(Y) A Lift &gt; 1 implies a strong association. 4.1.3 Techniques and Algorithms Apriori Algorithm: One of the most common algorithms for generating association rules. It uses a breadth-first search approach to find frequent itemsets. A breadth-first search (BFS)-like approach is employed to identify frequent itemsets. The algorithm explores the dataset level by level, starting with 1-itemsets, then moving to 2-itemsets, 3-itemsets, and so on. At each level, it generates candidate itemsets and checks their frequency, pruning those that do not meet the minimum support threshold. This BFS-like strategy allows the algorithm to systematically explore all itemsets while pruning infrequent ones early, optimizing the search process and making it computationally efficient for large datasets. Steps: Find frequent itemsets (those with support above a given threshold). Generate association rules from these itemsets. FP-Growth (Frequent Pattern Growth): A more efficient alternative to Apriori, especially for large datasets. It compresses the dataset into a tree structure and extracts frequent itemsets without generating candidate itemsets. Eclat Algorithm: An alternative method that uses depth-first search, and is suitable when the dataset has fewer transactions but a large number of items. 4.1.4 Use Cases in Marketing Cross-Selling: Suggesting complementary products (e.g., “Customers who bought this also bought…”). Product Placement: Optimizing the layout of stores or online catalogs by placing frequently purchased together items near each other. Personalized Recommendations: Using association rules to personalize product recommendations in online shopping carts or email campaigns. Promotions and Bundling: Creating product bundles or special promotions based on frequently purchased together items to increase average order value. 4.1.5 Handling Challenges Data Sparsity: Real-world transaction data often contains a vast number of products, which can lead to sparsity. Dimensionality reduction techniques or focusing on frequently bought items can help. High Cardinality: When dealing with a large number of unique products, algorithms like FP-Growth are preferable over Apriori due to performance efficiency. Overfitting: Be cautious of focusing on too niche associations. Lift is critical here; a high Lift with low Support might not be practically useful. Interpretability: Not all association rules are useful, so it’s important to prioritize rules with actionable insights (high Confidence and Lift) and interpret them in the context of the business. 4.1.6 Evaluation Metrics Lift: Higher Lift indicates stronger associations. Support and Confidence: Focus on rules with a good balance between Support (frequency) and Confidence (strength of the relationship). Profitability: Besides the statistical measures, consider the business value—whether the rule leads to actionable, profitable insights. 4.1.7 Tools and Libraries* Python Libraries: mlxtend: Popular library for Apriori and association rule mining. PyFPGrowth: For FP-Growth algorithm. pandas and scikit-learn: For data preprocessing and feature extraction. Other Tools: R, SAS, and SQL can also be used for Market Basket Analysis in different environments. 4.1.8 8. Example Problem Statement Scenario: You’re analyzing transaction data for an e-commerce company to identify product bundling opportunities. Goal: Find frequent itemsets and generate association rules to suggest which products should be bundled or cross-promoted to increase sales. Steps: Preprocess the data (transaction records) into a format suitable for MBA. Apply the Apriori algorithm with Support and Confidence thresholds. Evaluate the generated rules and use Lift to identify the strongest associations. Present actionable insights, such as product pairings or new bundling strategies. 4.1.9 9. Practical Implementation Example in Python from mlxtend.frequent_patterns import apriori, association_rules import pandas as pd # Sample transaction dataset data = {&#39;bread&#39;: [1, 1, 0, 1], &#39;butter&#39;: [1, 0, 0, 1], &#39;milk&#39;: [0, 1, 1, 1]} df = pd.DataFrame(data) # Generate frequent itemsets frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True) # Generate association rules rules = association_rules(frequent_itemsets, metric=&quot;lift&quot;, min_threshold=1.0) # Display the rules print(rules) 4.1.10 10. Interview Takeaways Explain how Market Basket Analysis can directly benefit a marketing team through better product placements, promotions, and personalized recommendations. Discuss the specific algorithms (e.g., Apriori, FP-Growth) and their applications to real-world datasets. Focus on how you handle data challenges (e.g., sparsity, overfitting) and your approach to ensuring actionable insights. Relate MBA to business impact, such as revenue uplift through cross-selling or bundling. 4.1.11 How to use for a Furniture Store In a furniture retail setting with both brick-and-mortar and online stores, Market Basket Analysis (MBA) can be leveraged in several ways to optimize product offerings, improve customer experience, and boost sales across channels. Here’s how it can be applied: 4.1.12 1. Cross-Selling Opportunities (Both In-Store and Online) Objective: Identify which furniture pieces and accessories (e.g., sofas, coffee tables, rugs) are frequently purchased together. Example: If MBA reveals that customers who buy a sofa are likely to buy a rug within the same transaction, the retailer can cross-sell rugs online by suggesting them on product pages, or display them near sofas in the physical stores. Implementation: Online: Use association rules to power “Frequently Bought Together” recommendations on product pages. In-store: Adjust store layouts and product placement based on common co-purchases (e.g., displaying lamps next to beds). 4.1.13 2. Product Bundling (Custom Furniture Packages) Objective: Create furniture bundles or home packages based on popular combinations identified through MBA. Example: If customers frequently purchase a dining table along with chairs and lighting, a bundled discount can be offered online, or a physical display set can be arranged in-store. Implementation: Online: Offer special bundles at a discounted rate or suggest bundles at checkout. In-store: Promote complete room setups or bundle promotions. 4.1.14 3. Optimizing Store Layout and Displays (Brick-and-Mortar) Objective: Use MBA insights to optimize the layout of physical stores by grouping frequently bought together items in close proximity. Example: If customers who buy office desks often purchase ergonomic chairs, placing these items in adjacent sections of the store can enhance the shopping experience and potentially increase sales. Implementation: Organize the store layout to reflect item associations, improving customer flow and making it easier for shoppers to find related items. 4.1.15 4. Personalized Marketing Campaigns Objective: Use customer purchase data from both online and offline channels to create targeted marketing campaigns. Example: If a customer purchased a bedroom set, you could send personalized offers for complementary items like nightstands or lamps through email or SMS. Implementation: Online: Send personalized recommendations via email or retargeted ads based on previously purchased products. In-store: Use loyalty program data to target customers with promotions for related items during subsequent visits. 4.1.16 5. Online vs. Offline Purchase Patterns Objective: Compare item associations in brick-and-mortar stores with those in online transactions to understand different purchasing behaviors across channels. Example: You may find that customers tend to buy larger items like sofas or beds in-store but prefer purchasing accessories like pillows or lamps online. Use this insight to align inventory strategies, promotional offers, and the balance between in-store and online stock. Implementation: Online: Focus on smaller, frequently purchased items with complementary cross-sell options. In-store: Promote big-ticket items like bedroom sets, dining tables, etc., where customers can physically inspect them before purchase. 4.1.17 6. Omnichannel Strategy (In-Store and Online Integration) Objective: Create a seamless experience across both channels by using MBA to understand customer journeys that begin online and finish in-store or vice versa. Example: Customers may research furniture online but prefer to make the final purchase in-store after seeing the item physically. Use MBA to track items researched online and purchased in-store to provide consistent recommendations and promotions across both channels. Implementation: Sync online and in-store purchase histories to generate consistent recommendations and offers, regardless of where the purchase takes place. Offer promotions encouraging in-store pickups after online purchases, where customers are shown complementary items that can be bought in-store. 4.1.18 7. Customer Segmentation and Targeted Discounts Objective: Segment customers based on their purchase behavior and offer targeted discounts or bundles. Example: Segment customers who typically buy higher-end furniture, such as luxury dining sets, and target them with premium accessory offers like designer lamps or high-end rugs. Implementation: Online: Personalized offers based on previous buying behavior, triggered by customer actions (e.g., abandoning a cart). In-store: Offer personalized discounts or recommendations at checkout for frequently purchased items based on transaction history. 4.1.19 8. Enhancing Customer Loyalty Programs Objective: Strengthen loyalty programs by offering members personalized offers based on items frequently bought together. Example: If MBA shows a pattern where loyal customers frequently buy living room furniture together (sofas, coffee tables, etc.), create a points system or offer special deals for completing a living room set. Implementation: Online: Tie loyalty points to purchases of complementary items and offer rewards for completing a set. In-store: Offer special rewards or discounts to loyal customers when they purchase items frequently bought together. 4.1.20 9. Inventory Management and Forecasting Objective: Use MBA results to better manage inventory by understanding which items are commonly purchased together and predicting demand for associated products. Example: If customers frequently buy certain styles of chairs with specific dining tables, ensure those chairs are sufficiently stocked both in-store and online to meet expected demand. Implementation: Adjust inventory across both channels based on co-purchase patterns and item associations. Use predictive analytics to forecast the demand for bundled products or associated items during sales or promotional events. 4.1.21 Key Takeaways for the Interview: Highlight how Market Basket Analysis can enhance both the online and in-store shopping experiences by improving cross-selling, bundling, and product placement. Discuss the importance of integrating data from both brick-and-mortar and online channels for a seamless omnichannel strategy. Mention specific marketing strategies that leverage MBA insights to drive personalization and customer engagement across multiple touchpoints. Focus on the business impact, such as improving inventory management, sales uplift, and customer retention through targeted promotions and optimized shopping experiences. By showcasing these insights, you’ll demonstrate how MBA can directly enhance the marketing strategy of a furniture retailer that operates both online and offline. Yes, you’re absolutely right! The term “breadth-first search (BFS)” is sometimes mentioned in the context of the Apriori algorithm and Market Basket Analysis, but the meaning here is slightly different from traditional graph-based BFS. Let’s break this down: 4.1.22 Apriori Algorithm Overview (in the Context of Market Basket Analysis): The Apriori algorithm is a classic algorithm used in association rule learning to find frequent itemsets in a large dataset (such as transactional data) and then generate association rules from these itemsets. In market basket analysis, the goal is to find items that frequently co-occur in transactions (e.g., if a customer buys bread, they are likely to buy butter). 4.1.23 How Breadth-First Search Relates to Apriori: In the context of the Apriori algorithm, the term BFS refers to the level-wise exploration of candidate itemsets. Here’s how: Level-wise Search for Frequent Itemsets: Apriori uses a level-wise search strategy, where it starts by identifying frequent 1-itemsets (i.e., individual items that appear frequently together in transactions). Once frequent 1-itemsets are identified, it moves to the next level by generating candidate 2-itemsets (pairs of items) and checks if they are frequent. This process continues by exploring 3-itemsets, 4-itemsets, and so on, until no further frequent itemsets can be found. The process of exploring itemsets level by level (1-itemsets, 2-itemsets, etc.) is similar to the breadth-first approach, where we explore all possible combinations at each level before moving to the next level. Breadth-First Search Strategy: Like a traditional BFS, Apriori explores the search space in a breadth-first manner, examining all candidates at the current level before proceeding to the next. For example, Apriori first considers all possible itemsets of size 1, then considers all possible itemsets of size 2, and so on. By pruning (eliminating) infrequent itemsets at each level, the algorithm reduces the number of candidate itemsets at the next level. 4.1.24 Apriori and the BFS-Like Approach in Action: Level 1 (Frequent 1-Itemsets): The algorithm scans the transaction dataset and counts the occurrence of each individual item. Items that meet the minimum support threshold are considered frequent 1-itemsets. Example: If we have transactions like: {Milk, Bread, Butter} {Milk, Butter} {Bread, Butter} {Milk, Bread} Frequent 1-itemsets might be: Milk (3 times) Bread (3 times) Butter (3 times) Level 2 (Frequent 2-Itemsets): The algorithm generates candidate 2-itemsets from the frequent 1-itemsets (e.g., {Milk, Bread}, {Milk, Butter}, {Bread, Butter}). It scans the dataset again and counts the occurrences of these pairs. Candidate pairs that meet the support threshold are retained as frequent 2-itemsets. In the above example: {Milk, Bread} might occur 2 times {Milk, Butter} might occur 2 times {Bread, Butter} might occur 2 times Level 3 (Frequent 3-Itemsets): The algorithm now generates 3-itemsets from the frequent 2-itemsets (e.g., {Milk, Bread, Butter}). It checks whether this 3-itemset meets the support threshold. Example: {Milk, Bread, Butter} might occur 1 time Continue until no more frequent itemsets can be found. At each level, Apriori prunes the search space by removing infrequent itemsets, reducing the computational effort at subsequent levels. 4.1.25 Comparison to Depth-First Search: In contrast to the BFS-like level-wise search used by Apriori, some other algorithms (like FP-Growth) use more of a depth-first search (DFS) approach, exploring combinations of items in a more recursive and hierarchical manner. FP-Growth builds a tree (frequent pattern tree) that captures the frequency of itemsets and navigates this tree using a depth-first search strategy to find frequent patterns. 4.1.26 Why Breadth-First Search in Apriori?: The BFS approach in Apriori makes sense because: - It systematically explores all possible itemsets starting from the smallest (1-itemsets) and incrementally builds up to larger itemsets. - It allows for early pruning of infrequent itemsets, saving computational effort. Since infrequent itemsets are discarded early, the algorithm doesn’t waste time exploring larger itemsets that are unlikely to be frequent. 4.1.27 Summary of BFS in Market Basket Analysis (Apriori): BFS in Apriori refers to the level-wise search of frequent itemsets, where the algorithm explores 1-itemsets first, then 2-itemsets, and so on. This approach ensures that we systematically explore all possible itemsets, with efficient pruning along the way, making the process computationally manageable for large datasets. In contrast to performing many independent searches (e.g., using a for loop), the Apriori algorithm’s BFS-like structure allows it to explore and prune itemsets efficiently in a structured manner. "],["methods-in-marketing-science.html", "Chapter 5 Methods in Marketing Science 5.1 Customer Lifetime Value 5.2 CLV Calculations", " Chapter 5 Methods in Marketing Science body {text-align: justify} 5.1 Customer Lifetime Value What Is Customer Lifetime Value (CLV)? Customer Lifetime Value (CLV) is a crucial business metric that estimates the total revenue a business can reasonably expect from a single customer throughout their entire relationship with the company. This metric is essential for understanding how much money customers will spend on your products or services over time. For example, consider a customer loyal to an auto brand whose vehicles average $30,000 each. If this customer buys three cars from the brand in their lifetime, their CLV is $90,000. Similarly, a person who visits their local coffee chain five days a week and spends $4 on a coffee will have a CLV of $10,400 over the course of 10 years. Understanding CLV is vital for businesses because it helps determine the appropriate amount of investment in acquiring and retaining customers. It takes into account a customer’s revenue value and compares it to the company’s predicted customer lifespan. Customer support and success teams play a significant role in influencing CLV by enhancing the customer’s journey. The longer a customer continues to purchase from your company, the greater their lifetime value becomes. 5.1.1 From Forbes Magazine Source 1: Forbes Customer lifetime value is a business metric used to determine the amount of money a customer will spend throughout the business relationship. It helps businesses determine customer acquisition costs, improve forecasting and increase profits over time. It also serves as a guide for decisions about their overall business strategy. A higher CLV indicates customers spend more money on your product or service throughout the business relationship. When customers spend more and purchase frequently, your business is more successful and profitable. The industries with the highest customer lifetime value are architecture firms for $1,129,000, followed by business operations consulting firms for $385,800 and healthcare consulting firms priced at $328,600. These firms generate high amounts of revenue for hourly fees, consultation fees, material costs and projects. The estimated value of each customer can play an integral role when making business decisions, such as whether to invest more in customer acquisition or retention. 5.1.1.1 Reasons To Know Your CLV Let’s take a look at several reasons why CLV matters. 1. Determine customer acquisition cost How much should you invest in hiring a new customer? When you can determine the amount a customer will spend on your business, you can gauge the amount of money to spend on marketing campaigns. For example, when you find out a customer spends an average of $1,000 on your business over time⁠—you might have the budget to spend more on advertising and targeting campaigns. Not only that, but you have room to invest more money to personalize your email marketing strategy or content strategy. Alternatively, if the estimated CLV is $1,000, you would only invest this much in convincing a customer to stay. Otherwise, you wouldn’t profit from the relationship. 2. Improve profitability consistently over time Optimizing CLV helps you focus on ensuring consistent profitability over time. If you only invest in acquisition and closing new deals, it won’t be easy to remain profitable during slow seasons. In contrast, a high CLV means you can rely on enough people to return to your store throughout the year. 3. More accurate forecasting Customer lifetime value (CLV) can help you make better production, workforce and inventory decisions. It helps pinpoint the types of clients you have, the best-selling products you buy and the factors that drive customer loyalty. Otherwise, you may spend more on producing products with insufficient demand. 4. Improve overall business strategy Understanding CLV helps you determine the most effective strategy for your business growth. If your CLV is low, you may need to invest more in loyalty programs and initiatives to boost customer retention. In contrast, a high CLV means you may need to look into the best-selling products and campaigns driving growth to keep the momentum going. Over time, this strategy will help you create more cost-effective strategies around customer acquisition, marketing and sales. 5. Better understand loyal customers Customer lifetime value helps you understand the most loyal brand advocates. How often do they shop from your business? What items are they more likely to purchase? Answering these questions can help you brainstorm ways to engage with your most loyal customers. 5.1.1.2 How To Improve Your Customer Lifetime Value Improving your CLV can enhance your business’s profitability over time. To that end, here are a few ways to improve customer loyalty and retention. 1. Create a loyalty and rewards program A growing body of research proves rewards programs effectively drive loyalty and retention. Gamify the experience by offering discounts and perks every time customers complete a milestone (e.g., making their first order and spending a specific amount). For example, Victoria’s Secret Pink Nation loyalty program lets customers receive members-only perks such as exclusive content, early access to sales, mental health tips and playlists. 2. Increase average order value Making customers spend more in your store can boost CLV. Offer free shipping or freebies for customers who reach a specific order amount, such as $50 or $100. Alternatively, you can bundle related products and sell them at a discounted price. For SaaS businesses, you can give temporary upgrades such as seven-day or 14-day trials. Not only does this allow your customers to see the advanced features they’re missing out on, but it may also persuade them to upgrade and make the transition. 3. Launch post-purchase email campaigns Offer next-order coupons or discounts to encourage customers to shop again. A good tip is to place them on order confirmation emails because they have a high open rate of around 65%, which is nearly four times higher than an average email. Another way is to deliver post-purchase emails seeking reviews to encourage customers to shop again. 4. Place product recommendations Product recommendations matter. A study found 92.4% of consumers are influenced by reviews when purchasing. Nearly 90% of consumers believe in product reviews as much as advice from family and friends. Having product recommendations lets customers evaluate whether or not a product is worth buying. So, recommendations are another way to get customers to buy more, which increases customer lifetime value. Amazon’s algorithm selects product recommendations based on users’ past purchases and browsing behavior. Using this information, it can make suggestions such as “similar items viewed” or “frequently bought together” by consumers with the same interests or preferences. That’s why 35% of Amazon.com’s revenue comes from its recommendation engine. Judging by the numbers, recommendations are crucial to increasing CLV. 5. Create personalized experiences Businesses that want to retain customers should focus on increasing their value and relevance. That’s why creating personalized experiences relevant to shoppers’ interests is essential. A survey of 1,000 U.S. adults by Epsilon and GBH Insights found that 80% of respondents want personalization from retailers. Likewise, McKinsey predicts shopping will feel incredibly personalized by 2030. Moving forward, businesses must be able to segment customers based on their demographics, interests and purchasing behaviors. This could mean tailoring content recommendations based on browsing behavior. 6. Offer quality customer service Good customer service is essential to encourage customers to be long-time patrons. It only takes one bad experience to prompt a customer to switch to your competitors. A Qualtrics study found 80% of customers have changed brands because of a poor customer experience. A good tip is to increase communication channels for customer support. Ideally, it would help if you looked into the channels your consumers use the most and created touchpoints there. A study found companies with solid omnichannel customer engagement retain 89% of their buyers. 7. Create unified customer experiences Thanks to the evolution of technology, most consumers adopt a hybrid approach when purchasing. They may discover a product on Facebook, visit the brand’s website and go to an in-store outlet to examine the physical product—and this won’t stop soon. While brands can create different touchpoints, ensuring these experiences are streamlined is essential. For example, Timberland lets people stand in front of augmented reality mirrors to envision how apparel fits before going to the fitting room. Similarly, IKEA’s app allows shoppers to browse products online and use their smartphone’s camera to see how it looks in a room. 8. Make returns easy (and ideally, free) Sometimes customers aren’t delighted with the product—and that’s perfectly okay. Just make it easy for customers to return products and services. A fast and easy return process will encourage customers to return to your online store and give it a try again. 9. Create actionable surveys Understand your customers by creating actionable surveys. This information will help you understand customers’ level of satisfaction with your products or services. Not only that, but it will help you determine the most effective strategies to drive higher CLV while growing your customer base. For example, Sephora collected consumer data and found that 70% of customers that visited its website within 24 hours before visiting the store spent 13% more than other customers. After realizing the importance of online customer journeys, it launched online campaigns that improved in-store engagement. The results? It found a higher return on ad spend (ROAS) by 3.9 times and a threefold increase in conversion rates. 5.1.1.3 Common Mistakes Around CLV CLV isn’t a magical metric that will solve all your problems. If not used wisely, businesses can fall prey to costly pitfalls. Remember these mistakes when examining your CLV. No Segmentation Sure, it’s excellent to increase CLV for your entire customer base—but it’s not an effective strategy. Marketing to everyone will lead you to invest more resources in low CLV customers. Examine cohorts with a high CLV—which could be your top 20% spenders. Ideally, it would be best if you focused on increasing CLV among valuable customers who are likely to spend more on your products and services based on data. Identify, understand and engage with them to understand their preferences, lifestyle, attitudes and behaviors. Wrong Segmentation You can also identify CLV within a customer cohort or segment. A segment is a group of customers with similar characteristics, attitudes and behavior. Proper segmentation provides an overview of consumer behavior and what makes them distinct. Creating campaigns that target specific segments is more effective due to personalization. However, incorrect segmentation may lead to a waste of precious company resources. Targeting an Unrealistic CLV Some customers will abandon your product or service no matter how hard you try. Only some people will pay thousands of dollars to transact with your business over time. There’s also no point in investing hundreds of dollars on low-value prospects. As with any business objective, you have to be realistic. Think of ways to appeal to your target demographic but do not expect everyone to end up with a high CLV. Failure To Be Flexible Turning your small business into an empire is ideal—but things aren’t always smooth sailing. Sometimes recessions or inflation could decrease your CLV. Or, you may have to increase the prices of your products and services based on production costs and uncontrollable market forces. Be flexible when unpredictable situations arise and don’t be afraid to change your CLV based on these trends. Bottom Line Customer lifetime value (CLV) can help determine how much customers will spend on your business in the long term. It helps inform customer loyalty, acquisition, marketing and sales decisions. Improving CLV can be done through various tactics such as creating a loyalty and rewards program, creating personalized experiences and offering quality customer service. Staying aware of common pitfalls when aiming for high CLV can also help prevent errors that could make your company waste valuable resources. 5.1.2 From a hubspot blog Source It’s easier to sell to an existing customer than it is to acquire a new one. Why is customer lifetime value important? Increasing CLV can increase revenue over time. It can help you find issues so you can boost customer loyalty and retention. It helps you target your ideal customers. Increasing CLV can help reduce customer acquisition costs. CLV can simplify financial planning. CLV trends can show you how to improve your products and services Customer lifetime value helps you understand the growth and revenue value of each customer over time. This metric is important to any business because it can help your business: Boost customer loyalty Reduce churn Improve strategic decision-making For example, you can use customer lifetime value to find the customer segments that are most valuable to your company. Here are some other reasons why understanding your CLV is essential. 1. Increasing CLV can increase revenue over time. The longer the lifecycle or the more value a customer brings during that lifecycle, the more revenue a business earns. Therefore, tracking and improving CLV results in more revenue. CLV helps you find the specific customers that contribute the most revenue to your business. You can use this information to segment your audience by the value those customers bring. Once you find those customers, you can encourage repeat purchases and find specific cross-selling and upselling opportunities for different segments of your audience. Or you can tailor your products or marketing to your highest spenders to keep them coming back for more. 2. It can help you identify issues so you can boost customer loyalty and retention. If CLV is a priority in your business, you can use it to identify impactful trends in your customer data. This insight can help you stay ahead of competition with action items to address those changes. CLV helps you understand customer behavior, preferences, and spending patterns. With this analysis, you can improve your data-driven decision-making. This leads to more personalized marketing strategies for growth. For example, say your CLV is low. You can work to optimize your customer support strategy or loyalty program to better meet the needs of your customers. Or you can optimize a new product to attract higher-value customers. 3. It helps you target your ideal customers. Customer lifetime value tracking makes it easier to segment your customers. You can segment based on profitability, customer needs, preferences, or behavior. When you know the lifetime value of a customer, you also know how much money they spend with your business over some time — whether it’s $50, $500, or $5000. Armed with that knowledge, you can develop a customer acquisition strategy that targets customers who will spend the most at your business. You can personalize marketing to attract and retain them, and effectively allocate resources to get the most value from your efforts. 4. Increasing CLV can help reduce customer acquisition costs. Acquiring new customers can be costly, and it’s less expensive to retain a customer than it is to acquire a new one. Customer lifetime value can help reduce costs with a focus on retaining existing customers. If you can keep a customer happy long-term, then you can improve their value to the business. Using CLV metrics can improve customer loyalty and word-of-mouth referrals — it can also reduce marketing and sales expenses. 5. CLV can simplify Financial planning. The financial health of a business is often a big concern for CEOs and business owners. Customer lifetime value helps you get a clear picture of your customers’ relationship with your business and products. It can offer insights into future revenue streams and changes in customer behavior. This knowledge can help you make more accurate predictions about future cash flows. So, CLV helps you reliably forecast revenue and plan the financial future of your business. 6. CLV trends can show you how to improve your products and services. Understanding CLV can give you a better understanding of the value customers get from specific products or services. With insights from your CLV you’ll have a clear direction for further analysis. This may guide you to look at customer feedback and behavior, update pain points, or change your approach to product development. Lifetime value data can help you find where to make key improvements that align with customer needs and boost satisfaction. This not only strengthens customer loyalty but also differentiates your company from competitors. Now that we understand the importance of customer lifetime value, let’s talk about the two main customer lifetime value models. Customer Lifetime Value Models There are two models that companies will use to measure customer lifetime value. Choosing between the two can result in different outcomes. This depends on whether a business is looking at pre existing data, or trying to figure out the future behavior of customers based on current circumstances. Predictive Customer Lifetime Value The predictive CLV model forecasts the buying behavior of existing and new customers using regression or machine learning. Using the predictive model for customer lifetime value helps you better identify your most valuable customers, the product or service that brings in the most sales, and how you can improve customer retention. Historical Customer Lifetime Value The historical model uses past data to predict the value of a customer without considering whether the existing customer will continue with the company or not. With the historical model, the average order value is used to determine the value of your customers. You’ll find this model to be especially useful if most of your customers only interact with your business over a certain period. But because most customer journeys are not identical, this model has certain drawbacks. Active customers (deemed valuable by the historical model) might become inactive and skew your data. In contrast, inactive customers might begin to buy from you again, and you might overlook them because they’ve been labeled “inactive.” Customer Lifetime Value Formula The customer lifetime value formula is Customer Lifetime Value = Customer Value x Average Customer Lifespan. The CLV result is the revenue you expect an average customer to generate during their relationship with your business. Typically, lifetime value (LTV) calculates the overall value of all customers. But customer lifetime value (CLV) can also focus on the business value of specific customers or groups of customers. The formula above is the standard formula to calculate CLV. But finding this important figure can be more complicated than it looks. Customer Lifetime Value = (Customer Value * Average Customer Lifespan). To find CLTV, calculate customer value = the average purchase value x average number of purchases Once you calculate the average customer lifespan, you can multiply that by customer value to determine customer lifetime value. You can see both formulas below: Customer Value = Average Purchase Value x Average Number of Purchases Customer Lifetime Value = Customer Value x Average Customer Lifespan Average Purchase Value Divide your company’s total revenue in a period (usually one year) by the number of purchases throughout that same period. Average purchase value helps you see the average amount of revenue each customer generates during a period. Analyzing this number also shows you: Opportunities to increase the value of each transaction New options for cross-selling and upselling Whether your pricing and packaging strategies are working This data helps you find new and viable products or services and other strategies to increase value per transaction and revenue. Average Purchase Frequency Rate To calculate average purchase frequency rate: Divide the number of purchases by the number of unique customers who made purchases during that period. Recent research says that a 5% customer retention increase can create a 25%+ increase in profit. Average Purchase Frequency Rate is essential for calculating CLV because it shows you how often customers make repeat purchases. This metric also offers insights into: Customer engagement and loyalty Trends in customer behavior over time Churn reduction Future revenue streams Average Purchase Frequency Rate Challenges Like average purchase value, inconsistent or incomplete data can also distort your purchase rate numbers. Other challenges include: Purchase cycle timing, which can get skewed by industry trends or product releases Changing customer buying patterns Seasonality Tips for Calculating Average Purchase Frequency Rate Track and analyze customer data to capture changing customer buying patterns Regularly review and update customer segmentation based on buying patterns ONer personalized promotions to inspire more consistent spending Conduct customer surveys or interviews for insights into reasons behind changing purchase patterns Customer Value To calculate customer value, =gure out the average purchase value for your products. Then, calculate the average number of purchases per customer (also called purchase frequency rate). When you multiply these two =gures, it will give you the customer value. Customer value is important in calculating CLV because it makes it easier to =nd the customers who have the most impact on your revenue. This leads to better strategies, because you can make more eNective decisions when you know what each customer is bringing to your business. Customer value is also important because it gives you what you need to segment customers by their purchasing habits. Segment insights help you create more targeted, customized experiences for your top customers. Tips for Calculating Customer Value Implement a CRM to con=rm data accuracy Create a consistent process for assigning monetary value to each customer based on their transaction history Combine =nancial systems with customer data to show the monetary value of each customer, like these [nance integrations Watch customer feedback and sentiment through reviews and social listening to add it to customer value calculations Average Customer Lifespan To calculate average customer lifespan:First, figure out the average number of years a customer stays active with your company. Once you have your customer lifespan, you’ll divide that by your total customer base to get the average. ou’ll need excellent data management for this =gure, and make sure you don’t have duplicate accounts in your data. Average customer lifespan is useful when calculating CLV. This is because it supports predictions on how long customer relationships will last with data. This helps you make more informed budgeting and resourcing decisions. It can also help you: Launch proactive strategies to build customer relationships and reduce churn Figure out the ROI for customer acquisition Optimize marketing strategies Find acquisition channels with higher CLV potential Average Customer Lifespan Challenges Calculating average customer lifespan can be tough because: Accurate customer lifecycle tracking needs a robust data management system DiNerent customer segments and subgroups can skew lifespan predictions Limited customer data or short relationships lead to projections that don’t align with actual customer behavior Tips for Calculating Average Customer Lifespan Use reliable customer service software to track the customer lifecycle Include data from diNerent sources and platforms to create a full view of the customer journey Capture and analyze data at each stage of the buyer journey to track engagement and retention Analyze the average lifespan of each customer segment individually to limit skewed results Conduct regular trend analysis to predict shifts or changes that may impact lifespan Gather data on customer satisfaction and loyalty Constantly con=rm and adjust lifespan average based on actual customer behavior and feedback Customer Acquisition Cost Customer acquisition cost is not a factor in most CLV formulas, but it can be useful to include in a customer lifetime value analysis. Comparing how much it costs to acquire a customer with their lifetime value to the business, you can =gure out how to: Decide how eNective marketing and sales strategies are Distribute resources wisely Find =tting opportunities to improve customer retention and acquisition Check out this guide to learn more about customer acquisition cost (CAC) and how to calculate. Then, review these tips for analyzing your CAC to LTV ratio. 5.2 CLV Calculations 5.2.1 From Forbes There are four essential steps to calculate CLV. 1. Determine the average order value Determine the average amount customers spend on your business. To get this information get an estimate based on customer transactions in the last few months. this is the average spending per order. 2. Identify frequency of transactions Next, identify how often customers come to your store. How many times do they come back, given a specific period? Do they return weekly, monthly or annually? 3. Measure customer retention Figure out how long an average customer remains loyal to your business. Some industries, including restaurants and retail, tend to have a lower CLV because customers tend to go to establishments that offer a better deal. Meanwhile, industries such as technology and travel have a higher CLV because customers seek updated product features and personalized holiday experiences. 4. Calculate CLV Once you have all this information, calculate CLV with this formula: X = average order value Y = number of transactions Z = average length of the customer relationship (in years) \\(CLV = X x Y x Z\\) Using this information, we can assume a father that regularly purchases smartphones for his family might be worth: \\(\\$1,000 (per\\ smartphone) × 2 (smartphones\\ per\\ year) × 10 (years) = \\$20,000\\) The CLV is $20,000. 5.2.1.1 3 Examples of CLV CLV varies based on the nature of the product or service. Let’s examine various industries to show how CLV could affect your bottom line. 1. Grocery Shop Grocery stores inspire loyalty among residents within the vicinity. Let’s say a shopper frequents a grocery in New York every week. He spends around $100 per visit. He returned every week, 52 weeks a year, for an average of three years. \\(\\$100 (purchase\\ per\\ visit) × 52 (visits\\ per\\ year) × 3 (years) = \\$15,600 (CLV)\\) 2. SaaS Service A UX designer uses a cloud-based subscription service to conceptualize mobile apps. He spends $70 per month for 10 years on the software. In this example, the SaaS product is a necessary job-related expense, so the subscription lasted a long time. \\(\\$70 (subscription\\ fee\\ per\\ month) × 12 (payments\\ per\\ year) × 10 (years) = \\$8,400 (CLV)\\) 3. Interior Design The interior design agency has higher average order values. For example, a homeowner spends $100,000 to renovate their home. Because they liked the initial experience, they became a patron of the interior design firm and renovated their property every 10 years within 20 years. \\(\\$100,000 (per\\ renovation) × 0.1 (annual\\ purchase) × 20 (years) = \\$200,000 (CLV)\\) These examples show CLV varies across industries. While day-to-day products such as coffee are bought more frequently, you need to get customers to purchase often to get a high CLV. In contrast, some products such as houses, automobiles or interior design agencies have a lower purchase frequency. But due to the nature of the product or service, they rack up thousands of dollars with only a few transactions. 5.2.2 Another example (AI) Customer Lifetime Value (CLV) can be calculated at both the individual level and the brand level, depending on your objectives and the granularity of your analysis. Here’s how you can approach each: 5.2.2.1 Individual-Level CLV Calculating CLV at the individual level involves estimating the total revenue that each specific customer will generate over their relationship with the brand. This method provides detailed insights into the value of each customer, which can help in personalizing marketing efforts and customer retention strategies. Here’s how you can calculate it: Calculate Average Purchase Value (APV): \\[ \\text{APV} = \\frac{\\text{Total Revenue}}{\\text{Number of Purchases}} \\] Calculate Purchase Frequency (PF): \\[ \\text{PF} = \\frac{\\text{Number of Purchases}}{\\text{Number of Customers}} \\] Calculate Customer Value (CV): \\[ \\text{CV} = \\text{APV} \\times \\text{PF} \\] Estimate Customer Lifespan (CL): \\[ \\text{CL} = \\text{Average Customer Lifespan in Years} \\] Calculate Individual CLV: \\[ \\text{CLV} = \\text{CV} \\times \\text{CL} \\] 5.2.2.2 Brand-Level CLV Calculating CLV at the brand level involves aggregating the CLV of all customers to get an overall estimate of the value that the customer base will generate over time. This method helps in understanding the overall financial health and growth potential of the brand. Here’s how you can calculate it: Calculate Average Revenue Per User (ARPU): \\[ \\text{ARPU} = \\frac{\\text{Total Revenue}}{\\text{Total Number of Customers}} \\] Estimate Average Customer Lifespan (CL): \\[ \\text{CL} = \\text{Average Customer Lifespan in Years} \\] Calculate Brand-Level CLV: \\[ \\text{Brand CLV} = \\text{ARPU} \\times \\text{CL} \\times \\text{Total Number of Customers} \\] 5.2.2.3 Steps to Calculate CLV with Your Data Given daily transactional individual-level data, here’s a step-by-step approach: Aggregate the data to calculate total revenue and number of purchases per customer. Calculate APV and PF for each customer. Estimate the average customer lifespan using historical data. Compute the individual CLV for each customer. Aggregate individual CLVs to get the overall brand CLV if needed. By calculating CLV at the individual level, you gain detailed insights that can be rolled up to understand the overall brand performance. This dual approach allows for both personalized customer engagement strategies and broader financial planning. Calculating CLV for each individual customer provides a more granular view of your customer base. This approach allows you to: Identify your most valuable customers Segment customers based on their lifetime value Tailor marketing strategies for different customer segments Predict future value of specific customers To calculate individual CLV, you would use each customer’s specific purchase history, frequency, and value over the 2-year period, and potentially project this into the future. Given your dataset, here’s how you could approach the calculation: Calculate individual CLV: For each customer, determine their total purchase value over the 2-year period Calculate their purchase frequency (number of purchases / 2 years) Project these values forward to estimate future value Sum up the historical and projected values to get individual CLV 5.2.2.4 Brand-level CLV: Calculating CLV at the brand level gives you an average value across all customers. This approach: Provides an overall measure of customer value for your chocolate brand Helps in strategic decision-making at the brand level Allows for easier comparison with industry benchmarks or competitors To calculate brand-level CLV, you would aggregate data across all customers to determine average purchase value, frequency, and customer lifespan. Remember that CLV is typically a forward-looking metric, so you may need to use your 2-year historical data to project future customer behavior and value. Additionally, consider factors like customer acquisition costs and profit margins to get a more accurate picture of customer value. Citations: [1] https://blog.hubspot.com/service/how-to-calculate-customer-lifetime-value [2] https://www.unionkitchen.com/resources/customer-lifetime-value [3] https://www.omnisend.com/blog/customer-lifetime-value-clv/ [4] https://getvoip.com/blog/customer-lifetime-value-formula/ [5] https://www.crazyegg.com/blog/customer-lifetime-value/ By calculating CLV, CPG brands can better understand the long-term value of their customers and make informed decisions about marketing strategies, customer retention efforts, and resource allocation. Keep in mind that CLV calculations are estimates and may be subject to adjustments based on changing market conditions and customer behaviors. The Customer Lifetime Value (CLV) formula provided is typically calculated on a per-customer basis, representing the expected value of an average customer over their entire relationship with a brand. The formula considers the average purchase value, purchase frequency, and customer lifespan for an individual customer. \\[ CLV = \\frac{{\\text{Average Purchase Value} \\times \\text{Purchase Frequency} \\times \\text{Customer Lifespan}}}{{\\text{Discount Rate}}} \\] So, each customer will have their own CLV based on their purchasing behavior and the estimated duration of their relationship with the brand. The overall CLV for a brand is often the sum of the CLVs for all its customers. This individual customer focus allows businesses to understand the value of acquiring and retaining each customer and can inform marketing strategies, customer relationship management, and overall business decisions. 5.2.3 CLV Example (hubspot) source Using data from a Kissmetrics report, we can take Starbucks as an example for determining CLTV. Its report measures the weekly purchasing habits of five customers, then averages their total values together. By following the steps listed above, we can use this information to calculate the average lifetime value of a Starbucks customer. 1. Calculate the average purchase value. Measure Average Purchase Value. based on Kissmetrics, the average Starbucks customer spends about $5.90 each visit. Average the money spent by a customer in each visit during the week. For example, a person goes to Starbucks three times and spent nine dollars total, then average purchase value would be three dollars. Repeat the process for the other five customers. Then add each average together, divide that value by the number of customers surveyed (five) to get the average purchase value. 2. Calculate the average purchase frequency rate. Now measure the average purchase frequency rate. How many visits the average customer makes to one of a store within a week. The average observed across the 5 customers in the report was found to be 4.2 visits. This makes our average purchase frequency rate 4.2. 3. Calculate the average customer’s value. Now that we know what the average customer spends and how many times they visit in a week, we can determine their customer value. To do this, we have to look at all =ve customers individually and then multiply their average purchase value by their average purchase frequency rate. This lets us know how much revenue the customer is worth to Starbucks within a week. Once we repeat this calculation for all =ve customers, we average their values to get the average customer’s value of $24.30. 4. Calculate the average customer’s lifetime span. While it’s not explicitly stated how Kissmetrics measured Starbucks’ average customer lifetime span, it does list this value as 20 years. If we were to calculate Starbucks’ average customer lifespan, we would have to look at the number of years each customer frequented Starbucks. Then we could average the values together to get 20 years. If you don’t have 20 years to wait and verify that, one way to estimate customer lifespan is to divide 1 by your churn rate percentage. Calculate your customer’s lifetime value. Once we have determined the average customer value and the average customer lifespan, we can use this data to calculate CLTV. In this case, we first need to multiply the average customer value by 52. Since we measured customers on their weekly habits, we need to multiply their customer value by 52 to reflect an annual average. After that, multiply this number by the customer lifespan value (20) to get CLTV. For Starbucks customers, that value turns out to be $25,272 (52 x 24.30 x 20= 25,272). 5.2.4 Study of Customer lifetime value model based on Survival analysis methods Customer are at the center of business. Understanding the value of a customer is important in terms of personalized marketing efforts 5.2.4.1 Basic Model of CLV Barbara, Jackson (1985) laid the foundation. CLV depends on the income from customer at every stage of the life cycle. Berger, Nasr (1998) introduced parameter of customer retention rate. \\[CLV = \\sum_{i=1}^{n}{\\gamma . \\pi(i).(1+d)^-i}\\] \\(\\pi():\\) profit function of customer \\(i:\\) time variable \\(\\gamma:\\) retention rate \\(d:\\) discount rate \\(n:\\) entire life cycle of time Here are the topics criticized: rate of customer retention is replaced by a constant, or by a function of time. time of the customer lifetime is always evaluated as constant. customer’s future profitablity is constant 5.2.4.2 Improved CLV model using Survival Analaysis 5.2.4.2.1 Estimating dynamic Customer retention rate survival time is a measure of the time of an event. Survival function can be used to describe the distribution of survival time. Customer retention rate is actually the distribution of customer life time. \\[r(t) = r_0(t)^{exp(\\beta)}, t&gt;0\\] \\(r(t)\\) is the cummulative retention rate of lost-for-good customers. \\(r(t)\\) is also the dynamic customer retention rate which can be can be given by Cox regression analysis. 5.2.4.2.2 Life cycle time parameter the lifetime of a typical customer is the expectation value of most customers’ lifetime. the time which it cost for the dynamic customer retention rate declining from 100% to 50% What is testing proportional hazard assumptions? 5.2.5 Look-alike Modeling What is a Look-Alike? Look-alike audiences are the prospects who are having similar traits, behavior like your already existing customers. Look-alike modeling is a process that essentially helps you in finding look-alike audiences of your best, most profitable customers. It is a modelling approach that can be used by marketers to define customers who are most likely to engage with their marketing messages or activities. This model analyzes and considers common behaviors or traits among the current customers and seeks potential customers who have similar characteristics. Seed Data is data of existing customers based on whom we want to find look-alike audiences. Pool Data is the customer database, in which we would look for customers who are look-alikes to seed data. Pool data could be collected from various sources. Extended Look-Alikes Audience are the look-alike audience generated by the model from pool audience, based on seed data. Benefits of Look-Alike Modeling Look-Alike model plays a key role in making business and marketing related decisions. Helps in understanding existing customer base and expand business reach by only focusing on your best customers with a stable business model. 1. Effective Targeting Look-Alike model helps businesses and marketers to execute better marketing campaigns by limiting their focus to those prospects who are similar to the target customers on whom the business is interested in. 2. Lower Acquisition Cost Customer Cost Acquisition (CAC) cost is, in general, approximately 6-7 times costlier than Customer Retention Cost (CRC). But by relying on look-alike modeling, businesses can reduce CAC as they would only spend their marketing efforts on potential customers (look-alikes) who are more likely to convert. 3. Loyal and Profitable Customer Base Look-alike modeling helps you in building a highly profitable customer base, by allowing you to target the look-alikes of those customers with high Customer Lifetime Value (CLV) ensuring a highly profitable customer base for your business, in the long run. What is Look-alike Modeling Look-alike modeling is essentially finding groups of people (audiences) who look and act like your best, most profitable customers. For example, let’s say you run an ecommerce store and you’ve identified that your best audience are people whose average purchase is over $100, buy cosmetics and perfumes, and make a purchase at least twice a month; look-alike modeling would allow you to find more people like that. How to Look-alike Modeling (LAL)? Demand Side Platforms (DSP) can perform LAL modeling Data Management Platforms can conduct LAL modeling Requires data collection and modeling Define the attributes and behaviors of your most valuable customers. The stricter your look-alike model is (the more attributes you define), the better chance you have of finding your target — albeit smaller — audience, which will allow you to improve campaign performance. Meaning if the model is more complex, then accuracy of the model increase. However, you could be less strict with the look-alike model (i.e. define less attributes and behaviors) if your goal is to focus on overall reach and awareness rather than higher conversion rates. A look-alike model that has tightly defined (more) attributes and behaviors, and one that has loosely defined (less) attributes and behaviors. The third step involves using algorithms to extend the audience based on the look-alike model. The DMP or DSP would analyze the seed audience (the pre-defined best customers) and then apply proprietary algorithms to the data you’ve collected in order to find user profiles that match the seed audience. Goal: Prospecting and Increasing Campaign Reach Look-alike modeling is mainly used for prospecting, which involves finding new potential customers and/or visitors. However, it can also be used to extend the reach of online advertising campaigns. Let’s say you target audiences based on a set of attributes (e.g. age, gender, location, etc.). By applying look-alike modeling to your campaigns, you can find similar customers who perhaps don’t fit your current audiences either because we don’t have enough data (e.g. we lack the attributes needed to make a match) or they don’t fit your current audiences (i.e. they consists of other attributes) but are still similar in many ways to your best customers. LAL Modeling vs Classification Modeling Look-alike modeling and classification modeling are two distinct techniques used in data analysis and machine learning, often employed in marketing and predictive analytics contexts. Look-alike Modeling: Definition: Look-alike modeling, also known as similarity modeling or clone modeling, involves identifying individuals or entities in a target group who resemble those in a source group based on certain characteristics. Process: It begins with a source group of individuals or entities with known traits or behaviors of interest. Machine learning algorithms then analyze these traits to identify patterns and similarities. These patterns are then applied to a larger population to find individuals or entities who closely resemble those in the source group. Application: Look-alike modeling is commonly used in marketing to identify potential customers who share characteristics with existing customers or high-value prospects. It helps in targeting marketing campaigns more effectively by focusing resources on individuals with a higher likelihood of conversion. Classification Modeling: Definition: Classification modeling involves categorizing data points into predefined classes or categories based on their features or attributes. Process: In classification modeling, historical data with known outcomes is used to train machine learning algorithms. These algorithms learn patterns from the input data and assign new data points to predefined classes or categories based on their similarities to the training data. Application: Classification modeling is widely used in various domains such as finance, healthcare, and e-commerce. Examples include spam email detection, sentiment analysis, disease diagnosis, and credit risk assessment. The model predicts the class or category to which a new data point belongs based on its features. In summary, look-alike modeling focuses on finding individuals or entities similar to a known group, while classification modeling focuses on categorizing data points into predefined classes or categories based on their features. Both techniques are valuable in different contexts and can provide insights for decision-making and targeting in various industries. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
